<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>哼着自己旳小调调</title>
  
  <subtitle>Happy hum their own small tune</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://cy-blogs.cn/"/>
  <updated>2019-12-24T11:09:15.844Z</updated>
  <id>https://cy-blogs.cn/</id>
  
  <author>
    <name>哼着自己旳小调调</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySQL 事务隔离级别</title>
    <link href="https://cy-blogs.cn/mysql%E4%BA%8B%E5%8A%A1%E7%89%B9%E6%80%A7%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
    <id>https://cy-blogs.cn/mysql事务特性及隔离级别/</id>
    <published>2019-12-24T11:09:28.852Z</published>
    <updated>2019-12-24T11:09:15.844Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-1-2、事务的特性"><a href="#1-1-2、事务的特性" class="headerlink" title="1.1.2、事务的特性"></a>1.1.2、事务的特性</h3><ol><li><p>原子性</p><blockquote><p>事务中的全部操作在数据库中是不可分割的，要么全部完成，要么全都不完成</p></blockquote></li><li><p>一致性</p><blockquote><p>几个并行执行的事务，其执行结果必须与按某一顺序串行执行的结果相一致</p></blockquote></li><li><p>隔离性</p><blockquote><p>事务的执行不受其他事务的干扰，事务执行的中间结果对其他事务必须是透明的</p></blockquote></li><li><p>持久性</p><blockquote><p>一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作</p></blockquote></li></ol><a id="more"></a><p><img src="https://pic2.zhimg.com/80/v2-59ea2f0769e4e9ffbcdce938d306fae9_hd.png" alt="img"> </p><h3 id="1-1-3、事务隔离级别"><a href="#1-1-3、事务隔离级别" class="headerlink" title="1.1.3、事务隔离级别"></a>1.1.3、事务隔离级别</h3><ol><li><p><strong>未提交读：脏读（READ UNCOMMITTED）</strong></p><ol><li>事务2查询到的数据是事务1中修改但未提交的数据，但因为事务1回滚了数据</li><li>所以事务2查询的数据是不正确的，因此出现了脏读的问题</li></ol></li></ol><h3 id="READ-UNCOMMITTED（读未提交）"><a href="#READ-UNCOMMITTED（读未提交）" class="headerlink" title="READ UNCOMMITTED（读未提交）"></a>READ UNCOMMITTED（读未提交）</h3><p> 该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为<strong>脏读</strong>。 </p><p> 两个命令行客户端分别为A，B；不断改变A的隔离级别，在B端修改数据。 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">将A的隔离级别设置为read uncommitted(未提交读)</span><br><span class="line">A：<span class="keyword">SET</span> @@session.transaction_isolation = <span class="string">'READ-UNCOMMITTED'</span>;</span><br><span class="line">创建一张test</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">test</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">use</span> <span class="keyword">test</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(<span class="keyword">id</span> <span class="built_in">int</span> primary <span class="keyword">key</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span>(<span class="keyword">id</span>) <span class="keyword">values</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">A：启动事务，此时数据为初始状态</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"></span><br><span class="line">B：启动事务，更新数据，但不提交</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">test</span> <span class="keyword">set</span> <span class="keyword">id</span> = <span class="number">2</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">A：再次读取数据，发现数据已经被修改了，这就是所谓的“脏读</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line"></span><br><span class="line">B:回滚事务</span><br><span class="line"><span class="keyword">rollback</span>;</span><br><span class="line"></span><br><span class="line">A:再次读数据，发现数据变回初始状态</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><ol><li><p><strong>提交读：不可重复读（READ COMMITTED）</strong></p><p>注：一个事务从开始到提交之前对数据所做的改变对其他事务是不可见的，这样就解决在READ-UNCOMMITTED级别下的脏读问题。</p><ol><li>事务2执行update语句但未提交前，事务1的前两个select操作返回结果是相同的</li><li>但事务2执行commit操作后，事务1的第三个select操作就读取到事务2对数据的改变</li><li>导致与前两次select操作返回不同的数据，因此出现了不可重复读的问题</li></ol></li></ol><h3 id="READ-COMMITTED（提交读）"><a href="#READ-COMMITTED（提交读）" class="headerlink" title="READ COMMITTED（提交读）"></a>READ COMMITTED（提交读）</h3><p> 一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，此现象称为不可重复读问题，Oracle 和 SQL Server 的默认隔离级别。 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">A:将客户端A的事务隔离级别设置为read committed(已提交读)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> @@session.transaction_isolation = <span class="string">'READ-COMMITTED'</span>;</span><br><span class="line">创建test表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(<span class="keyword">id</span> <span class="built_in">int</span> primary <span class="keyword">key</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span>(<span class="keyword">id</span>) <span class="keyword">values</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">A：启动事务，此时数据为初始状态</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"></span><br><span class="line">B：启动事务，更新数据，但不提交</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">test</span> <span class="keyword">set</span> <span class="keyword">id</span> = <span class="number">2</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">A：再次读数据，发现数据未被修改</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line"></span><br><span class="line">B：提交事务</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line">A：再次读取数据，发现数据已发生变化，说明B提交的修改被事务中的A读到了，这就是所谓的“不可重复读”</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><ol><li><strong>可重复读：幻读（REPEATABLE READ）：这是MySQL的默认事务隔离级别</strong><ol><li>事务每开启一个实例，都会分配一个版本号给它，如果读取的数据行正在被其他事务执行DELETE或UPDATE操作（既该行上有排他锁）</li><li>这时该事务的读取操作不会等待行上的锁释放，而是根据版本号去读取行的快照数据（记录在undo log中）</li><li>这样，事务中的查询操作返回的都是同一版本下的数据，解决了不可重复读问题。</li><li>虽然该隔离级别下解决了不可重复读问题，但理论上会导致另一个问题：幻读（Phantom Read）。</li><li>一个事务在执行过程中，另一个事务对已有数据行的更改，MVCC机制可保障该事务读取到的原有数据行的内容相同</li><li>但并不能阻止另一个事务插入新的数据行，这就会导致该事务中凭空多出数据行，像出现了幻读一样，这便是幻读问题</li></ol></li></ol><h3 id="REPEATABLE-READ（可重复读）"><a href="#REPEATABLE-READ（可重复读）" class="headerlink" title="REPEATABLE READ（可重复读）"></a>REPEATABLE READ（可重复读）</h3><p> 该隔离级别是 MySQL 默认的隔离级别，在同一个事务里，<code>select</code> 的结果是事务开始时时间点的状态，因此，同样的 <code>select</code> 操作读到的结果会是一致的，但是，会有<strong>幻读</strong>现象 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">将A的隔离级别设置为repeatable read(可重复读)</span><br><span class="line"><span class="keyword">SET</span> @@session.transaction_isolation = <span class="string">'REPEATABLE-READ'</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(<span class="keyword">id</span> <span class="built_in">int</span> primary <span class="keyword">key</span>,<span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">20</span>));</span><br><span class="line"></span><br><span class="line">A：登录 mysql 终端 A，开启一个事务。</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>; <span class="comment">-- 无记录</span></span><br><span class="line"></span><br><span class="line">B：登录 mysql 终端 B，开启一个事务。</span><br><span class="line"><span class="keyword">use</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>; <span class="comment">-- 无记录</span></span><br><span class="line"></span><br><span class="line">A:切换到 mysql 终端 A，增加一条记录并提交。</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span>(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">'a'</span>);</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>; <span class="comment">--可以看到已经更改</span></span><br><span class="line"></span><br><span class="line">B:切换到 msyql 终端 B。</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>; <span class="comment">--此时查询还是无记录</span></span><br><span class="line"></span><br><span class="line">通过这一步可以证明，在该隔离级别下已经读取不到别的已提交的事务，如果想看到 mysql 终端 1 提交的事务，在 mysql 终端 2 将当前事务提交后再次查询就可以读取到 mysql 终端 1 提交的事务。</span><br><span class="line"> 可重复读隔离级别只允许读取已提交记录，而且在一个事务两次读取一个记录期间，其他事务部的更新该记录。 </span><br><span class="line"></span><br><span class="line">B：此时接着在 mysql 终端 B 插入一条数据。</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span>(<span class="keyword">id</span>,<span class="keyword">name</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">'b'</span>); <span class="comment">-- 此时报主键冲突的错误</span></span><br><span class="line">这就是该隔离级别下可能产生的问题，MySQL 称之为幻读。</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><ol><li><p><strong>可串行读（SERIALIZABLE）</strong></p><ol><li>这是事务的最高隔离级别，通过强制事务排序，使之不可能相互冲突，就像在每个读的数据行加上共享锁来实现</li><li>在该隔离级别下，可以解决前面出现的脏读、不可重复读和幻读问题，但也会导致大量的超时和锁竞争现象，一般不推荐使用</li></ol></li></ol><h3 id="SERIALIZABLE（可串行读）"><a href="#SERIALIZABLE（可串行读）" class="headerlink" title="SERIALIZABLE（可串行读）"></a>SERIALIZABLE（可串行读）</h3><p> 在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式加一把读共享锁，从而避免了脏读、不可重读复读和幻读问题。 </p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">A:准备两个终端，在此命名为 mysql 终端 A 和 mysql 终端 B，分别登入 mysql，准备一张测试表 test 并调整隔离级别为 SERIALIZABLE，任意一个终端执行即可。</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">session</span> <span class="keyword">transaction</span> <span class="keyword">isolation</span> <span class="keyword">level</span> <span class="keyword">serializable</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">test</span>(<span class="keyword">id</span> <span class="built_in">int</span> primary <span class="keyword">key</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">test</span>(<span class="keyword">id</span>) <span class="keyword">values</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">A:登录 mysql 终端 A，开启一个事务，并写入一条数据。</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line"></span><br><span class="line">B:登录 mysql 终端 B，开启一个事务。</span><br><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">test</span>; </span><br><span class="line"> <span class="keyword">delete</span> <span class="keyword">from</span> <span class="keyword">test</span>;</span><br><span class="line"></span><br><span class="line">A:立马切换到 mysql 终端 A,提交事务。</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line">一旦事务提交，msyql 终端 B 会立马返回 ID 为 1 的记录，否则会一直卡住，直到超时，其中超时参数是由 innodb_lock_wait_timeout 控制</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-1-2、事务的特性&quot;&gt;&lt;a href=&quot;#1-1-2、事务的特性&quot; class=&quot;headerlink&quot; title=&quot;1.1.2、事务的特性&quot;&gt;&lt;/a&gt;1.1.2、事务的特性&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;原子性&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;事务中的全部操作在数据库中是不可分割的，要么全部完成，要么全都不完成&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;一致性&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;几个并行执行的事务，其执行结果必须与按某一顺序串行执行的结果相一致&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;隔离性&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;事务的执行不受其他事务的干扰，事务执行的中间结果对其他事务必须是透明的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;持久性&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="MySQL" scheme="https://cy-blogs.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL存储引擎如何选择</title>
    <link href="https://cy-blogs.cn/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9/"/>
    <id>https://cy-blogs.cn/MySQL存储引擎如何选择/</id>
    <published>2019-12-24T11:09:28.850Z</published>
    <updated>2019-12-24T11:07:47.122Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL存储引擎如何选择"><a href="#MySQL存储引擎如何选择" class="headerlink" title="MySQL存储引擎如何选择"></a>MySQL存储引擎如何选择</h1><h4 id="定义以及作用"><a href="#定义以及作用" class="headerlink" title="定义以及作用"></a>定义以及作用</h4><blockquote><p>数据库引擎是用于存储、处理和保护数据的核心服务。</p><p>利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。</p><p>使用数据库引擎创建用于联机(客户端与服务端能够实时通信。由客户机发起，直到服务器确认。)事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）。</p></blockquote><a id="more"></a><h4 id="Mysql的存储引擎有哪些："><a href="#Mysql的存储引擎有哪些：" class="headerlink" title="Mysql的存储引擎有哪些："></a>Mysql的存储引擎有哪些：</h4><blockquote><p>InnoDB</p><blockquote><p>这是MySQL 5.5或更高版本的默认存储引擎。它提供了事务安全(ACID兼容)表，支持外键引用完整性约束。它支持提交、回滚和紧急恢复功能来保护数据。它还支持行级锁定。当在多用户环境中使用时，它的“一致非锁定读取”提高了性能。它将数据存储在集群索引中，从而减少了基于主键的查询的I/O。</p></blockquote></blockquote><blockquote><p>MyISAM</p><blockquote><p>该存储引擎管理非事务性表，提供高速存储和检索，支持全文搜索。</p></blockquote></blockquote><blockquote><p>MEMORY</p><blockquote><p>提供内存中的表，以前称为堆。它在RAM中处理所有数据，以便比在磁盘上存储数据更快地访问。用于快速查找引用和其他相同的数据。</p></blockquote></blockquote><h4 id="修改数据库引擎"><a href="#修改数据库引擎" class="headerlink" title="修改数据库引擎"></a>修改数据库引擎</h4><blockquote><p>方式壹：</p><blockquote><p>修改配置文件my.ini</p><p>将mysql.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=Innodb,重启服务，数据库默认的引擎修改为Innodb</p></blockquote></blockquote><blockquote><p>方式贰：</p><blockquote><p>在建表得时候指定</p><p>create table table_name(你的各个字段名)type=MyISAM;</p></blockquote></blockquote><blockquote><p>方式叁：</p><blockquote><p>建表后更改</p><p>alert table table_name type=Innodb;</p></blockquote></blockquote><h4 id="如何查看是否修改成功-查看当前数据库的引擎"><a href="#如何查看是否修改成功-查看当前数据库的引擎" class="headerlink" title="如何查看是否修改成功(查看当前数据库的引擎)"></a>如何查看是否修改成功(查看当前数据库的引擎)</h4><blockquote><p>方式壹：</p><blockquote><p>show table status from table_name;</p></blockquote></blockquote><blockquote><p>方拾贰：</p><blockquote><p>show create table table_name;</p></blockquote></blockquote><blockquote><p>方式叁：</p><blockquote><p>使用数据库管理工具(具体自己去问度娘)<br>注意：不同版本之间有可能命令有些不同</p></blockquote></blockquote><h4 id="MyISAM、InnoDB和MEMORY引擎之间的区别"><a href="#MyISAM、InnoDB和MEMORY引擎之间的区别" class="headerlink" title="MyISAM、InnoDB和MEMORY引擎之间的区别:"></a>MyISAM、InnoDB和MEMORY引擎之间的区别:</h4><blockquote><p>InnoDB存储引擎</p><blockquote><p>InnoDB给MySQL的表提供了事务处理、回滚、崩溃修复能力和多版本并发控制的事务安全。在MySQL从3.23.34a开始包含InnnoDB。它是MySQL上第一个提供外键约束的表引擎。而且InnoDB对事务处理的能力，也是其他存储引擎不能比拟的。靠后版本的MySQL的默认存储引擎就是InnoDB。</p><p>InnoDB存储引擎总支持AUTO_INCREMENT。自动增长列的值不能为空，并且值必须唯一。MySQL中规定自增列必须为主键。在插入值的时候，如果自动增长列不输入值，则插入的值为自动增长后的值；如果输入的值为0或空（NULL），则插入的值也是自动增长后的值；如果插入某个确定的值，且该值在前面没有出现过，就可以直接插入。</p><p>InnoDB还支持外键（FOREIGN KEY）。外键所在的表叫做子表，外键所依赖（REFERENCES）的表叫做父表。父表中被字表外键关联的字段必须为主键。当删除、更新父表中的某条信息时，子表也必须有相应的改变，这是数据库的参照完整性规则。</p><p>InnoDB中，创建的表的表结构存储在.frm文件中（我觉得是frame的缩写吧）。数据和索引存储在innodb_data_home_dir和innodb_data_file_path定义的表空间中。</p><p>InnoDB的优势在于提供了良好的事务处理、崩溃修复能力和并发控制。缺点是读写效率较差，占用的数据空间相对较大。</p></blockquote></blockquote><blockquote><p>MyISAM存储引擎</p><blockquote><p>MyISAM是MySQL中常见的存储引擎，曾经是MySQL的默认存储引擎。MyISAM是基于ISAM引擎发展起来的，增加了许多有用的扩展。</p><p>MyISAM的表存储成3个文件。文件的名字与表名相同。拓展名为frm、MYD、MYI。其实，frm文件存储表的结构；MYD文件存储数据，是MYData的缩写；MYI文件存储索引，是MYIndex的缩写。</p><p>基于MyISAM存储引擎的表支持3种不同的存储格式。包括静态型、动态型和压缩型。其中，静态型是MyISAM的默认存储格式，它的字段是固定长度的；动态型包含变长字段，记录的长度不是固定的；压缩型需要用到myisampack工具，占用的磁盘空间较小。</p><p>MyISAM的优势在于占用空间小，处理速度快。缺点是不支持事务的完整性和并发性。</p></blockquote></blockquote><blockquote><p>MEMORY存储引擎</p><blockquote><p>MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且数据全部放在内存中。这些特性与前面的两个很不同。</p><p>每个基于MEMORY存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为frm类型。该文件中只存储表的结构。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。值得注意的是，服务器需要有足够的内存来维持MEMORY存储引擎的表的使用。如果不需要了，可以释放内存，甚至删除不需要的表。</p><p>MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。</p><p>注意，MEMORY用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于MEMORY的表的生命周期很短，一般是一次性的</p></blockquote></blockquote><h4 id="怎样选择合理的存储引擎"><a href="#怎样选择合理的存储引擎" class="headerlink" title="怎样选择合理的存储引擎"></a>怎样选择合理的存储引擎</h4><blockquote><p>InnoDB：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的完整性要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要频繁的更新、删除操作的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）。</p><p>MyISAM：插入数据快，空间和内存使用比较低。如果表主要是用于插入新记录和读出记录，那么选择MyISAM能实现处理高效率。如果应用的完整性、并发性要求比 较低，也可以使用。</p><p>MEMORY：所有的数据都在内存中，数据的处理速度快，但是安全性不高。如果需要很快的读写速度，对数据的安全性要求较低，可以选择MEMOEY。它对表的大小有要求，不能建立太大的表。所以，这类数据库只使用在相对较小的数据库表。</p><p>注意，同一个数据库也可以使用多种存储引擎的表。如果一个表要求比较高的事务处理，可以选择InnoDB。这个数据库中可以将查询要求比较高的表选择MyISAM存储。如果该数据库需要一个用于查询的临时表，可以选择MEMORY存储引擎。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MySQL存储引擎如何选择&quot;&gt;&lt;a href=&quot;#MySQL存储引擎如何选择&quot; class=&quot;headerlink&quot; title=&quot;MySQL存储引擎如何选择&quot;&gt;&lt;/a&gt;MySQL存储引擎如何选择&lt;/h1&gt;&lt;h4 id=&quot;定义以及作用&quot;&gt;&lt;a href=&quot;#定义以及作用&quot; class=&quot;headerlink&quot; title=&quot;定义以及作用&quot;&gt;&lt;/a&gt;定义以及作用&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;数据库引擎是用于存储、处理和保护数据的核心服务。&lt;/p&gt;
&lt;p&gt;利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。&lt;/p&gt;
&lt;p&gt;使用数据库引擎创建用于联机(客户端与服务端能够实时通信。由客户机发起，直到服务器确认。)事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="MySQL 引擎" scheme="https://cy-blogs.cn/tags/MySQL-%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>MySQL MyISAM 引擎</title>
    <link href="https://cy-blogs.cn/MySQL%20MyISAM%E5%BC%95%E6%93%8E/"/>
    <id>https://cy-blogs.cn/MySQL MyISAM引擎/</id>
    <published>2019-12-24T11:09:28.848Z</published>
    <updated>2019-12-24T11:07:25.973Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL-MyISAM引擎"><a href="#MySQL-MyISAM引擎" class="headerlink" title="MySQL MyISAM引擎"></a>MySQL MyISAM引擎</h1><h4 id="MyISAM-介绍"><a href="#MyISAM-介绍" class="headerlink" title="MyISAM 介绍"></a>MyISAM 介绍</h4><blockquote><p>myisam引擎是MySQL关系数据库系统的默认储存引擎（mysql 5.5.5之前）。这种MySQL表存储结构从旧的ISAM代码扩展出许多有用的功能。在新版本的Mysql中，Innodb引擎由于其对事务参照完整性，以及更高的并发性等优点开始逐步取代Myisam引擎。<br>MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。</p><p>MySQL的MyISAM存储引擎支持压缩表空间，压缩后的表空间会减少，但是压缩后的表是只读的，不能插入和更新数据，如果需要更新，则需要解压后更新，再压缩 。</p><p>每一个myisam的表都对应于硬盘上的三个文件。这三个文件有一样的文件名，但是有不同的扩展名指示其类型用途：.frm文件保存表的定义，这个文件并不是myisam引擎的一部分，而是服务器的一部分；.MYD保存表的数据；.MYI是表的索引文件。.MYD和.MYI是MyISAM的关键点。</p></blockquote><a id="more"></a><h4 id="MyASAM-引擎的特点"><a href="#MyASAM-引擎的特点" class="headerlink" title="MyASAM 引擎的特点"></a>MyASAM 引擎的特点</h4><blockquote><p>1.不支持事务（事务是指逻辑上的一组操作，组成这组操作的各个单元，要么全成功要么全失败）<br>2.表级锁定，数据更新时锁定整个表：其锁定机制是表级锁定，这虽然可以让锁定的实现成本很小但是也同时大大降低了其并发性能。<br>3.读写互相阻塞：不仅会在写入的时候阻塞读取，myisam还会在读取的时候阻塞写入，但读本身并不会阻塞另外的读。<br>4.只会缓存索引：myisam可以通过key_buffer_size缓存索引，以大大提高访问性能，减少产品IO，但是这个缓存区只会缓存索引，而不会缓存数据。<br>key_buffer_size = 16M<br>5.读取速度较快，占用资源相对少。<br>6.不支持外键约束，但支持全文索引。</p></blockquote><h4 id="MyISAM-引攀适用的生产业务场景，"><a href="#MyISAM-引攀适用的生产业务场景，" class="headerlink" title="MyISAM 引攀适用的生产业务场景，"></a>MyISAM 引攀适用的生产业务场景，</h4><blockquote><p>1.不需要事务支持的业务（例如转账就不行）。<br>2.一般为读数据比较多的应用，读写都频繁场景不适合，读多或者写多的都适合。<br>3.读写并发访问相对较低的业务（纯读纯写高并发也可以）（锁定机制问题）<br>4.数据修改相对较少的业务（阻塞问题）。<br>5.以读为主的业务，例如：数据库系统表、www， blog ，图片信息数据库，用户数据库，商品库等业务。<br>6.对数据一致性要求不是非常高的业务（不支持事务）。<br>7.硬件资源比较差的机器可以用 MyiSAM （占用资源少）<br>8.使用读写分离的 MySQL 从库可以使用 MyISAM。</p></blockquote><blockquote><p>小结：单一对数据库的操作都可以使用MyiSAM，所谓单一就是尽量纯读，或纯写 ( insert . update , delete ）等</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MySQL-MyISAM引擎&quot;&gt;&lt;a href=&quot;#MySQL-MyISAM引擎&quot; class=&quot;headerlink&quot; title=&quot;MySQL MyISAM引擎&quot;&gt;&lt;/a&gt;MySQL MyISAM引擎&lt;/h1&gt;&lt;h4 id=&quot;MyISAM-介绍&quot;&gt;&lt;a href=&quot;#MyISAM-介绍&quot; class=&quot;headerlink&quot; title=&quot;MyISAM 介绍&quot;&gt;&lt;/a&gt;MyISAM 介绍&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;myisam引擎是MySQL关系数据库系统的默认储存引擎（mysql 5.5.5之前）。这种MySQL表存储结构从旧的ISAM代码扩展出许多有用的功能。在新版本的Mysql中，Innodb引擎由于其对事务参照完整性，以及更高的并发性等优点开始逐步取代Myisam引擎。&lt;br&gt;MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。&lt;/p&gt;
&lt;p&gt;MySQL的MyISAM存储引擎支持压缩表空间，压缩后的表空间会减少，但是压缩后的表是只读的，不能插入和更新数据，如果需要更新，则需要解压后更新，再压缩 。&lt;/p&gt;
&lt;p&gt;每一个myisam的表都对应于硬盘上的三个文件。这三个文件有一样的文件名，但是有不同的扩展名指示其类型用途：.frm文件保存表的定义，这个文件并不是myisam引擎的一部分，而是服务器的一部分；.MYD保存表的数据；.MYI是表的索引文件。.MYD和.MYI是MyISAM的关键点。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="MySQL 引擎" scheme="https://cy-blogs.cn/tags/MySQL-%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>MySQL MEMORY引擎</title>
    <link href="https://cy-blogs.cn/MySQL%20MEMORY%E5%BC%95%E6%93%8E/"/>
    <id>https://cy-blogs.cn/MySQL MEMORY引擎/</id>
    <published>2019-12-24T11:09:28.742Z</published>
    <updated>2019-12-24T11:06:58.135Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL-MEMORY引擎"><a href="#MySQL-MEMORY引擎" class="headerlink" title="MySQL MEMORY引擎"></a>MySQL MEMORY引擎</h1><h4 id="MEMORY-介绍"><a href="#MEMORY-介绍" class="headerlink" title="MEMORY 介绍"></a>MEMORY 介绍</h4><blockquote><p>MEMORY存储引擎创建的表数据只能保存在内存。</p><p>memoery存储引擎是在内存中来创建表，每个memory表只实际对应一个磁盘文件格式是.frm. 该引擎的表访问非常得快，因为数据是放在内存中，且默认是hash索引，但服务关闭，表中的数据就会丢失掉。</p><p>MySQL宕机、硬件故障或者意外掉电，都会造成MEMORY引擎表丢失数据。所以，MEMORY表中的数据来源于其他表(可落盘永久保存)用于只读适用，或者用于临时工作起到数据周转。</p><p>服务器需要足够的内存来维护所有在同一时间使用的memory表，当不再需要时，要释放，应执行 delete from 或 truncate table 或删除表drop table。</p><p>每个memory表放置的数据量大小，受到max_heap_table_size系统变量的约束，初始值是16MB. 通过max_rows 子句指定表的最大行数。</p></blockquote><a id="more"></a><h4 id="MEMORY-引擎的特点"><a href="#MEMORY-引擎的特点" class="headerlink" title="MEMORY 引擎的特点"></a>MEMORY 引擎的特点</h4><blockquote><p>memeory存储引擎使用hash索引对于等值查找是很高效的</p><p>比较容易丢失数据</p></blockquote><h4 id="MEMORY-引擎适用的生产业务场景"><a href="#MEMORY-引擎适用的生产业务场景" class="headerlink" title="MEMORY 引擎适用的生产业务场景"></a>MEMORY 引擎适用的生产业务场景</h4><blockquote><p>临时使用、不重要的数据，例如网站的会话管理和缓存。可接受数据丢失<br>可以用于存储在分析中产生的中间表<br>使用memroy存储引擎的表一定要是可以再生的或者是不需要的</p></blockquote><blockquote><p>小结：据保存在ram(内存)中，访问速度快，但对表的大小有限制，要确保数据是可以恢复的，常用于更新不太频繁的小表，用以快速访问。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MySQL-MEMORY引擎&quot;&gt;&lt;a href=&quot;#MySQL-MEMORY引擎&quot; class=&quot;headerlink&quot; title=&quot;MySQL MEMORY引擎&quot;&gt;&lt;/a&gt;MySQL MEMORY引擎&lt;/h1&gt;&lt;h4 id=&quot;MEMORY-介绍&quot;&gt;&lt;a href=&quot;#MEMORY-介绍&quot; class=&quot;headerlink&quot; title=&quot;MEMORY 介绍&quot;&gt;&lt;/a&gt;MEMORY 介绍&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;MEMORY存储引擎创建的表数据只能保存在内存。&lt;/p&gt;
&lt;p&gt;memoery存储引擎是在内存中来创建表，每个memory表只实际对应一个磁盘文件格式是.frm. 该引擎的表访问非常得快，因为数据是放在内存中，且默认是hash索引，但服务关闭，表中的数据就会丢失掉。&lt;/p&gt;
&lt;p&gt;MySQL宕机、硬件故障或者意外掉电，都会造成MEMORY引擎表丢失数据。所以，MEMORY表中的数据来源于其他表(可落盘永久保存)用于只读适用，或者用于临时工作起到数据周转。&lt;/p&gt;
&lt;p&gt;服务器需要足够的内存来维护所有在同一时间使用的memory表，当不再需要时，要释放，应执行 delete from 或 truncate table 或删除表drop table。&lt;/p&gt;
&lt;p&gt;每个memory表放置的数据量大小，受到max_heap_table_size系统变量的约束，初始值是16MB. 通过max_rows 子句指定表的最大行数。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="MySQL 引擎" scheme="https://cy-blogs.cn/tags/MySQL-%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>MySQL Innodb引擎</title>
    <link href="https://cy-blogs.cn/MySQL%20Innodb%E5%BC%95%E6%93%8E/"/>
    <id>https://cy-blogs.cn/MySQL Innodb引擎/</id>
    <published>2019-12-24T11:09:28.740Z</published>
    <updated>2019-12-24T11:07:02.641Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL-Innodb引擎"><a href="#MySQL-Innodb引擎" class="headerlink" title="MySQL Innodb引擎"></a>MySQL Innodb引擎</h1><h4 id="Innodb-介绍"><a href="#Innodb-介绍" class="headerlink" title="Innodb 介绍"></a>Innodb 介绍</h4><blockquote><p>InnoDB引擎的优点是支持兼容ACID的事务，以及参数完整性（即对外键的支持）。<br>Oracle公司2005年10月收购了Innovase；mysql5.5.5之后数据库的默认存储引擎为InnoDB</p></blockquote><a id="more"></a><h6 id="Innodb-的特点"><a href="#Innodb-的特点" class="headerlink" title="Innodb 的特点"></a>Innodb 的特点</h6><blockquote><p>1.支持事务，支持4个事务隔离级别，支持多版本读。<br>2.行级锁定（更新时一般是锁定当前行），通过索引实现，全表扫描仍然会是表锁，注意间隙锁的影响。<br>3.读写阻塞与事务隔离级别相关。<br>4.具有非常高效的缓存特性：能缓存索引，也能缓存数据。<br>5.整个表和主键以Cluster方式存储，组成一个平衡树。<br>6.所有Secondary Index都会保存主键信息。<br>7.支持分区，表空间，类似oracle数据库。<br>8.支持外键约束，5.5之前不支持全文索引，5.5之后支持外键索引。<br>9.和Myisam引擎比，Innodb对硬件资源要求比较高</p></blockquote><p>InnoDB:支持行级锁(row-level locking)和表级锁,默认为行级锁。</p><h6 id="Innodb-引擎适用的生产业务场景"><a href="#Innodb-引擎适用的生产业务场景" class="headerlink" title="Innodb 引擎适用的生产业务场景"></a>Innodb 引擎适用的生产业务场景</h6><blockquote><p>1、需要事务支持的业务（具有较好的事务特性）<br>2、行级锁定对高并发有很好的适应能力，但需要确保查询时通过索引完成。<br>3、数据读写及更新都较为频繁的场景，如：bbs，sns，微博，微信等。<br>4、数据一致性要求较高的业务，例如：充值转账，银行卡转账。<br>5、硬件设备内存较大，可以利用Innodb较好的缓存能力来提高内存利用率，尽可能减少磁盘IO。</p><p>innodb_buffer_pool_size = 2048M<br>innodb_buffer_pool_size = 64M #InnoDB使用一个缓冲池来保存索引和原始数据，设置越大，在存取表里面数据时所需要的磁盘I/O越少。强烈建议不要武断地将InnoDB的Buffer Pool值配置为物理内存的50%~80%，应根据具体环境而定。<br>16G内存多实例差不多给2G</p></blockquote><h4 id="Innodb存储引擎"><a href="#Innodb存储引擎" class="headerlink" title="Innodb存储引擎"></a>Innodb存储引擎</h4><blockquote><p>Innodb是事务型数据库的首选引，支持事物安全表(ACID)</p><blockquote><p>事务的ACID属性：即原子性、一致性、隔离性、持久性</p><blockquote><p>a.原子性：原子性也就是说这组语句要么全部执行，要么全部不执行，如果事务执行到一半出现错误，数据库就要回滚到事务开始执行的地方。</p></blockquote></blockquote></blockquote><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">实现：主要是基于MySQ日志系统的<span class="keyword">redo</span>和<span class="keyword">undo</span>机制。事务是一组SQL语句，里面有选择，查询、删除等功能。每条语句执行会有一个节点。例如，删除语句执行后，在事务中有个记录保存下来，这个记录中储存了我们什么时候做了什么事。如果出错了，就会回滚到原来的位置，<span class="keyword">redo</span>里面已经存储了我做过什么事了，然后逆向执行一遍就可以了。</span><br></pre></td></tr></table></figure><blockquote><blockquote><blockquote><p>b.一致性：事务开始前和结束后，数据库的完整性约束没有被破坏。(eg:比如A向B转账，不可能A扣了钱，B却没有收到)<br>c.隔离性：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰；</p></blockquote></blockquote></blockquote><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">如果不考虑隔离性则会出现几个问题：</span><br><span class="line">                                 a、脏读：是指在一个事务处理过程里读取了另一个未提交的事务中的数据（当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致）；（读取了另一个事务未提交的脏数据）</span><br><span class="line">                                 aa、不可重复读：在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了；（读取了前一个事务提交的数据，查询的都是同一个数据项）</span><br><span class="line">                                 aaa、虚读（幻读）：是事务非独立执行时发生的一种现象（eg:事务<span class="built_in">T1</span>对一个表中所有的行的某个数据项做了从“<span class="number">1</span>”修改为“<span class="number">2</span>”的操作，这时事务<span class="built_in">T2</span>又对这个表中插入了一行数据项，而这个数据项的数值还是为“<span class="number">1</span>”并且提交给数据库。而操作事务<span class="built_in">T1</span>的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务<span class="built_in">T2</span>中添加的，就好像产生幻觉一样）；（读取了前一个事务提交的数据，针对一批数据整体）</span><br></pre></td></tr></table></figure><blockquote><blockquote><blockquote><p>d.持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚</p></blockquote></blockquote></blockquote><h6 id="MySQL数据库为我们提供的四种隔离级别："><a href="#MySQL数据库为我们提供的四种隔离级别：" class="headerlink" title="MySQL数据库为我们提供的四种隔离级别："></a>MySQL数据库为我们提供的四种隔离级别：</h6><blockquote><p>1、Serializable（串行化）：可避免脏读、不可重复读、幻读的发生；</p><p>2、Repeatable read（可重复读）：可避免脏读、不可重复读的发生；</p><p>3、Read committed（读已提交）：可避免脏读的发生；</p><p>4、Read uncommitted（读未提交）：最低级别，任何情况都无法保证；</p><blockquote><p>从1—-4隔离级别由高到低，级别越高，执行效率越低</p></blockquote></blockquote><p>InnoDB的存储文件有两个，后缀名分别是 .frm和 .idb；其中 .frm是表的定义文件， .idb是表的数据文件。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MySQL-Innodb引擎&quot;&gt;&lt;a href=&quot;#MySQL-Innodb引擎&quot; class=&quot;headerlink&quot; title=&quot;MySQL Innodb引擎&quot;&gt;&lt;/a&gt;MySQL Innodb引擎&lt;/h1&gt;&lt;h4 id=&quot;Innodb-介绍&quot;&gt;&lt;a href=&quot;#Innodb-介绍&quot; class=&quot;headerlink&quot; title=&quot;Innodb 介绍&quot;&gt;&lt;/a&gt;Innodb 介绍&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;InnoDB引擎的优点是支持兼容ACID的事务，以及参数完整性（即对外键的支持）。&lt;br&gt;Oracle公司2005年10月收购了Innovase；mysql5.5.5之后数据库的默认存储引擎为InnoDB&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="MySQL 引擎" scheme="https://cy-blogs.cn/tags/MySQL-%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>使用xtrabackup备份mysql</title>
    <link href="https://cy-blogs.cn/%E4%BD%BF%E7%94%A8xtrabackup%E8%BF%9B%E8%A1%8C%E5%A4%87%E4%BB%BD/"/>
    <id>https://cy-blogs.cn/使用xtrabackup进行备份/</id>
    <published>2019-12-24T11:05:34.478Z</published>
    <updated>2019-12-24T11:05:29.298Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用xtrabackup备份mysql"><a href="#使用xtrabackup备份mysql" class="headerlink" title="使用xtrabackup备份mysql"></a>使用xtrabackup备份mysql</h1><h2 id="简介（Percona-XtraBackup-）简称PXB"><a href="#简介（Percona-XtraBackup-）简称PXB" class="headerlink" title="简介（Percona XtraBackup ）简称PXB"></a>简介（<a href="https://www.percona.com/software/mysql-database/percona-xtrabackup" target="_blank" rel="noopener">Percona XtraBackup</a> ）简称PXB</h2><blockquote><p>Xtrabackup是由percona开源的免费数据库热备份软件，它能对Innodb数据库和Xtradb存储引擎的数据库非阻塞地备份。（对于Myisam的备份同样需要加表锁），mysqldump备份方式是采用的逻辑备份，其最大的缺陷是备份和恢复速度较慢，如果数据库大于50G，mysqldump备份就不太适合。</p></blockquote><a id="more"></a><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>备份速度快，物理备份可靠</li><li>备份过程不会打断正在执行的事务（无需锁表）</li><li>能够基于压缩等功能节约磁盘空间和流量</li><li>自动备份校验</li><li>还原速度快</li><li>可以流传将备份传输到另一台机器上</li><li>在不增加服务器负载的情况下备份数据</li></ul><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><blockquote><p>​    备份开始的时候，首先会开启一个后台检测进程，实时检测mysql redo到的变化，一旦发现有新的日志写入，立刻将日志记入后台日志文件xtrabackup_log中，之后赋值innodb的数据文件，系统表空间文件ibdatax，复制后，将上锁（读锁），flush tables with read lock，让后复制.frm MYI MYD等文件，最后执行 unlock tables（释放锁），最终停止xtrabackup_log。</p></blockquote><p>​        <img src="http://mysql.taobao.org/monthly/pic/2016-03-07/PXB-backup-procedure.png" alt="image "></p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><blockquote><p>​    在innodb内部会维护一个redo日志文件，我们也可以叫做事务日志文    件，事务日志会存储每一个Innodb表数据的记录修改。当Innodb启动时，Innodb会检查数据文件和事务日志。并执行两个步骤：它应用（前滚）已经提交的事务日志到数据文件，并将修改过但没有提交的数据进行回滚操作。</p><p>​    xtrabackup在启动时会记住log    sequence number（LSN），并且复制所有数据文件，复制过程需要一些时间，所以这期间如果数据文件有改动，那么将会使数据库处于一个不同的时间点。这时，Xtrabackup会运行一个后台进程，用于监测事务日志，并从事务日志复制最新的修改。xtrabackup必须持续的做这个操作，因为事务日志是会轮转重复的写入，并且事务日志可以被重用。所以xtrabackup自启动开始，就不停的将事务日志中每个数据文件的修改都记录下来。这就是xtrabackup的备份过程。</p><p>​    接下来是准备（prepare）过程。在这个过程中，xtrabackup使用之前复制的事务日志。对各个数据文件执行灾难恢复（就像mysql刚启动时要做的一样）。当这个过程结束后，数据库就可以做恢复还原了。</p><p>​    整个过程就是-备份-》准备。先将文件全部复制过来，在根据事务日志对部分操作进行回滚。</p><p>​    程序innobbackupex可以允许我们备份Myisam表和文件从而增加了便捷和功能。</p><p>​    innobbackupex会启动xtrabackup，直到xtrabackup复制数据文件后，然后执行FLUSH TABLES WITH READ LOCK 来阻止新的写入刷新到磁盘上。之后复制Myisam数据文件。最后UNLOCK TABLES （释放锁）。</p><p>​    备份Myisam和Innodb表最终会处于一致，在准备（prepare）过程结束后，Innodb表数据已经前滚到整个备份结束点，而不是回滚到xtrabackup感刚开始的点。这个时间点与执行FLUSH TABLES WITH READ LOCK的时间点相同，所以Myisam表数据与Innodb表数据是同步的。</p></blockquote><h2 id="xtrabackup增量备份"><a href="#xtrabackup增量备份" class="headerlink" title="xtrabackup增量备份"></a>xtrabackup增量备份</h2><ul><li><p>原理</p><blockquote><p>​    首先是建立在完全备份的基础上，记录下此时的检查点LSN</p><p>​    在进行增量备份时，比较表空间中每个页的LSN是否大于上次备份的LSN，若是则备份该页并记录当前检查点的LSN。</p></blockquote></li><li><p>优点：</p><ul><li>数据库太大没有足够的空间全量备份，增量备份能有效节省空间，并且效率高</li><li>支持热备份，备份过程不锁表（针对Innodb而言），不阻塞数据库读写。</li><li>每日备份只产生少量数据，也可采用远程备份，节省本地空间</li><li>备份恢复基于文件操作，降低直接对数据库操作风险</li><li>备份效率更高，恢复效率更高。</li></ul></li></ul><h2 id="工具集"><a href="#工具集" class="headerlink" title="工具集"></a>工具集</h2><p>软件包安装完后一共有4个可执行文件，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">usr</span><br><span class="line">├── bin</span><br><span class="line">│   ├── innobackupex</span><br><span class="line">│   ├── xbcrypt  #用来加密或解密备份的数据</span><br><span class="line">│   ├── xbstream  #用来解压或压缩xbstream格式的文件</span><br><span class="line">│   └── xtrabackup</span><br></pre></td></tr></table></figure><p>其中最主要的是 <code>innobackupex</code> 和 <code>xtrabackup</code>，前者是一个 perl 脚本，后者是 C/C++ 编译的二进制。</p><p><code>xtrabackup</code> 是用来备份 InnoDB 表的，不能备份非 InnoDB 表，和 mysqld server 没有交互；<code>innobackupex</code> 脚本用来备份非 InnoDB 表，同时会调用 <code>xtrabackup</code> 命令来备份 InnoDB 表，还会和 mysqld server 发送命令进行交互，如加读锁（FTWRL）、获取位点（SHOW SLAVE STATUS）等。简单来说，<code>innobackupex</code> 在 <code>xtrabackup</code> 之上做了一层封装。</p><p>一般情况下，我们是希望能备份 MyISAM 表的，虽然我们可能自己不用 MyISAM 表，但是 mysql 库下的系统表是 MyISAM 的，因此备份基本都通过 <code>innobackupex</code> 命令进行；另外一个原因是我们可能需要保存位点信息。</p><p>另外2个工具相对小众些，<code>xbcrypt</code> 是加解密用的；<code>xbstream</code> 类似于tar，是 Percona 自己实现的一种支持并发写的流文件格式。两都在备份和解压时都会用到（如果备份用了加密和并发）。</p><p>本文的介绍的主角是 <code>innobackupex</code> 和 <code>xtrabackup</code>。</p><h2 id="下载"><a href="#下载" class="headerlink" title="下载##"></a>下载##</h2><ul><li><p>安装percona仓库</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm</span><br></pre></td></tr></table></figure></li><li><p>安装xtrabackup</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install percona-xtrabackup -y</span><br></pre></td></tr></table></figure></li><li><p>创建备份用户及设置权限（也可以直接使用root用户）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER ‘用户名’@'localhost' IDENTIFIED BY '密码';#创建</span><br><span class="line">GRANT RELOAD,LOCK TABLES,PROCESS,REPLICATION CLIENT ON *.* TO '用户名'@'localhost';#设置权限</span><br><span class="line">FLUSH PRIVILEGES;#刷新权限</span><br></pre></td></tr></table></figure></li><li><p>配置xtrabackup（可配置也可以已参数的形式写入）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim /root/.my.cnf</span><br><span class="line"></span><br><span class="line">[xtrabackup]</span><br><span class="line"></span><br><span class="line">user=创建的用户名</span><br><span class="line"></span><br><span class="line">password=密码</span><br></pre></td></tr></table></figure></li><li><p>创建备份使用的文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/backup/mysql</span><br></pre></td></tr></table></figure></li></ul><h2 id="基于xtrabackup的备份和恢复"><a href="#基于xtrabackup的备份和恢复" class="headerlink" title="基于xtrabackup的备份和恢复"></a>基于xtrabackup的备份和恢复</h2><ul><li><p><em>xtrabackup</em> 只支持innodb引擎和xtradb引擎</p></li><li><p>语法：</p><ul><li>–backup 表示该操作代表备份操作</li><li>–target-dir 指定备份文件的路径</li><li>–user 备份的用户 （设定配置文件后，无需指定）</li><li>–password  用户密码（同上）</li><li>–socket 指定socket启动文件路径（不添加使用默认路径）</li><li>–incremental-basedir  表示在某个全量备份的基础上进行增备</li></ul></li><li><p>全量备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# xtrabackup --backup --target-dir=/data/backup/mysql</span><br><span class="line"><span class="meta">#</span><span class="bash">以下是返回的结果</span></span><br><span class="line">191221 13:49:02  version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup' as 'backuper'  (using password: YES).</span><br><span class="line">191221 13:49:02  version_check Connected to MySQL server</span><br><span class="line">191221 13:49:02  version_check Executing a version check against the server...</span><br><span class="line">191221 13:49:02  version_check Done.</span><br><span class="line">191221 13:49:02 Connecting to MySQL server host: localhost, user: backuper, password: set, port: not set, socket: not set</span><br><span class="line">Using server version 5.5.64-MariaDB</span><br><span class="line">xtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)</span><br><span class="line">xtrabackup: uses posix_fadvise().</span><br><span class="line">xtrabackup: cd to /var/lib/mysql</span><br><span class="line">xtrabackup: open files limit requested 0, set to 65535</span><br><span class="line">xtrabackup: using the following InnoDB configuration:</span><br><span class="line"><span class="meta">#</span><span class="bash">省略.....</span></span><br><span class="line">MySQL binlog position: filename 'mysql-bin.000001', position '245'</span><br><span class="line">191221 13:49:03 [00] Writing backup-my.cnf</span><br><span class="line">191221 13:49:03 [00]        ...done</span><br><span class="line">191221 13:49:03 [00] Writing xtrabackup_info</span><br><span class="line">191221 13:49:03 [00]        ...done</span><br><span class="line">xtrabackup: Transaction log of lsn (8622624) to (8622624) was copied.</span><br><span class="line">191221 13:49:04 completed OK!#代表成功全量备份</span><br></pre></td></tr></table></figure></li><li><p>在全量备份的基础上进行增量备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">xtrabackup --backup --target-dir=/data/mysql/增量备份文件夹的名字（自定义）--incremental-basedir=/全量备份文件路径</span></span><br><span class="line">[root@ax mysql]# xtrabackup --backup --target-dir=/data/backup/mysql/mysql_increment1 --incremental-basedir=/data/backup/mysql</span><br><span class="line">191221 14:00:43  version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup' as 'backuper'  (using password: YES).</span><br><span class="line">191221 14:00:43  version_check Connected to MySQL server</span><br><span class="line">191221 14:00:43  version_check Executing a version check against the server...</span><br><span class="line">191221 14:00:43  version_check Done.</span><br><span class="line">191221 14:00:43 Connecting to MySQL server host: localhost, user: backuper, password: set, port: not set, socket: not set</span><br><span class="line">Using server version 5.5.64-MariaDB</span><br><span class="line">xtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)</span><br><span class="line">incremental backup from 8622624 is enabled.</span><br><span class="line">xtrabackup: uses posix_fadvise().</span><br><span class="line">xtrabackup: cd to /var/lib/mysql</span><br><span class="line">xtrabackup: open files limit requested 0, set to 65535</span><br><span class="line"><span class="meta">#</span><span class="bash">省略....</span></span><br><span class="line">xtrabackup: Stopping log copying thread.</span><br><span class="line">.191221 14:00:45 &gt;&gt; log scanned up to (8622624)</span><br><span class="line"></span><br><span class="line">191221 14:00:45 Executing UNLOCK TABLES</span><br><span class="line">191221 14:00:45 All tables unlocked</span><br><span class="line">191221 14:00:45 Backup created in directory '/data/backup/mysql/mysql_increment1/'</span><br><span class="line">MySQL binlog position: filename 'mysql-bin.000001', position '245'</span><br><span class="line">191221 14:00:45 [00] Writing backup-my.cnf</span><br><span class="line">191221 14:00:45 [00]        ...done</span><br><span class="line">191221 14:00:45 [00] Writing xtrabackup_info</span><br><span class="line">191221 14:00:45 [00]        ...done</span><br><span class="line">xtrabackup: Transaction log of lsn (8622624) to (8622624) was copied.</span><br><span class="line">191221 14:00:45 completed OK!#代表增量备份成功</span><br></pre></td></tr></table></figure></li><li><p>在增量备份的基础上继续增量备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在第一次增量备份后，以后的每一次增量备份都是以上一次增量备份为基准</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xtrabackup --backup --target-dir=增量备份文件路径 --incremental-basedir=上次增量备份的文件位置</span></span><br><span class="line">[root@ax ~]# xtrabackup --backup --target-dir=/data/backup/mysql_increment2 --incremental-basedir=/data/backup/mysql/mysql_increment1</span><br><span class="line">191221 18:39:28  version_check Connecting to MySQL server with DSN 'dbi:mysql:;mysql_read_default_group=xtrabackup' as 'backuper'  (using password: YES).</span><br><span class="line">191221 18:39:28  version_check Connected to MySQL server</span><br><span class="line">191221 18:39:28  version_check Executing a version check against the server...</span><br><span class="line">191221 18:39:28  version_check Done.</span><br><span class="line">191221 18:39:28 Connecting to MySQL server host: localhost, user: backuper, password: set, port: not set, socket: not set</span><br><span class="line">Using server version 5.5.64-MariaDB</span><br><span class="line">xtrabackup version 2.3.10 based on MySQL server 5.6.24 </span><br><span class="line"><span class="meta">#</span><span class="bash">省略...</span></span><br><span class="line">191221 18:39:32 Executing UNLOCK TABLES</span><br><span class="line">191221 18:39:32 All tables unlocked</span><br><span class="line">191221 18:39:32 Backup created in directory '/data/backup/mysql_increment2/'</span><br><span class="line">MySQL binlog position: filename 'mysql-bin.000001', position '245'</span><br><span class="line">191221 18:39:32 [00] Writing backup-my.cnf</span><br><span class="line">191221 18:39:32 [00]        ...done</span><br><span class="line">191221 18:39:32 [00] Writing xtrabackup_info</span><br><span class="line">191221 18:39:32 [00]        ...done</span><br><span class="line">xtrabackup: Transaction log of lsn (8622624) to (8622624) was copied.</span><br><span class="line">191221 18:39:32 completed OK!#代表成功</span><br></pre></td></tr></table></figure></li></ul><h2 id="使用xtrabackup恢复"><a href="#使用xtrabackup恢复" class="headerlink" title="使用xtrabackup恢复"></a>使用xtrabackup恢复</h2><ul><li><p>语法：</p><ul><li><p>xtrabackup –prepare –apply-log-only –target-dir=全量备份文件路径</p><ul><li>–prepare  表示还原</li><li>–apply-log-only 表示不回滚事务，因为后面有基于全备的增量备份，所以不需要回滚，如果没有增量备份则可以不添加。</li></ul></li><li><p>将第一次增量备份加载至全备中（增量备份多每次都要以上一次加载的备份文件为基准，命令相同，只需修改增量备份文件的路径即可。）</p></li><li><p>在加载最后一次的增量备份文件时，不需要添加–apply-log-only，因为增量备份都加载完成了，所以需要事务回滚。</p></li><li><p>如果恢复的是增量备份，需要先执行<code>xtrabackup --prepare --apply-log-only --target-dir=全量备份文件路径</code> 准备好全量基准</p></li><li><p>在全量备份准备好的基础上在将增量加载至全量备份 <code>xtrabackup --prepare --apply-log-only --target-dir=全量备份文件路径 --incremental-dir=增量备份文件路径</code></p></li><li><p>最后一次的增量加载至全量备份。不需要添加apply-log-only<code>xtrabackup --prepare  --target-dir=全量备份文件路径 --incremental-dir=增量备份文件路径</code> 这样就可以还原了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">xtrabackup --prepare --apply-log-only --target-dir=全量备份文件路径 --incremental-dir=增量备份文件路径</span></span><br><span class="line">[root@ax ~]# xtrabackup --prepare --apply-log-only --target-dir=/data/backup/mysql --incremental-dir=/data/backup/mysql_increment1</span><br><span class="line">xtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)</span><br><span class="line">incremental backup from 8622624 is enabled.</span><br><span class="line">xtrabackup: cd to /data/backup/mysql/</span><br><span class="line">xtrabackup: This target seems to be already </span><br><span class="line"><span class="meta">#</span><span class="bash">省略...</span></span><br><span class="line">191221 18:56:43 [01]        ...done</span><br><span class="line">191221 18:56:43 [01] Copying /data/backup/mysql_increment1/mysql/db.MYD to ./mysql/db.MYD</span><br><span class="line">191221 18:56:43 [01]        ...done</span><br><span class="line">191221 18:56:43 [00] Copying /data/backup/mysql_increment1//xtrabackup_binlog_info to ./xtrabackup_binlog_info</span><br><span class="line">191221 18:56:43 [00]        ...done</span><br><span class="line">191221 18:56:43 [00] Copying /data/backup/mysql_increment1//xtrabackup_info to ./xtrabackup_info</span><br><span class="line">191221 18:56:43 [00]        ...done</span><br><span class="line">191221 18:56:43 completed OK!#代表成功</span><br><span class="line"><span class="meta">#</span><span class="bash">最后一加载增量备份到全量备份</span></span><br><span class="line">[root@ax ~]# xtrabackup --prepare --target-dir=/data/backup/mysql --incremental-dir=/data/backup/mysql_increment2</span><br><span class="line"><span class="meta">#</span><span class="bash">返回也上面最后一行的结果代表成功</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>恢复</p><ul><li><p>停止mysql服务</p></li><li><p>清空mysql的数据目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MariaDB [(none)]&gt; show variables like &apos;datadir&apos;; #查询数据目录</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">| Variable_name | Value           |</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">| datadir       | /var/lib/mysql/ |</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line">#cd到指定目录 rm -rf ./*  这是模拟数据库损坏</span><br></pre></td></tr></table></figure></li><li><p>恢复 <code>xtrabackup --copy-back --target-dir=/data/backup/mysql</code>  –copy-back 将备份的数据目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@ax ~]# xtrabackup --copy-back --target-dir=/data/backup/mysql</span><br><span class="line">xtrabackup version 2.3.10 based on MySQL server 5.6.24 Linux (x86_64) (revision id: bd0d4403f36)</span><br><span class="line">191221 19:23:55 [01] Copying ib_logfile0 to /var/lib/mysql/ib_logfile0</span><br><span class="line">191221 19:23:55 [01]        ...done</span><br><span class="line">191221 19:23:55 [01] Copying ib_logfile1 to /var/lib/mysql/ib_logfile1</span><br><span class="line">191221 19:23:55 [01]        ...done</span><br><span class="line">191221 19:23:55 [01] Copying ibdata1 to /var/</span><br></pre></td></tr></table></figure></li><li><p>恢复后的数据目录下的文件及文件夹，用户数属于root的,mysql用户是没有权限使用的，所以需要重新赋予权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# ll</span><br><span class="line">total 36896</span><br><span class="line">drwx------ 2 root root     4096 Dec 21 19:23 exam</span><br><span class="line">-rw-r----- 1 root root 27262976 Dec 21 19:23 ibdata1</span><br><span class="line">-rw-r----- 1 root root  5242880 Dec 21 19:23 ib_logfile0</span><br><span class="line">-rw-r----- 1 root root  5242880 Dec 21 19:23 ib_logfile1</span><br><span class="line">drwx------ 2 root root     4096 Dec 21 19:23 mysql</span><br><span class="line">drwx------ 2 root root     4096 Dec 21 19:23 nextcloud</span><br><span class="line">drwx------ 2 root root     4096 Dec 21 19:23 performance_schema</span><br><span class="line">drwx------ 2 root root     4096 Dec 21 19:23 siyouyun</span><br><span class="line">drwx------ 2 root root     4096 Dec 21 19:23 text</span><br><span class="line">-rw-r----- 1 root root       23 Dec 21 19:23 xtrabackup_binlog_pos_innodb</span><br><span class="line">-rw-r----- 1 root root      548 Dec 21 19:23 xtrabackup_info</span><br><span class="line"><span class="meta">#</span><span class="bash">重新赋予权限，所属者和所属组改为mysql</span></span><br><span class="line">[root@ax mysql]# chown -R mysql:mysql ../mysql</span><br><span class="line">[root@ax mysql]# ll</span><br><span class="line">total 36896</span><br><span class="line">drwx------ 2 mysql mysql     4096 Dec 21 19:23 exam</span><br><span class="line">-rw-r----- 1 mysql mysql 27262976 Dec 21 19:23 ibdata1</span><br><span class="line">-rw-r----- 1 mysql mysql  5242880 Dec 21 19:23 ib_logfile0</span><br><span class="line">-rw-r----- 1 mysql mysql  5242880 Dec 21 19:23 ib_logfile1</span><br><span class="line">drwx------ 2 mysql mysql     4096 Dec 21 19:23 mysql</span><br><span class="line">drwx------ 2 mysql mysql     4096 Dec 21 19:23 nextcloud</span><br><span class="line">drwx------ 2 mysql mysql     4096 Dec 21 19:23 performance_schema</span><br><span class="line">drwx------ 2 mysql mysql     4096 Dec 21 19:23 siyouyun</span><br><span class="line">drwx------ 2 mysql mysql     4096 Dec 21 19:23 text</span><br><span class="line">-rw-r----- 1 mysql mysql       23 Dec 21 19:23 xtrabackup_binlog_pos_innodb</span><br><span class="line">-rw-r----- 1 mysql mysql      548 Dec 21 19:23 xtrabackup_info</span><br></pre></td></tr></table></figure></li><li><p>重新启动mysql服务查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# systemctl restart mariadb</span><br><span class="line">[root@ax mysql]# mysql -uroot -p</span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</span><br><span class="line">Your MariaDB connection id is 2</span><br><span class="line">Server version: 5.5.64-MariaDB MariaDB Server</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line"></span><br><span class="line">Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.</span><br><span class="line"></span><br><span class="line">MariaDB [(none)]&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| exam               |</span><br><span class="line">| mysql              |</span><br><span class="line">| nextcloud          |</span><br><span class="line">| performance_schema |</span><br><span class="line">| siyouyun           |</span><br><span class="line">| text               |</span><br><span class="line">+--------------------+</span><br><span class="line">7 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">MariaDB [(none)]&gt; </span><br><span class="line"><span class="meta">#</span><span class="bash">恢复成功</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>单表/单库备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">单表：xtrabackup --backup --datadir=数据目录路径 --tables='库名.表名' --target-dir=备份文件路径</span><br><span class="line"></span><br><span class="line">--tables:单引号中填写databases.tables</span><br><span class="line"></span><br><span class="line">单库：trabackup --backup  --databases=数据库名 --target-dir=备份文件路径 </span><br><span class="line">--databases:库名（database）</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ax ~]# xtrabackup --backup --datadir=/var/lib/mysql --target-dir=/data/backup/mysql --tables='exam.a1';</span><br><span class="line"><span class="meta">#</span><span class="bash">还原也需要进行事务回滚</span></span><br><span class="line">[root@ax exam]# xtrabackup --prepare --target-dir=单表或单库备份文件</span><br><span class="line"><span class="meta">#</span><span class="bash">停止数据库</span></span><br><span class="line"><span class="meta">#</span><span class="bash">数据目录中的原表删除，复制备份文件中单表或单库文件到数据目录</span></span><br><span class="line"><span class="meta">#</span><span class="bash">重置所属用户和组到mysql</span></span><br><span class="line"><span class="meta">#</span><span class="bash">重启数据库</span></span><br><span class="line"><span class="meta">#</span><span class="bash">成功</span></span><br></pre></td></tr></table></figure></li></ul><p>##使用innobackupex的备份与恢复</p><ul><li><p>innobackupex封装了xtrabackup，支持Myisam的数据表</p></li><li><p>innobackupex完整备份后生成的几个重要文件：</p><ul><li>记录当前最新的Log position</li><li>xtrabackup_binlog_pos_innodb:innodb log position</li><li>xtrabackup_checkpoints:存放备份的起始LSN（beginlsn），和结束的位置LSN（endlsn）</li><li>增量备份需要上次备份的endlsn</li></ul></li><li><p>innobackupex命令相当于冷备份，复制数据目录的索引，数据结构文件，为保证数据一致，需要短暂的锁表（时间的长短依赖于Myisam表的大小。）</p></li><li><p>参数解释（同样适用于xtrabackup）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--defaults-file：指定my.cnf参数文件的位置[此配置文件里必须指定datadir]</span></span><br><span class="line"><span class="comment">#--apply-log：同xtrabackup的--prepare参数,一般情况下,在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据 文件仍处理不一致状态。--apply-log的作用是通过回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性状态。</span></span><br><span class="line"><span class="comment">#--copy-back：做数据恢复时将备份数据文件拷贝到MySQL服务器的datadir</span></span><br><span class="line"><span class="comment">#--remote-host=HOSTNAME： 通过ssh将备份数据存储到进程服务器上</span></span><br><span class="line"><span class="comment">#--stream=[tar]：备份文件输出格式, 该文件可在XtarBackup binary文件中获得. 在使用参数stream=tar备份的时候,你的xtrabackup_logfile可能会临时放在/tmp目录下,如果你备份的时候并发写入较大的话,xtrabackup_logfile可能会很大(5G+),很可能会撑满你的/tmp目录,可以通过参数--tmpdir指定目录来解决这个问题.</span></span><br><span class="line"><span class="comment">#--tmpdir=DIRECTORY：当有指定--remote-host or --stream时, 事务日志临时存储的目录, 默认采用MySQL配置文件中所指定的临时目录tmpdir</span></span><br><span class="line"><span class="comment">#--redo-only --apply-log：强制备份日志时只redo,跳过rollback,这在做增量备份时非常必要</span></span><br><span class="line"><span class="comment">#--use-memory=*：该参数在prepare的时候使用,控制prepare时innodb实例使用的内存</span></span><br><span class="line"><span class="comment">#--databases=LIST：列出需要备份的databases,如果没有指定该参数,所有包含MyISAM和InnoDB表的database都会被备份</span></span><br><span class="line"><span class="comment">#--slave-info：备份从库, 加上--slave-info备份目录下会多生成一个xtrabackup_slave_info 文件, 这里会保存主日志文件以及偏移, 文件内容类似于:CHANGE MASTER TO MASTER_LOG_FILE='', MASTER_LOG_POS=0</span></span><br><span class="line"><span class="comment">#--socket=SOCKET：指定mysql.sock所在位置，以便备份进程登录mysql.</span></span><br></pre></td></tr></table></figure></li><li><p>全量备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ax backup]# innobackupex --user=备份账户 --password=密码 备份文件存储路径</span><br><span class="line">191223 10:08:18 innobackupex: Starting the backup operation</span><br><span class="line"></span><br><span class="line">IMPORTANT: Please check that the backup run completes successfully.</span><br><span class="line">           At the end of a successful backup run innobackupex</span><br><span class="line">           prints "completed OK!".</span><br><span class="line"><span class="meta">#</span><span class="bash">省略...</span></span><br><span class="line">191223 10:08:20 completed OK!#代表成功</span><br></pre></td></tr></table></figure></li><li><p>全量恢复</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">执行innobackupex --apply-log --use-memory=size（可加可不加） 备份文件路径    这一步是准备操作。apply-only在上面介绍过。</span></span><br><span class="line">[root@ax backup]# innobackupex --apply-only --use-memory=4G /data/backup/2019-12-23_10-08-18</span><br><span class="line">191223 10:16:02 innobackupex: Starting the backup operation</span><br><span class="line"></span><br><span class="line">IMPORTANT: Please check that the backup run completes successfully.</span><br><span class="line">           At the end of a successful backup run innobackupex</span><br><span class="line">           prints "completed OK!".</span><br><span class="line"><span class="meta">#</span><span class="bash">省略...</span></span><br><span class="line">191223 10:16:04 completed OK!#代表成功</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">接下来是恢复</span></span><br><span class="line"><span class="meta">#</span><span class="bash">关闭mysql服务,模拟数据库损坏，清空数据目录（不清空会报错）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">执行 innobackupex --copy-back 备份文件路径</span></span><br><span class="line"><span class="meta">#</span><span class="bash">给予mysql数据目录下所有文件的操作权限</span></span><br><span class="line"><span class="meta">#</span><span class="bash">启动mysql</span></span><br></pre></td></tr></table></figure></li><li><p>增量备份（所有的增量备份都是在全量备份的基础上进行的）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">执行 innobackupex --incremental 指定增量文件存储路径 --incremental-basedir=第一次是全量备份的文件路径/在增量的备份的基础上继续增量这里就需要填写上次增量备份文件的路径</span></span><br><span class="line">[root@ax backup]# innobackupex --incremental /data/backup/ --incremental-basedir=/data/backup/2019-12-23_11-25-13/</span><br><span class="line">xtrabackup: Transaction log of lsn (8626208) to (8626208) was copied.</span><br><span class="line">191223 11:34:20 completed OK!#代表成功</span><br></pre></td></tr></table></figure></li><li><p>恢复：（将各个增量备份的数据文件合并到全量备份的目录下，最终是从全量备份的这个目录上进行恢复的）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">准备工作</span></span><br><span class="line"><span class="meta">#</span><span class="bash">innobackupex --apply-log --redo-only 全被文件路径</span></span><br><span class="line"><span class="meta">#</span><span class="bash">innobackupex --apply-log --redo-only 全备路径 --incremental-dir=第一次增备路径</span></span><br><span class="line"><span class="meta">#</span><span class="bash">innobackupex --apply-log --redo-only 全备文件路径 --incremental-dir=第二次增备路径 <span class="comment">#多次增备执行多次</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">innobackupex --apply-log 全备路径 --incremental-dir=最后一次增备路径 最后一次不需要填加--redo-only参数</span></span><br><span class="line"><span class="meta">#</span><span class="bash">恢复</span></span><br><span class="line"><span class="meta">#</span><span class="bash">关闭mysql服务,模拟数据库损坏，清空数据目录（不清空会报错）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">innobackupex --copy-back 全量备份路径 </span></span><br><span class="line"><span class="meta">#</span><span class="bash">给予mysql数据目录下所有文件的操作权限</span></span><br><span class="line"><span class="meta">#</span><span class="bash">启动mysql</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;使用xtrabackup备份mysql&quot;&gt;&lt;a href=&quot;#使用xtrabackup备份mysql&quot; class=&quot;headerlink&quot; title=&quot;使用xtrabackup备份mysql&quot;&gt;&lt;/a&gt;使用xtrabackup备份mysql&lt;/h1&gt;&lt;h2 id=&quot;简介（Percona-XtraBackup-）简称PXB&quot;&gt;&lt;a href=&quot;#简介（Percona-XtraBackup-）简称PXB&quot; class=&quot;headerlink&quot; title=&quot;简介（Percona XtraBackup ）简称PXB&quot;&gt;&lt;/a&gt;简介（&lt;a href=&quot;https://www.percona.com/software/mysql-database/percona-xtrabackup&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Percona XtraBackup&lt;/a&gt; ）简称PXB&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Xtrabackup是由percona开源的免费数据库热备份软件，它能对Innodb数据库和Xtradb存储引擎的数据库非阻塞地备份。（对于Myisam的备份同样需要加表锁），mysqldump备份方式是采用的逻辑备份，其最大的缺陷是备份和恢复速度较慢，如果数据库大于50G，mysqldump备份就不太适合。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="使用xtrabackup备份mysql" scheme="https://cy-blogs.cn/tags/%E4%BD%BF%E7%94%A8xtrabackup%E5%A4%87%E4%BB%BDmysql/"/>
    
  </entry>
  
  <entry>
    <title>Redis 事务、乐观锁、分布式锁、信号量</title>
    <link href="https://cy-blogs.cn/redis%E4%BA%8B%E5%8A%A1%EF%BC%8C%E4%B9%90%E8%A7%82%E9%94%81%EF%BC%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%8C%E4%BF%A1%E5%8F%B7%E9%87%8F/"/>
    <id>https://cy-blogs.cn/redis事务，乐观锁，分布式锁，信号量/</id>
    <published>2019-12-24T06:34:30.367Z</published>
    <updated>2019-12-24T10:45:41.773Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h1><blockquote><p>Redis是一款内存高速缓存数据库，该软件使用C语言编写，</p><p>Redis是一个key - value 存储系统，它支持丰富的数据类型，</p><p>如：String、List、Set、Hash。</p><p>是为了解决高并发、高扩展，大数据存储等问题！</p></blockquote><a id="more"></a><ul><li>读写效率高，持久化、丰富的特性</li></ul><blockquote><p>读写效率高：读写速度最高可达 <code>10万次/s+</code>。</p><p>持久化：断电或重启后，数据也不会丢失。因为 Redis 的存储分为内存存储、磁盘存储和 log 文件三部分，中启后，Redis可以从磁盘将数据加载到内存中。</p><p>丰富的特性：建空间、事务、订阅发布功能、计数。</p></blockquote><h2 id="Redis-事务"><a href="#Redis-事务" class="headerlink" title="Redis 事务"></a>Redis 事务</h2><ul><li><p>回顾Mysql 数据库事务</p><ul><li>什么是事务，事务是原子操作，里面的操作，要么都成功，要么都不成功。</li></ul></li><li><p>原子性</p><ul><li>整个事务的操作，要么都成功，要么都不成功，如果在执行的过程中，发生了错误，就回滚到开始的状态。</li></ul></li><li><p>一致性</p><ul><li>在事务的开始前，和结束后，数据的完整性约束，没有被破坏。</li></ul></li><li><p>隔离性</p><ul><li>使得同一时间，只有一个请求同一数据。</li></ul></li><li><p>持久性</p><ul><li>事务成功之后，对数据库的操作会，永远的保存在数据库当中。</li></ul></li><li><p><strong>Redsi</strong>事务</p><blockquote><p>Redis 事务的本质：</p><p>​        是将一组操作放入队列中，批量执行，过程中如果产生了某个命令错误，不会回滚，其他正确的命令，仍然会继续执行</p></blockquote></li><li><p>与 mysql 对比</p><ul><li><p>redis 是  ：</p><p>​    开始事务   multi（）</p><p>​    提交事务  execute（）</p><p>​    放弃事务  reset（）</p></li></ul></li></ul><h3 id="什么时候用到锁"><a href="#什么时候用到锁" class="headerlink" title="什么时候用到锁"></a>什么时候用到锁</h3><ul><li>锁的生命周期<ul><li>任务通过竞争获取锁才能对资源进行操作 （竞争锁）</li><li>当任务在对资源进行操作时！（占有锁）</li><li>其它任务都不可以对这个资源操作 （任务阻塞）</li><li>直到该任务完成更新 （释放锁）</li></ul></li></ul><h3 id="redis-乐观锁的使用"><a href="#redis-乐观锁的使用" class="headerlink" title="redis 乐观锁的使用"></a>redis 乐观锁的使用</h3><ul><li><p>乐观锁：</p><blockquote><p>每次去拿数据的时候都任务别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去跟新这个数据</p></blockquote></li><li><p>redis 中的乐观锁：</p><blockquote><p>可以使用 watch（）方法来实现，可以监控一个或多个键，再事务执行的过程中，其中的一个键发生了改变，那么这个事务，就不会执行</p></blockquote></li></ul><h3 id="redis-实现分布式锁"><a href="#redis-实现分布式锁" class="headerlink" title="redis 实现分布式锁"></a>redis 实现分布式锁</h3><ul><li><p>什么是分布式锁：</p><blockquote><p>控制分布式系统有序的去对共享资源进行操作，通过互斥来保持一致性。</p></blockquote><p><a href="https://v.qq.com/x/page/n3026r8xhil.html" target="_blank" rel="noopener">https://v.qq.com/x/page/n3026r8xhil.html</a></p></li><li><p>SETNX（）</p><blockquote><p>这个命令会在键不存在的情况下为键设置值，如果存在的情况下则不作任何操作！</p></blockquote></li><li><p>获取锁</p><blockquote><p>如果程序在尝试获取锁的过程中失败，那么他将不断的进行重试，直到成功的取到锁，或者超过锁的过期时间</p></blockquote></li><li><p>删除锁</p><blockquote><p>删除锁之前会先判断，是否是该线程加的锁，如果是，则执行delete 进行删除。</p></blockquote></li></ul><h3 id="分布式锁应该具备哪些条件"><a href="#分布式锁应该具备哪些条件" class="headerlink" title="分布式锁应该具备哪些条件"></a>分布式锁应该具备哪些条件</h3><ul><li>互斥性，在任意时刻，只有一个客户端能持有锁</li><li>高可用的获取锁和释放锁</li><li>具备锁失效机制，避免死锁</li><li>具备非阻塞锁特性，即没有获取到锁直接返回获取锁失败</li><li>释放锁</li></ul><h3 id="计数信号量"><a href="#计数信号量" class="headerlink" title="计数信号量"></a>计数信号量</h3><blockquote><p>何为计数信号量？<br>简单来说就是控制对共享资源的访问。<br>实现方法： Semaphore （）<br>Semaphore 是一个计数信号量。<br>常用于限制可以访问某些资源的线程数量</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Redis简介&quot;&gt;&lt;a href=&quot;#Redis简介&quot; class=&quot;headerlink&quot; title=&quot;Redis简介&quot;&gt;&lt;/a&gt;Redis简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Redis是一款内存高速缓存数据库，该软件使用C语言编写，&lt;/p&gt;
&lt;p&gt;Redis是一个key - value 存储系统，它支持丰富的数据类型，&lt;/p&gt;
&lt;p&gt;如：String、List、Set、Hash。&lt;/p&gt;
&lt;p&gt;是为了解决高并发、高扩展，大数据存储等问题！&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="https://cy-blogs.cn/categories/Redis/"/>
    
    
      <category term="Redis 事务、乐观锁、分布式锁、信号量" scheme="https://cy-blogs.cn/tags/Redis-%E4%BA%8B%E5%8A%A1%E3%80%81%E4%B9%90%E8%A7%82%E9%94%81%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%81%E4%BF%A1%E5%8F%B7%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>MYSQL定时备份任务shell脚本</title>
    <link href="https://cy-blogs.cn/Mysql%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BDshell%E8%84%9A%E6%9C%AC/"/>
    <id>https://cy-blogs.cn/Mysql定时备份shell脚本/</id>
    <published>2019-12-23T11:42:53.388Z</published>
    <updated>2019-12-24T11:05:07.582Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MYSQL定时备份任务shell脚本"><a href="#MYSQL定时备份任务shell脚本" class="headerlink" title="MYSQL定时备份任务shell脚本"></a>MYSQL定时备份任务shell脚本</h1><h2 id="备份的必要性"><a href="#备份的必要性" class="headerlink" title="备份的必要性"></a>备份的必要性</h2><ul><li>每个公司的业务都是基于数据进行的，数据的存储基本都是数据库</li><li>保证了数据的安全，稳定，也就可以做到防范于未然。</li></ul><h2 id="冷备和热备"><a href="#冷备和热备" class="headerlink" title="冷备和热备"></a>冷备和热备</h2><a id="more"></a><ul><li>冷备份：(读写均不可进行)<ul><li>冷备份，off，快，时间点上恢复</li><li>冷备份发生在数据库已经正常关闭的情况下，当正常关闭时会提供给我们一个完整的数据库，冷备份是将关键性文件拷贝的另外位置的一种说法，对于备份数据库信息而言，冷备份是最快和最安全的方法。</li><li>冷备份的优点：<ul><li>低度维护，安全</li><li>容易归档，拷贝文件</li><li>速度快</li><li>恢复简单</li></ul></li><li>冷备份的缺点：<ul><li>不能按表或按用户恢复</li><li>若磁盘空间有限，只能拷贝到磁带等其他外部存储设备上，速度会很慢。</li><li>恢复限制，在备份期间，数据库不能做写入操作。</li></ul></li></ul></li><li>热备份：（读写皆可进行）<ul><li>在数据库运行时，直接进行备份，对运行的数据库没有影响。</li><li>热备份的优点：<ul><li>可在表空间或数据文件级备份，备份时间段。</li><li>灵活，备份时不影响数据库的使用。</li><li>秒级恢复，能够恢复到某一时间点上。</li></ul></li><li>热备份的缺点：<ul><li>严谨性，尽量不要出错，否则后果很严重。</li><li>维护困难</li></ul></li></ul></li><li>温备：（只能读，不可写）<ul><li>上锁（考虑持锁的长久）<h2 id="MYSQL备份数据的几种方式"><a href="#MYSQL备份数据的几种方式" class="headerlink" title="MYSQL备份数据的几种方式"></a>MYSQL备份数据的几种方式</h2></li></ul></li></ul><h3 id="into-outfile"><a href="#into-outfile" class="headerlink" title="into outfile"></a>into outfile</h3><ul><li><p>利用<code>select语句 into outfile table +指定的路径</code> 实现指定表数据的备份 备份完的文件是文本文件</p><ul><li><p>在使用<code>select into outfile</code> 使用默认的用户是mysql在操作，使用<code>show variables like &#39;datadir&#39;</code>会显示所属mysql用户的文件件具有一切权限</p></li><li><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MariaDB [exam]&gt; show variables like 'datadir';</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">| Variable_name | Value           |</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">| datadir       | /var/lib/mysql/ |</span><br><span class="line">+---------------+-----------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></li><li><p>指定路径可以直接放在mysql所属的文件夹下</p></li><li><p>如果指定文件备份位置，会报错<code>ERROR 1 (HY000): Can&#39;t create/write to file &#39;/data/test.txt&#39; (Errcode: 13)</code> 这是代表mysql没有文件目录的操作权限。</p><ul><li>解决办法 <ul><li>直接更改文件目录的所属用户为mysql让mysql拥有一切权限，<code>clown mysql:mysql +指定文件夹的路径</code></li><li>修改文件夹其它用户可以有写的权限。(不建议)</li><li>先备份至mysql所属文件夹内 进行mv</li></ul></li></ul></li><li><p>可以使用<code>load data infile +备份完数据的路径 into table +表名</code> 进行恢复。</p></li></ul></li></ul><h3 id="mysqldump"><a href="#mysqldump" class="headerlink" title="mysqldump"></a>mysqldump</h3><ul><li><p>mysqldump 常用来做温备 （所以需要先对备份的数据施加锁，只能读不能写）本质上就是将指定数据库中的数据已sql语句的方式输出 使用重定向到指定的文件</p></li><li><p>施加读锁的方式：</p><ul><li>flush tables with read lock 施加锁，表示把位于内存上的表统统都同步到磁盘上，然后去施加读锁。</li><li>unlock tables 释放锁。</li></ul></li><li><p>全量备份</p><ul><li><p>使用mysqldump工具进行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# mysqldump -uroot -pxieyang --single-transaction --master-data=2 --databases 表名 &gt;/data/mysql/a1_`date +%F`.sql</span><br></pre></td></tr></table></figure><ul><li>–single-transaction 通过在一个事务中导出所有表从而创建一个一致性的快照，（只支持innodb，myisam不支持事务），从而有效的保证了dump文件，即正确的表内容和二进制日志位置。</li><li>–master-data=2 选项开启式默认会打开lock-all-tables 一个是加锁，一个是获取log信息 =1和=2的在于log信息前者不注释，后者注释。</li><li>lock-all-tables 在dump执行的时候会在表上加上读锁，保证数据一致性，innodb不需加上此参数，而使用 –single-tansaction</li><li>–all-databases  导出所有的数据库 也可以指定表名</li></ul></li><li><p>恢复</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# mysql -uroot -p &lt; 备份文件路径/备份文件名</span><br></pre></td></tr></table></figure></li></ul></li><li><p>增量备份</p><ul><li><p>使用mysqlbinlog工具进行，本质上就是指定备份文件的log开始偏移量和结束日志的偏移量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# mysqlbinlog --start-position=3210 /var/lib/mysql/mysql-bin.000009 &gt; /data/mysql/a1_2019-12-19_17.sql</span><br></pre></td></tr></table></figure><ul><li><p>–start-position=开始的偏移量</p></li><li><p>–stop-position=结束的偏移量</p></li><li><p>可以先使用<code>show master status</code> 来查看日志版本</p></li><li><p>通过find / -name 日志版本名来查找到路径</p></li><li><p>使用<code>mysqlbinlog --start-position=上次同步的结束位置 查询到的路径</code> 来查看需要同步的结束偏移量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@ax mysql]# mysqlbinlog --start-position=0 /var/lib/mysql/mysql-bin.000010</span><br><span class="line">SET TIMESTAMP=1576755138/*!*/;</span><br><span class="line">insert into a1 values (4,'赵六'),(5,'冯七')</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="meta">#</span><span class="bash"> at 423</span></span><br><span class="line"><span class="meta">#</span><span class="bash">191219 19:32:18 server id 1  end_log_pos 450 Xid = 919</span></span><br><span class="line">COMMIT/*!*/;</span><br><span class="line"><span class="meta">#</span><span class="bash"> at 450</span></span><br><span class="line"><span class="meta">#</span><span class="bash">191219 19:32:32 server id 1  end_log_pos 531 Querythread_id=334exec_time=0error_code=0</span></span><br><span class="line">SET TIMESTAMP=1576755152/*!*/;</span><br><span class="line">drop database exam</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="meta">#</span><span class="bash"> at 531</span></span><br><span class="line"><span class="meta">#</span><span class="bash">191219 19:50:53 server id 1  end_log_pos 574 Rotate to mysql-bin.000011  pos: 4</span></span><br><span class="line">DELIMITER ;</span><br><span class="line"><span class="meta">#</span><span class="bash"> End of <span class="built_in">log</span> file</span></span><br><span class="line">ROLLBACK /* added by mysqlbinlog */;</span><br><span class="line">/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;</span><br><span class="line">/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;</span><br></pre></td></tr></table></figure></li><li><p>其中end_log_pos就是结束的偏移量</p></li><li><p>或者直接使用<code>show master status</code> 中查询出来的偏移量，备份到操作该库的最后一次位置</p></li></ul></li><li><p>恢复，和全量恢复是相同的  </p><ul><li>[root@ax mysql]# mysql -uroot -p &lt; 备份文件路径/增量备份名备份文件名</li><li>恢复前先关闭二进制日志 <code>set sql_log_bin=0</code></li><li>滚动日志 <code>flush logs</code></li></ul></li></ul></li></ul><h3 id="利用lvm快照备份和恢复"><a href="#利用lvm快照备份和恢复" class="headerlink" title="利用lvm快照备份和恢复"></a>利用lvm快照备份和恢复</h3><ul><li>LVM（Logical Volume Manager）是一个应用于Linux的内核的逻辑卷管理器，是Linux环境下对磁盘进行分区管理的一种机制。相关名词：<ul><li>PV（物理卷）可以是一个磁盘，一个分区。由PE（物理盘区）组成，多个PV可以组成一个VG（卷组）<ul><li>VG（卷组）多个物理卷组成的一个组，卷组不可以直接使用，需要在上面创建LV（逻辑卷）才可以使用。VG上可以创建多个LV。</li><li>PE（物理盘区），默认是4MB,像磁盘的block块</li><li>LV（逻辑卷）是建立在卷组之上的一个可用空间，有物理边界和逻辑边界两种边界。</li></ul></li></ul></li><li>LVM扩展<ul><li><a href="https://www.jb51.net/LINUXjishu/105937.html" target="_blank" rel="noopener">连接</a></li><li>LVM是一种将一个或多个硬盘的分区在逻辑上的集合，相当于一个大硬盘来使用，当空间不够使用时，可以继续将其它硬盘的分区加入其中，这样可以实现一种磁盘空间的动态管理，相对于普通的磁盘分区有很大的灵活性，使用普通的磁盘分区，当一个磁盘的分区空间不够使用的时候，可能就会带来很大的麻烦，使用LVM在一定程度就可以解决普通磁盘分区带来的问题。LVM通常用于装备大量磁盘的系统，但他它同样适于仅有一，两块硬盘的小系统。</li></ul></li></ul><h3 id="Mysql定时备份shell脚本"><a href="#Mysql定时备份shell脚本" class="headerlink" title="Mysql定时备份shell脚本"></a>Mysql定时备份shell脚本</h3><ul><li><p>利用的都是mysqldump，利用Crontab设置定时任务，来自动执行备份命令。直接上代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 以下配置信息请自己修改</span></span><br><span class="line">mysql_user="root" #MySQL备份用户</span><br><span class="line">mysql_password="password" #MySQL备份用户的密码</span><br><span class="line">mysql_host="localhost"</span><br><span class="line">mysql_port="3306"</span><br><span class="line">mysql_charset="utf8" #MySQL编码</span><br><span class="line">backup_db_arr=("db1" "db2") #要备份的数据库名称，多个用空格分开隔开 如("db1" "db2" "db3")</span><br><span class="line">backup_location=/data/mysql #备份数据存放位置，末尾请不要带"/",此项可以保持默认，程序会自动创建文件夹</span><br><span class="line">expire_backup_delete="ON" #是否开启过期备份删除 ON为开启 OFF为关闭</span><br><span class="line">expire_days=3 #过期时间天数 默认为三天，此项只有在expire_backup_delete开启时有效</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 本行开始以下不需要修改</span></span><br><span class="line">backup_time=`date +%F:%T` #定义备份详细时间</span><br><span class="line">backup_Ymd=`date +%Y-%m-%d` #定义备份目录中的年月日时间</span><br><span class="line">backup_3ago=`date -d '3 days ago' +%Y-%m-%d` #3天之前的日期</span><br><span class="line">backup_dir=$backup_location/$backup_Ymd #备份文件夹全路径</span><br><span class="line">welcome_msg="Welcome to use MySQL backup tools!" #欢迎语</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 判断MYSQL是否启动,mysql没有启动则备份退出</span></span><br><span class="line">mysql_ps=`ps -ef |grep mysql |wc -l`</span><br><span class="line">mysql_listen=`netstat -an |grep LISTEN |grep $mysql_port|wc -l`</span><br><span class="line">if [ [$mysql_ps == 0] -o [$mysql_listen == 0] ]; then</span><br><span class="line">echo "`date +%F:%T` --ERROR:MySQL is not running! backup stop!"</span><br><span class="line">exit</span><br><span class="line">else</span><br><span class="line">echo "备份时间-- `date +%F:%T`"</span><br><span class="line">echo `date +%F:%T` -- $welcome_msg</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 连接到mysql数据库，无法连接则备份退出</span></span><br><span class="line">mysql -h$mysql_host -P$mysql_port -u$mysql_user -p$mysql_password &lt;&lt;end</span><br><span class="line">use mysql;</span><br><span class="line">select host,user from user where user='root' and host='localhost';</span><br><span class="line">exit</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">flag=`echo $?`</span><br><span class="line">if [ $flag != "0" ]; then</span><br><span class="line">echo "`date +%F:%T` --ERROR:Can't connect mysql server! backup stop!"</span><br><span class="line">exit</span><br><span class="line">else</span><br><span class="line">echo "`date +%F:%T` --MySQL connect ok! Please wait......"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 判断有没有定义备份的数据库，如果定义则开始备份，否则退出备份</span></span><br><span class="line">if [ "$backup_db_arr" != "" ];then</span><br><span class="line"><span class="meta">#</span><span class="bash">dbnames=$(cut -d <span class="string">','</span> -f1-5 <span class="variable">$backup_database</span>)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">echo</span> <span class="string">"arr is (<span class="variable">$&#123;backup_db_arr[@]&#125;</span>)"</span></span></span><br><span class="line">for dbname in $&#123;backup_db_arr[@]&#125;</span><br><span class="line">do</span><br><span class="line">echo "`date +%F:%T` --database $dbname backup start..."</span><br><span class="line">`mkdir -p $backup_dir`</span><br><span class="line">`mysqldump -h$mysql_host -P$mysql_port -u$mysql_user -p$mysql_password $dbname --default-character-set=$mysql_charset | gzip &gt; $backup_dir/$dbname-$backup_time.sql.gz`</span><br><span class="line">flag=`echo $?`</span><br><span class="line">if [ $flag == "0" ];then</span><br><span class="line">echo "`date +%F:%T` --database $dbname success backup to $backup_dir/$dbname-$backup_time.sql.gz"</span><br><span class="line">else</span><br><span class="line">echo "`date +%F:%T` --database $dbname backup fail!"</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">else</span><br><span class="line">echo "`date +%F:%T` --ERROR:No database to backup! backup stop"</span><br><span class="line">exit</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果开启了删除过期备份，则进行删除操作</span></span><br><span class="line">if [ "$expire_backup_delete" == "ON" -a "$backup_location" != "" ];then</span><br><span class="line"><span class="meta">#</span><span class="bash">`find <span class="variable">$backup_location</span>/ -<span class="built_in">type</span> d -o -<span class="built_in">type</span> f -ctime +<span class="variable">$expire_days</span> -<span class="built_in">exec</span> rm -rf &#123;&#125; \;`</span></span><br><span class="line">`find $backup_location/ -type d -mtime +$expire_days | xargs rm -rf`</span><br><span class="line">echo "`date +%F:%T` --Expired backup data delete complete!"</span><br><span class="line">fi</span><br><span class="line">echo "`date +%F:%T` --All database backup success! Thank you!"</span><br><span class="line">echo ""</span><br><span class="line">exit</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>在非linux界面下操作，sh脚本中每行都会多个\r，导致linux无法执行脚本。解决办法，使用vim编辑shell脚本文件，执行::set ff=unix。文件即使unix文件了。可以使用::set ff? 查看文件的类型。dos就是在ATOM操作后保存的文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fileformat=unix </span><br><span class="line">fileformat=dos</span><br></pre></td></tr></table></figure></li><li><p>文件的创建默认UGO权限为 -rw-r–r– 代表的这个文件没有执行权限，所以需要给文件增加权限。</p><ul><li><p>文件创建者拥有所有权限，用户组和其他组只有执行权限</p><p><code>chmod 711 备份文件</code></p></li><li><p>r=4 w=2 x=1 </p></li></ul></li><li><p>拥有了执行权限后，该shell脚本就可以执行了，可以执行一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@ax auto_backup]# ./Backup.sh </span><br><span class="line">备份时间-- 2019-12-20:17:09:40</span><br><span class="line">2019-12-20:17:09:40 -- Welcome to use MySQL backup tools!</span><br><span class="line">hostuser</span><br><span class="line">localhostroot</span><br><span class="line">2019-12-20:17:09:40 --MySQL connect ok! Please wait......</span><br><span class="line">2019-12-20:17:09:40 --database exam backup start...</span><br><span class="line">2019-12-20:17:09:40 --database exam success backup to /data/mysql/2019-12-20/exam-2019-12-20:17:09:40.sql.gz</span><br><span class="line">2019-12-20:17:09:40 --database shiyouyun backup start...</span><br><span class="line">mysqldump: Got error: 1049: "Unknown database 'shiyouyun'" when selecting the database</span><br><span class="line">2019-12-20:17:09:40 --database shiyouyun success backup to /data/mysql/2019-12-20/shiyouyun-2019-12-20:17:09:40.sql.gz</span><br><span class="line">2019-12-20:17:09:40 --Expired backup data delete complete!</span><br><span class="line">2019-12-20:17:09:40 --All database backup success! Thank you!</span><br></pre></td></tr></table></figure></li><li><p>执行成功说明shell没有问题，只剩下写入定时任务了</p></li></ul><h4 id="Crontab"><a href="#Crontab" class="headerlink" title="Crontab"></a>Crontab</h4><ul><li><p>linux下使用crontab命令来提交和管理用户需要定时、周期性的执行任务。</p></li><li><p>linux下默认会安装此服务工具，并且会自动启动crond进程，crond进程会每分钟定期检查是否有要执行的任务。如果有要执行的任务，则自动执行该任务。</p></li><li><p>命令语法：</p><ul><li>crontab（选项） （参数）</li><li>选项：<ul><li>-e  编辑该用户的计时设置</li><li>-l   列出该用户的计时器设置</li><li>-r   删除该用户的计时器设置</li><li>-u   用户名称   指定要设定计时器的用户名称</li></ul></li><li>参数：<ul><li>crontab文件   指定包含待执行任务的crontab文件</li></ul></li></ul></li><li><p>直接在/etc/crontab文件中添加shell脚本任务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">00 3 * * * root /data/auto_backup/Backup.sh &gt;&gt; /data/mysql/backup.log</span><br></pre></td></tr></table></figure><ul><li>上面代表每天在凌晨3点运行Backup.sh脚本 并将输出重定向追加到backup.log文件中。</li><li>从左往右依次代表<ul><li>分 可取0-59的整数 加/数字 代表每分钟执行多少次</li><li>时 可取0-23的整数  </li><li>天  可取1-31的整数 ，必须是指定月份的有效日期</li><li>月 可取1-12的整数，也可写英文简写</li><li>周几 可取1-7的整数，描述周几</li><li>执行的用户  指定用户</li><li>shell脚本的路径</li><li>log日志的路径</li></ul></li></ul></li><li><p>添加完后保存，重启crond服务。一切ok</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>ax mysql]# ls</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>  backup.log</span><br><span class="line">[<span class="symbol">root@</span>ax mysql]# cd <span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>/</span><br><span class="line">[<span class="symbol">root@</span>ax <span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>]# ls</span><br><span class="line">exam<span class="number">-201912201600.</span>sql.gz  exam<span class="number">-201912201613.</span>sql.gz         exam<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01.</span>sql.gz  shiyouyun<span class="number">-201912201608.</span>sql.gz  shiyouyun<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">21</span>:<span class="number">01.</span>sql.gz</span><br><span class="line">exam<span class="number">-201912201601.</span>sql.gz  exam<span class="number">-201912201614.</span>sql.gz         exam<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">32</span>:<span class="number">01.</span>sql.gz  shiyouyun<span class="number">-201912201609.</span>sql.gz  shiyouyun<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">22</span>:<span class="number">01.</span>sql.gz</span><br><span class="line">[<span class="symbol">root@</span>ax mysql]# cat backup.log </span><br><span class="line">备份时间-- <span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span></span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> -- Welcome to use MySQL backup tools!</span><br><span class="line">hostuser</span><br><span class="line">localhostroot</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --MySQL connect ok! Please wait......</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --database exam backup start...</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --database exam success backup to /data/mysql/<span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>/exam<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01.</span>sql.gz</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --database shiyouyun backup start...</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --database shiyouyun success backup to /data/mysql/<span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>/shiyouyun<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01.</span>sql.gz</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --Expired backup data delete complete!</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">30</span>:<span class="number">01</span> --All database backup success! Thank you!</span><br><span class="line"></span><br><span class="line">备份时间-- <span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span></span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> -- Welcome to use MySQL backup tools!</span><br><span class="line">hostuser</span><br><span class="line">localhostroot</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --MySQL connect ok! Please wait......</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --database exam backup start...</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --database exam success backup to /data/mysql/<span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>/exam<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01.</span>sql.gz</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --database shiyouyun backup start...</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --database shiyouyun success backup to /data/mysql/<span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>/shiyouyun<span class="number">-2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01.</span>sql.gz</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --Expired backup data delete complete!</span><br><span class="line"><span class="number">2019</span><span class="number">-12</span><span class="number">-20</span>:<span class="number">16</span>:<span class="number">31</span>:<span class="number">01</span> --All database backup success! Thank you!</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MYSQL定时备份任务shell脚本&quot;&gt;&lt;a href=&quot;#MYSQL定时备份任务shell脚本&quot; class=&quot;headerlink&quot; title=&quot;MYSQL定时备份任务shell脚本&quot;&gt;&lt;/a&gt;MYSQL定时备份任务shell脚本&lt;/h1&gt;&lt;h2 id=&quot;备份的必要性&quot;&gt;&lt;a href=&quot;#备份的必要性&quot; class=&quot;headerlink&quot; title=&quot;备份的必要性&quot;&gt;&lt;/a&gt;备份的必要性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;每个公司的业务都是基于数据进行的，数据的存储基本都是数据库&lt;/li&gt;
&lt;li&gt;保证了数据的安全，稳定，也就可以做到防范于未然。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;冷备和热备&quot;&gt;&lt;a href=&quot;#冷备和热备&quot; class=&quot;headerlink&quot; title=&quot;冷备和热备&quot;&gt;&lt;/a&gt;冷备和热备&lt;/h2&gt;
    
    </summary>
    
    
      <category term="MYSQL" scheme="https://cy-blogs.cn/categories/MYSQL/"/>
    
    
      <category term="MYSQL定时备份任务shell脚本" scheme="https://cy-blogs.cn/tags/MYSQL%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%E4%BB%BB%E5%8A%A1shell%E8%84%9A%E6%9C%AC/"/>
    
  </entry>
  
  <entry>
    <title>Redis 持久化之RDB和AOF</title>
    <link href="https://cy-blogs.cn/redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>https://cy-blogs.cn/redis持久化/</id>
    <published>2019-12-23T09:16:38.222Z</published>
    <updated>2019-12-23T09:12:42.252Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-持久化之RDB和AOF"><a href="#Redis-持久化之RDB和AOF" class="headerlink" title="Redis 持久化之RDB和AOF"></a>Redis 持久化之RDB和AOF</h1><p>Redis 有两种持久化方案，RDB （Redis DataBase）和 AOF （Append Only File）。如果你想快速了解和使用RDB和AOF，可以直接跳到文章底部看总结。本章节通过配置文件，触发快照的方式，恢复数据的操作，命令操作演示，优缺点来学习 Redis 的重点知识<strong>持久化</strong>。</p><a id="more"></a><h2 id="RDB-详解"><a href="#RDB-详解" class="headerlink" title="RDB 详解"></a>RDB 详解</h2><p>RDB 是 Redis 默认的持久化方案。在指定的时间间隔内，执行指定次数的写操作，则会将内存中的数据写入到磁盘中。即在指定目录下生成一个dump.rdb文件。Redis 重启会通过加载dump.rdb文件恢复数据。</p><h3 id="从配置文件了解RDB"><a href="#从配置文件了解RDB" class="headerlink" title="从配置文件了解RDB"></a>从配置文件了解RDB</h3><p>打开 redis.conf 文件，找到 SNAPSHOTTING 对应内容<br>1 RDB核心规则配置（重点）</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line"># save <span class="string">""</span></span><br><span class="line">save <span class="number">900</span> <span class="number">1</span></span><br><span class="line">save <span class="number">300</span> <span class="number">10</span></span><br><span class="line">save <span class="number">60</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure><p>解说：save &lt;指定时间间隔&gt; &lt;执行指定次数更新操作&gt;，满足条件就将内存中的数据同步到硬盘中。官方出厂配置默认是 900秒内有1个更 改，300秒内有10个更改以及60秒内有10000个更改，则将内存中的数据快照写入磁盘。<br>若不想用RDB方案，可以把 save “” 的注释打开，下面三个注释。</p><p>2 指定本地数据库文件名，一般采用默认的 dump.rdb</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">dbfilename</span> <span class="selector-tag">dump</span><span class="selector-class">.rdb</span></span><br></pre></td></tr></table></figure><p>3 指定本地数据库存放目录，一般也用默认配置</p><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">dir</span> ./</span><br></pre></td></tr></table></figure><p>4 默认开启数据压缩</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">rdbcompression</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure><p>解说：配置存储至本地数据库时是否压缩数据，默认为yes。Redis采用LZF压缩方式，但占用了一点CPU的时间。若关闭该选项，但会导致数据库文件变的巨大。建议开启。</p><h3 id="触发RDB快照"><a href="#触发RDB快照" class="headerlink" title="触发RDB快照"></a>触发RDB快照</h3><p>1 在指定的时间间隔内，执行指定次数的写操作<br>2 执行save（阻塞， 只管保存快照，其他的等待） 或者是bgsave （异步）命令<br>3 执行flushall 命令，清空数据库所有数据，意义不大。<br>4 执行shutdown 命令，保证服务器正常关闭且不丢失任何数据，意义…也不大。</p><h3 id="通过RDB文件恢复数据"><a href="#通过RDB文件恢复数据" class="headerlink" title="通过RDB文件恢复数据"></a>通过RDB文件恢复数据</h3><p>将dump.rdb 文件拷贝到redis的安装目录的bin目录下，重启redis服务即可。在实际开发中，一般会考虑到物理机硬盘损坏情况，选择备份dump.rdb 。可以从下面的操作演示中可以体会到。</p><h3 id="RDB-的优缺点"><a href="#RDB-的优缺点" class="headerlink" title="RDB 的优缺点"></a>RDB 的优缺点</h3><p>优点：<br>1 适合大规模的数据恢复。<br>2 如果业务对数据完整性和一致性要求不高，RDB是很好的选择。</p><p>缺点：<br>1 数据的完整性和一致性不高，因为RDB可能在最后一次备份时宕机了。<br>2 备份时占用内存，因为Redis 在备份时会独立创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍哦），最后再将临时文件替换之前的备份文件。<br>所以Redis 的持久化和数据的恢复要选择在夜深人静的时候执行是比较合理的。</p><h3 id="操作演示"><a href="#操作演示" class="headerlink" title="操作演示"></a>操作演示</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@itdragon bin]<span class="comment"># vim redis.conf</span></span><br><span class="line">save <span class="number">900</span> <span class="number">1</span></span><br><span class="line">save <span class="number">120</span> <span class="number">5</span></span><br><span class="line">save <span class="number">60</span> <span class="number">10000</span></span><br><span class="line">[root@itdragon bin]<span class="comment"># ./redis-server redis.conf</span></span><br><span class="line">[root@itdragon bin]<span class="comment"># ./redis-cli -h 127.0.0.1 -p 6379</span></span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> keys *</span><br><span class="line">(empty list <span class="keyword">or</span> set)</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> set key1 value1</span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> set key2 value2</span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> set key3 value3</span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> set key4 value4</span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> set key5 value5</span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> set key6 value6</span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> SHUTDOWN</span><br><span class="line"><span class="keyword">not</span> connected&gt; QUIT</span><br><span class="line">[root@itdragon bin]<span class="comment"># cp dump.rdb dump_bk.rdb</span></span><br><span class="line">[root@itdragon bin]<span class="comment"># ./redis-server redis.conf</span></span><br><span class="line">[root@itdragon bin]<span class="comment"># ./redis-cli -h 127.0.0.1 -p 6379</span></span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> FLUSHALL </span><br><span class="line">OK</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> keys *</span><br><span class="line">(empty list <span class="keyword">or</span> set)</span><br><span class="line"><span class="meta">127.0.0.1:6379&gt;</span> SHUTDOWN</span><br><span class="line"><span class="keyword">not</span> connected&gt; QUIT</span><br><span class="line">[root@itdragon bin]<span class="comment"># cp dump_bk.rdb  dump.rdb</span></span><br><span class="line"><span class="symbol">cp:</span> overwrite <span class="string">`dump.rdb'? y</span></span><br><span class="line"><span class="string">[root@itdragon bin]# ./redis-server redis.conf</span></span><br><span class="line"><span class="string">[root@itdragon bin]# ./redis-cli -h 127.0.0.1 -p 6379</span></span><br><span class="line"><span class="string">127.0.0.1:6379&gt; keys *</span></span><br><span class="line"><span class="string">1) "key5"</span></span><br><span class="line"><span class="string">2) "key1"</span></span><br><span class="line"><span class="string">3) "key3"</span></span><br><span class="line"><span class="string">4) "key4"</span></span><br><span class="line"><span class="string">5) "key6"</span></span><br><span class="line"><span class="string">6) "key2"</span></span><br></pre></td></tr></table></figure><p>第一步：vim 修改持久化配置时间，120秒内修改5次则持久化一次。<br>第二步：重启服务使配置生效。<br>第三步：分别set 5个key，过两分钟后，在bin的当前目录下会自动生产一个dump.rdb文件。（set key6 是为了验证shutdown有触发RDB快照的作用）<br>第四步：将当前的dump.rdb 备份一份（模拟线上工作）。<br>第五步：执行FLUSHALL命令清空数据库数据（模拟数据丢失）。<br>第六步：重启Redis服务，恢复数据…..咦？？？？( ′◔ ‸◔`)。数据是空的？？？？这是因为FLUSHALL也有触发RDB快照的功能。<br>第七步：将备份的 dump_bk.rdb 替换 dump.rdb 然后重新Redis。</p><p>注意点：SHUTDOWN 和 FLUSHALL 命令都会触发RDB快照，这是一个坑，请大家注意。</p><p>其他命令：</p><ul><li>keys * 匹配数据库中所有 key</li><li>save 阻塞触发RDB快照，使其备份数据</li><li>FLUSHALL 清空整个 Redis 服务器的数据(几乎不用)</li><li>SHUTDOWN 关机走人（很少用）</li></ul><hr><h2 id="AOF-详解"><a href="#AOF-详解" class="headerlink" title="AOF 详解"></a>AOF 详解</h2><p>AOF ：Redis 默认不开启。它的出现是为了弥补RDB的不足（数据的不一致性），所以它采用日志的形式来记录每个<strong>写操作</strong>，并<strong>追加</strong>到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。</p><h3 id="从配置文件了解AOF"><a href="#从配置文件了解AOF" class="headerlink" title="从配置文件了解AOF"></a>从配置文件了解AOF</h3><p>打开 redis.conf 文件，找到 APPEND ONLY MODE 对应内容<br>1 redis 默认关闭，开启需要手动把no改为yes</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">appendonly</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure><p>2 指定本地数据库文件名，默认值为 appendonly.aof</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">appendfilename</span> <span class="string">"appendonly.aof"</span></span><br></pre></td></tr></table></figure><p>3 指定更新日志条件</p><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># appendfsync always</span></span><br><span class="line">appendfsync everysec</span><br><span class="line"><span class="meta"># appendfsync no</span></span><br></pre></td></tr></table></figure><p>解说：<br>always：同步持久化，每次发生数据变化会立刻写入到磁盘中。性能较差当数据完整性比较好（慢，安全）<br>everysec：出厂默认推荐，每秒异步记录一次（默认值）<br>no：不同步</p><p>4 配置重写触发机制</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">auto</span>-aof-rewrite-percentage <span class="number">100</span></span><br><span class="line"><span class="built_in">auto</span>-aof-rewrite-min-size <span class="number">64</span>mb</span><br></pre></td></tr></table></figure><p>解说：当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。一般都设置为3G，64M太小了。</p><h3 id="触发AOF快照"><a href="#触发AOF快照" class="headerlink" title="触发AOF快照"></a>触发AOF快照</h3><p>根据配置文件触发，可以是每次执行触发，可以是每秒触发，可以不同步。</p><h3 id="根据AOF文件恢复数据"><a href="#根据AOF文件恢复数据" class="headerlink" title="根据AOF文件恢复数据"></a>根据AOF文件恢复数据</h3><p>正常情况下，将appendonly.aof 文件拷贝到redis的安装目录的bin目录下，重启redis服务即可。但在实际开发中，可能因为某些原因导致appendonly.aof 文件格式异常，从而导致数据还原失败，可以通过命令redis-check-aof –fix appendonly.aof 进行修复 。从下面的操作演示中体会。</p><h3 id="AOF的重写机制"><a href="#AOF的重写机制" class="headerlink" title="AOF的重写机制"></a>AOF的重写机制</h3><p>前面也说到了，AOF的工作原理是将写操作追加到文件中，文件的冗余内容会越来越多。所以聪明的 Redis 新增了重写机制。当AOF文件的大小超过所设定的阈值时，Redis就会对AOF文件的内容压缩。</p><p>重写的原理：Redis 会fork出一条新进程，读取内存中的数据，并重新写到一个临时文件中。并没有读取旧文件（你都那么大了，我还去读你？？？ o(ﾟДﾟ)っ傻啊！）。最后替换旧的aof文件。</p><p>触发机制：当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。这里的“一倍”和“64M” 可以通过配置文件修改。</p><h3 id="AOF-的优缺点"><a href="#AOF-的优缺点" class="headerlink" title="AOF 的优缺点"></a>AOF 的优缺点</h3><p>优点：数据的完整性和一致性更高<br>缺点：因为AOF记录的内容多，文件会越来越大，数据恢复也会越来越慢。</p><h3 id="操作演示-1"><a href="#操作演示-1" class="headerlink" title="操作演示"></a>操作演示</h3><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[<span class="symbol">root@</span>itdragon bin]# vim appendonly.aof</span><br><span class="line">appendonly yes</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-server redis.conf</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-cli -h <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> -p <span class="number">6379</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; keys *</span><br><span class="line">(empty list <span class="keyword">or</span> <span class="keyword">set</span>)</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; <span class="keyword">set</span> keyAOf valueAof</span><br><span class="line">OK</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; FLUSHALL </span><br><span class="line">OK</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; SHUTDOWN</span><br><span class="line"><span class="keyword">not</span> connected&gt; QUIT</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-server redis.conf</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-cli -h <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> -p <span class="number">6379</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; keys *</span><br><span class="line"><span class="number">1</span>) <span class="string">"keyAOf"</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; SHUTDOWN</span><br><span class="line"><span class="keyword">not</span> connected&gt; QUIT</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# vim appendonly.aof</span><br><span class="line">fjewofjwojfoewifjowejfwf</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-server redis.conf</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-cli -h <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> -p <span class="number">6379</span></span><br><span class="line">Could <span class="keyword">not</span> connect to Redis at <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>: Connection <span class="built_in">ref</span>used</span><br><span class="line"><span class="keyword">not</span> connected&gt; QUIT</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# redis-check-aof --fix appendonly.aof </span><br><span class="line"><span class="string">'x              3e: Expected prefix '</span>*<span class="string">', got: '</span></span><br><span class="line">AOF analyzed: size=<span class="number">92</span>, ok_up_to=<span class="number">62</span>, diff=<span class="number">30</span></span><br><span class="line">This will shrink the AOF <span class="keyword">from</span> <span class="number">92</span> bytes, with <span class="number">30</span> bytes, to <span class="number">62</span> bytes</span><br><span class="line">Continue? [y/N]: y</span><br><span class="line">Successfully truncated AOF</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-server redis.conf</span><br><span class="line">[<span class="symbol">root@</span>itdragon bin]# ./redis-cli -h <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> -p <span class="number">6379</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; keys *</span><br><span class="line"><span class="number">1</span>) <span class="string">"keyAOf"</span></span><br></pre></td></tr></table></figure><p>第一步：修改配置文件，开启AOF持久化配置。<br>第二步：重启Redis服务，并进入Redis 自带的客户端中。<br>第三步：保存值，然后模拟数据丢失，关闭Redis服务。<br>第四步：重启服务，发现数据恢复了。（额外提一点：有教程显示FLUSHALL 命令会被写入AOF文件中，导致数据恢复失败。我安装的是redis-4.0.2没有遇到这个问题）。<br>第五步：修改appendonly.aof，模拟文件异常情况。<br>第六步：重启 Redis 服务失败。这同时也说明了，RDB和AOF可以同时存在，且优先加载AOF文件。<br>第七步：校验appendonly.aof 文件。重启Redis 服务后正常。</p><p>补充点：aof 的校验是通过 redis-check-aof 文件，那么rdb 的校验是不是可以通过 redis-check-rdb 文件呢？？？</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>Redis 默认开启RDB持久化方式，在指定的时间间隔内，执行指定次数的写操作，则将内存中的数据写入到磁盘中。</li><li>RDB 持久化适合大规模的数据恢复但它的数据一致性和完整性较差。</li><li>Redis 需要手动开启AOF持久化方式，默认是每秒将写操作日志追加到AOF文件中。</li><li>AOF 的数据完整性比RDB高，但记录内容多了，会影响数据恢复的效率。</li><li>Redis 针对 AOF文件大的问题，提供重写的瘦身机制。</li><li>若只打算用Redis 做缓存，可以关闭持久化。</li><li>若打算使用Redis 的持久化。建议RDB和AOF都开启。其实RDB更适合做数据的备份，留一后手。AOF出问题了，还有RDB。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Redis-持久化之RDB和AOF&quot;&gt;&lt;a href=&quot;#Redis-持久化之RDB和AOF&quot; class=&quot;headerlink&quot; title=&quot;Redis 持久化之RDB和AOF&quot;&gt;&lt;/a&gt;Redis 持久化之RDB和AOF&lt;/h1&gt;&lt;p&gt;Redis 有两种持久化方案，RDB （Redis DataBase）和 AOF （Append Only File）。如果你想快速了解和使用RDB和AOF，可以直接跳到文章底部看总结。本章节通过配置文件，触发快照的方式，恢复数据的操作，命令操作演示，优缺点来学习 Redis 的重点知识&lt;strong&gt;持久化&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="https://cy-blogs.cn/categories/Redis/"/>
    
    
      <category term="Redis 持久化之RDB和AOF" scheme="https://cy-blogs.cn/tags/Redis-%E6%8C%81%E4%B9%85%E5%8C%96%E4%B9%8BRDB%E5%92%8CAOF/"/>
    
  </entry>
  
  <entry>
    <title>Redis 发布者与订阅者,键空间事件</title>
    <link href="https://cy-blogs.cn/Redis%E5%8F%91%E5%B8%83%E8%80%85%E4%B8%8E%E8%AE%A2%E9%98%85%E8%80%85%EF%BC%8C%E9%94%AE%E7%A9%BA%E9%97%B4%E4%BA%8B%E4%BB%B6/"/>
    <id>https://cy-blogs.cn/Redis发布者与订阅者，键空间事件/</id>
    <published>2019-12-21T08:26:57.446Z</published>
    <updated>2019-12-23T09:16:15.755Z</updated>
    
    <content type="html"><![CDATA[<h2 id="发布者与订阅者（pub-sub）"><a href="#发布者与订阅者（pub-sub）" class="headerlink" title="发布者与订阅者（pub/sub）"></a>发布者与订阅者（pub/sub）</h2><p>发布和订阅<code>pub/sub</code>，订阅者负责订阅频道，发送者负责像频道发送二进制字符串消息，每当有消息发布到订阅的这个频道，那么所有的订阅者都可以收到这个消息，发布订阅也是像是我们生活中的电台，订阅者可以订阅收听多个电台，而发送者可以再任何电台发送消息</p><a id="more"></a><h3 id="发布，订阅常用命令"><a href="#发布，订阅常用命令" class="headerlink" title="发布，订阅常用命令"></a>发布，订阅常用命令</h3><table><thead><tr><th>指令</th><th>解释</th></tr></thead><tbody><tr><td>SUBSCRIBE CHANNLE</td><td>订阅给定的一个或多个频道</td></tr><tr><td>UNSUBSCRIBE CHANNLE</td><td>退订一个或多个频道，如果没有指定具体退订的频道，那么是全部退订</td></tr><tr><td>PSUBSCRIBE PATTERN</td><td>订阅与给定模式相匹配的所有频道</td></tr><tr><td>PUNSUBSCRIBE PATTERN</td><td>退订给定的模式相匹配的频道，未指定，则退订所有</td></tr><tr><td>PUBLISH CHANNLE MESSAGE</td><td>向给定频道发送消息</td></tr></tbody></table><h2 id="键空间事件"><a href="#键空间事件" class="headerlink" title="键空间事件"></a>键空间事件</h2><h3 id="键空间事件通知"><a href="#键空间事件通知" class="headerlink" title="键空间事件通知"></a>键空间事件通知</h3><p>在<code>Redis</code>里面有一些事件，比如键<strong>到期</strong>、键被<strong>删除</strong>等。可以通过打开<code>redis</code>键空间事件通知来让 Redis 一旦触发这些事件的时候就往特定的<code>Channel</code>推一条消息</p><h3 id="键事件通知配置"><a href="#键事件通知配置" class="headerlink" title="键事件通知配置"></a>键事件通知配置</h3><ul><li>默认在<code>redis</code>中，键事件通知是不打开的，需要我们手动配置，具体的选项如下，默认他是个空字符串，代表关闭状态</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">notify-keyspace-<span class="keyword">events</span> <span class="string">""</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>选项字符</th><th>解释</th></tr></thead><tbody><tr><td>K</td><td>键空间通知，所有通知以<code>__keyspace@&lt;db&gt;__</code> 为前缀</td></tr><tr><td>E</td><td>键事件通知，所有通知以<code>__keyevent@&lt;db&gt;__</code> 为前缀</td></tr><tr><td>g</td><td><code>DEL</code>、<code>EXPIRE</code>、<code>RENAME</code>等类型无关的通用命令的通知</td></tr><tr><td>$</td><td>字符串命令的通知</td></tr><tr><td>l</td><td>列表命令的通知</td></tr><tr><td>s</td><td>集合命令的通知</td></tr><tr><td>h</td><td>哈希命令的通知</td></tr><tr><td>z</td><td>有序集合命令的通知</td></tr><tr><td>x</td><td>过期事件：每当有过期键被删除时发送</td></tr><tr><td>e</td><td>驱逐<code>(evict)</code>事件：每当有键因为<code>maxmemory</code>政策而被删除时发送</td></tr><tr><td>A</td><td>参数<code>g$lshzxe</code>的别名</td></tr></tbody></table><p>注意，该选项的值中至少需要包含K或者E，否则不会发布任何事件。比如，如果需要开启针对列表的keyspace事件通知，则该选项需要配置为“Kl”； </p><h3 id="键空间和键事件"><a href="#键空间和键事件" class="headerlink" title="键空间和键事件"></a>键空间和键事件</h3><blockquote><p>对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件</p><p>比如说，对<code>0</code>号数据库的键<code>mykey</code>执行<code>DEL</code>命令时， 系统将分发两条消息， 相当于执行以下两个<code>PUBLISH</code>命令</p></blockquote><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUBLISH <span class="symbol">__keyspace@</span><span class="number">0</span>__:mykey del</span><br><span class="line">PUBLISH <span class="symbol">__keyevent@</span><span class="number">0</span>__:del mykey</span><br></pre></td></tr></table></figure><ul><li><code>__keyspace@0__:mykey</code>：接收<code>0</code>号数据库中所有修改键<code>mykey</code>的事件</li><li><code>__keyevent@0__:del</code>：接收<code>0</code>号数据库中所有执行<code>del</code>命令的键</li></ul><blockquote><p><code>keyspace</code>为前缀的频道被称为键空间通知<code>key-space notification</code></p></blockquote><blockquote><p><code>keyevent</code>为前缀的频道则被称为键事件通知<code>key-event notification</code></p></blockquote><ul><li>订阅<strong>键空间频道</strong>，监控被执行事件的键，如监控<code>mykey</code>；那么此时将接收到该键所对应的事件：<code>del</code></li><li>订阅<strong>键事件频道</strong>，监控某个事件，如<code>del</code>；那么<code>del</code>事件触发时，订阅者收到：<code>mykey</code></li></ul><h3 id="过期的键事件通知"><a href="#过期的键事件通知" class="headerlink" title="过期的键事件通知"></a>过期的键事件通知</h3><ul><li>过期的键事件通知常用在订单过期通知等场景下，此时只需要订阅对应<strong>过期事件</strong>的频道，当某键触发过期事件时，即可接受到对应<strong>过期键</strong>的消息</li><li><code>redis</code>配置如下：</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">notify-keyspace-<span class="keyword">events</span> <span class="string">"Ex"</span></span><br></pre></td></tr></table></figure><ul><li><code>Python</code>代码的简单示范，订阅过期频道</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">redis = redis.Redis(host=<span class="string">'123.57.61.168'</span>, port=<span class="number">6379</span>)</span><br><span class="line">pubsub = redis.pubsub()</span><br><span class="line">pubsub.psubscribe(<span class="string">'__keyevent@0__:expired'</span>) <span class="comment"># 订阅过期事件频道</span></span><br><span class="line">print(<span class="string">'Starting message loop'</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        message = pubsub.get_message()</span><br><span class="line">        <span class="keyword">if</span> message:</span><br><span class="line">            print(message)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            time.sleep(<span class="number">0.01</span>)</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        <span class="comment"># CTRL + C</span></span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><ul><li>那么当此时执行此段代码，另起<code>redis</code>客户端，设置一个可以过期的<code>key</code>值，来看一下效果</li></ul><p><img src="/Redis发布者与订阅者，键空间事件/%E9%94%AE%E8%BF%87%E6%9C%9F%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5.gif" alt="键过期事件通知"></p><h3 id="不同命令产生的事件通知"><a href="#不同命令产生的事件通知" class="headerlink" title="不同命令产生的事件通知"></a>不同命令产生的事件通知</h3><p>​            DEL 命令为每个被删除的键产生一个 del 事件；</p><pre><code>RENAME 产生两个事件：为源键产生一个 rename_from 事件，并为目标键产生一个 rename_to 事件；EXPIRE命令，在设置键的过期时间时产生一个 expire事件；当键因过期而被删除时，产生一个 expired事件；SORT命令，在带有 STORE 参数时产生一个 sortstore事件。如果 STORE 指示的用于保存排序结果的键已经存在，则原键会被删除，因此还会产生一个 del 事件；SET 以及它的所有变种(SETEX、SETNX和GETSET)都产生set事件。另外，SETEX命令还会产生expire 事件；MSET 命令，为每个键产生一个 set 事件；SETRANGE 产生一个 setrange 事件；INCR 、DECR、INCRBY和DECRBY都产生 incrby 事件；INCRBYFLOAT产生incrbyfloat事件；APPEND产生append事件；LPUSH和LPUSHX都产生单个 lpush 事件，即使有多个输入元素时，也是如此；RPUSH 和 RPUSHX 都产生单个rpush事件，即使有多个输入元素时，也是如此；RPOP 产生 rpop 事件，如果被弹出的元素是列表的最后一个元素，那么还会产生一个 del 事件；LPOP 产生 lpop 事件，如果被弹出的元素是列表的最后一个元素，那么还会产生一个 del 事件；LINSERT 产生一个 linsert 事件；LSET 产生一个 lset 事件；LREM产生一个lrem事件，如果该命令执行之后，列表键被清空，则还会产生一个 del 事件；LTRIM 产生一个ltrim事件，如果该命令执行之后，列表键被清空，则还会产生一个 del 事件；RPOPLPUSH 和 BRPOPLPUSH 产生一个 rpop 事件，以及一个 lpush 事件。两个命令都保证rpop事件在 lpush 事件之前发出。如果弹出元素之后，列表键被清空，则还会产生一个 del 事件；HSET 、 HSETNX 和 HMSET 都只产生一个 hset 事件；HINCRBY 产生一个 hincrby 事件；HINCRBYFLOAT 产生一个 hincrbyfloat 事件；HDEL 产生一个 hdel 通知。如果执行该命令之后，哈希键被清空，则还会产生一个del事件；SADD 产生一个 sadd 事件，即使有多个输入元素时，也是如此；SREM 产生一个 srem 事件，如果执行该命令之后，集合键被清空，则还会产生一个 del 事件；SMOVE 为源键产生一个 srem 事件，并为目标键产生一个sadd 事件；SPOP 产生一个 spop 事件。如果执行该命令之后，集合键被清空，则还会产生一个 del 事件；SINTERSTORE、SUNIONSTORE和SDIFFSTORE分别产生 sinterstore、sunionostore和sdiffstore 三种事件。如果用于保存结果的键已经存在，则还会产生一个 del 事件；ZINCR产生一个 zincr 事件；ZADD 产生一个 zadd事件，即使有多个输入元素时，也是如此；ZREM 产生一个 zrem 通知，即使有多个输入元素时，也是如此。如果执行 ZREM 之后，有序集合键被清空，则还会产生一个 del 事件；ZREMEBYSCORE 产生一个 zrembyscore事件，如果用于保存结果的键已经存在，则还会产生一个 del 事件。ZREMBYRANK 产生一个 zrembyrank事件，如果用于保存结果的键已经存在，则还会产生一个 del 事件。ZINTERSTORE 和 ZUNIONSTORE 分别产生 zinterstore 和 zunionstore 两种事件。如果用于保存结果的键已经存在，那么还会产生一个 del 事件。每当一个键因为过期而被删除时，产生一个 expired 事件。每当一个键因为 maxmemory策略而被删除并回收内存时，产生一个 evicted 事件。注意：所有命令都只在键真的被改动了之后，才会产生事件通知。比如，当srem命令试图删除不存在于集合的元素时，删除操作执行失败，因为没有真正的改动键，所以这一操作不会发送通知。</code></pre><h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p>1：Redis发布所有通知，客户端A订阅所有消息：</p><p>127.0.0.1:6379&gt; config set notify-keyspace-events KEA<br>OK<br>127.0.0.1:6379&gt; psubscribe <strong>key*@0</strong>:*<br>Reading messages… (press Ctrl-C to quit)</p><p>1) “psubscribe”<br>2) “<strong>key*@0</strong>:*”<br>3) (integer) 1<br>         然后，在客户端B上执行set和del命令：</p><p>127.0.0.1:6379&gt; set msg “hello”<br>OK<br>127.0.0.1:6379&gt; del msg<br>(integer) 1<br>127.0.0.1:6379&gt; del msg<br>(integer) 0<br>         然后客户端A的打印如下：</p><p>1) “pmessage”<br>2) “<strong>key*@0</strong>:*”<br>3) “<strong>keyspace@0</strong>:msg”<br>4) “set”</p><p>1) “pmessage”<br>2) “<strong>key*@0</strong>:*”<br>3) “<strong>keyevent@0</strong>:set”<br>4) “msg”</p><p>1) “pmessage”<br>2) “<strong>key*@0</strong>:*”<br>3) “<strong>keyspace@0</strong>:msg”<br>4) “del”</p><p>1) “pmessage”<br>2) “<strong>key*@0</strong>:*”<br>3) “<strong>keyevent@0</strong>:del”<br>4) “msg”<br>         可见，针对每一个操作，客户端A都收到了两种消息，分别是keyspace和keyevent消息。</p><p>2：使Redis仅发布keyspace通知，而客户端A订阅所有消息类型：</p><p>127.0.0.1:6379&gt; config set notify-keyspace-events KA<br>OK<br>127.0.0.1:6379&gt; psubscribe <strong>key*@0</strong>:*<br>Reading messages… (press Ctrl-C to quit)</p><p>1) “psubscribe”<br>2) “<strong>key*@0</strong>:*”<br>3) (integer) 1<br>         在客户端B上执行，与上面同样的步骤。此时，客户端A上的打印：</p><p>1) “pmessage”<br>2) “<strong>key*@0</strong>:*”<br>3) “<strong>keyspace@0</strong>:msg”<br>4) “set”</p><p>1) “pmessage”<br>2) “<strong>key*@0</strong>:*”<br>3) “<strong>keyspace@0</strong>:msg”<br>4) “del”<br>         可见，尽管客户端A订阅了所有消息，但是Redis仅发布了keyspace事件。而且，在客户端B上执行了两次del操作，而只有第一个del成功执行了，从而产生了一个事件。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;发布者与订阅者（pub-sub）&quot;&gt;&lt;a href=&quot;#发布者与订阅者（pub-sub）&quot; class=&quot;headerlink&quot; title=&quot;发布者与订阅者（pub/sub）&quot;&gt;&lt;/a&gt;发布者与订阅者（pub/sub）&lt;/h2&gt;&lt;p&gt;发布和订阅&lt;code&gt;pub/sub&lt;/code&gt;，订阅者负责订阅频道，发送者负责像频道发送二进制字符串消息，每当有消息发布到订阅的这个频道，那么所有的订阅者都可以收到这个消息，发布订阅也是像是我们生活中的电台，订阅者可以订阅收听多个电台，而发送者可以再任何电台发送消息&lt;/p&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="https://cy-blogs.cn/categories/Redis/"/>
    
    
      <category term="Redis 发布者与订阅者,键空间事件" scheme="https://cy-blogs.cn/tags/Redis-%E5%8F%91%E5%B8%83%E8%80%85%E4%B8%8E%E8%AE%A2%E9%98%85%E8%80%85-%E9%94%AE%E7%A9%BA%E9%97%B4%E4%BA%8B%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Redis 心跳检测</title>
    <link href="https://cy-blogs.cn/redis%E5%BF%83%E8%B7%B3%E6%A3%80%E6%B5%8B/"/>
    <id>https://cy-blogs.cn/redis心跳检测/</id>
    <published>2019-12-20T03:23:07.031Z</published>
    <updated>2019-12-20T03:22:12.655Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-心跳检测"><a href="#Redis-心跳检测" class="headerlink" title="Redis 心跳检测"></a>Redis 心跳检测</h1><blockquote><p>在命令传播阶段，<strong>从服务器默认以每秒一次的频率</strong>，向主服务器发送命令：</p><p>*<em>REPLCONF ACK *</em> //replication_offset是从服务器当前的复制偏移量。</p><p>心跳检测的作用：检测主服务器的网络连接状态；辅助实现min-slaves选项；检测命令丢失。</p><p>检测主从服务器的网络连接状态</p><p>通过向主服务器发送INFO replication命令，可以列出从服务器列表，可以看出从最后一次向主发送命令距离现在过了多少秒。</p><p><img src="https://img-blog.csdn.net/20170829110005938?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemxmcHJvZ3JhbQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt></p><p>lag的值应该在0或1之间跳动，如果超过1则说明主从之间的连接有故障。</p><p>辅助实现min-slaves选项</p><p>Redis可以通过配置<strong>防止主服务器在不安全的情况下执行写命令</strong>；</p><p>min-slaves-to-write 3</p><p>min-slaves-max-lag 10</p><p>上面的配置表示：从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时，主服务器将拒绝执行写命令。这里的延迟值就是上面INFOreplication命令的lag值。</p><p>检测命令丢失</p><p>如果因为网络故障，主服务器传播给从服务器的<strong>写命令在半路丢失</strong>，那么当从服务器向主服务器发送REPLCONF ACK命令时，主服务器将发觉从服务器当前的<strong>复制偏移量</strong>少于自己的复制偏移量，然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。</p><p>主服务器向从服务器<strong>补发缺失数据</strong>这一操作的原理和部分重同步操作的原理非常相似，它们的区别在于：补发缺失数据操作在主从服务器没有断线的情况下执行，而部分重同步操作则在主从服务器断线并重连之后执行。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis-心跳检测&quot;&gt;&lt;a href=&quot;#Redis-心跳检测&quot; class=&quot;headerlink&quot; title=&quot;Redis 心跳检测&quot;&gt;&lt;/a&gt;Redis 心跳检测&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;在命令传播阶段，&lt;strong&gt;从服务器默认以每秒
      
    
    </summary>
    
    
      <category term="Redis" scheme="https://cy-blogs.cn/categories/Redis/"/>
    
    
      <category term="Redis 心跳检测" scheme="https://cy-blogs.cn/tags/Redis-%E5%BF%83%E8%B7%B3%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>Redis哨兵机制</title>
    <link href="https://cy-blogs.cn/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/"/>
    <id>https://cy-blogs.cn/Redis哨兵机制/</id>
    <published>2019-12-20T03:23:07.006Z</published>
    <updated>2019-12-20T08:41:29.683Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-哨兵机制"><a href="#Redis-哨兵机制" class="headerlink" title="Redis 哨兵机制"></a>Redis 哨兵机制</h1><h3 id="什么是哨兵机制？"><a href="#什么是哨兵机制？" class="headerlink" title="什么是哨兵机制？"></a>什么是哨兵机制？</h3><ul><li><p>Redis 的哨兵（sentinel）系统用于管理多个 Redis 服务器，<strong>哨兵是redis集群架构中非常重要的一个组件</strong>，该系统执行以下三个任务：</p><ul><li><strong>监控（Monitoring）</strong>：哨兵（sentinel）会不断地检查你的 Master 和Slave 是否运作正常。</li><li><strong>提醒（Notification）</strong>：当别监控的某个 Redis 出现问题时，哨兵（sentinel）可以通过 API 向管理员或者其他应用程序发送通知。</li><li><strong>自动故障迁移（Automatic failover）</strong>：当一个Master 不能正常工作时，哨兵（sentinel）会开始一次自动故障迁移操作，它会将失效 Master 的其中一个 Slave 升级为新的 Master，并让失效 Master 的其他 Slave 改为复制新的 Master；当客户端视图连接失败的 Master时，集群也会向客户端返回新 Master 的地址，使得集群可以使用 Master 代替失效 Master。</li></ul></li><li><p><strong>哨兵（sentinel）是一个分布式系统，作为一个哨兵集群去运行的，相互协同工作，你可以在一个架构中运行多个哨兵（sentinel）进程</strong></p><blockquote><p>​        (1)故障转移时，判断一个master node宕机了，需要大部分哨兵都同意才行，涉及到分布式选举问题。<br>​         (2)及时部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身就是单点，那么就不靠谱。        </p><p>​        这些进程使用留言协议（gossipprotocols）来接收关于Master 是否下线的信息，并使用投票协议 （agreementprotocols）来决定是否执行自动故障迁移，以及选择哪个 Slave 作为新的 Master。</p><p>​        每个哨兵（sentinel）会向其它哨兵（sentinel）、master、slave<strong>定时</strong>发送消息，以确认对方是否 <strong>“活“ **着，如果发现对方在指定时间（可配置）内未响应，则暂时认为对方已挂（所谓的</strong>”主观认为冗机“**Subjective Down,简称sdown)）</p><p>​        若<strong>“哨兵群”</strong>中的多数据sentinel，都报告某一 master 没响应，系统才认为该 master <strong>“彻底死亡”</strong>(即:客观上的真正down机,Objective Down,简称odown),通过一定的vote算法,从剩下的slave节点中,选一台提升为master,然后自动修改相关配置。</p><p>​         虽然<strong>哨兵(sentinel) *<em>释出为一个单独的可执行文件 *</em>redis-sentinel **,但实际上它只是一个运行在特殊模式下的 Redis 服务器，你可以在启动一个普通 Redis 服务器时通过给定</strong> –sentinel** 选项来启动<strong>哨兵(sentinel)</strong>。</p></blockquote><p>​         哨兵(sentinel) 的一些设计思路和zookeeper非常类似</p><p><img src="/Redis哨兵机制/20171004163652928.jpg" alt="哨兵"></p></li></ul><a id="more"></a><h3 id="哨兵的核心知识"><a href="#哨兵的核心知识" class="headerlink" title="哨兵的核心知识"></a>哨兵的核心知识</h3><hr><ul><li><p>哨兵至少需要3个实例，来保证自己的健壮性。</p></li><li><p>哨兵+redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性</p></li><li><p>对于哨兵+redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充分的测试和演练。</p></li></ul><h3 id="redis哨兵主备切换的数据丢失问题"><a href="#redis哨兵主备切换的数据丢失问题" class="headerlink" title="redis哨兵主备切换的数据丢失问题"></a>redis哨兵主备切换的数据丢失问题</h3><hr><p>两种丢失情况：</p><ul><li><p>异步复制导致的数据丢失</p><blockquote><p>​        因为master-&gt;slave的复制是异步的，所 以可能有部分数据还没复制到slave，master就宕机了，这些数据就丢失了。</p></blockquote></li><li><p>脑裂导致的数据丢失</p><blockquote><p>​        脑裂，也就是说，某个master所在机器 突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着<br> ​        这个时候，集群中就会出现两个master。<br> ​        此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master数据可能就会丢失。<br> ​        因此master在恢复的时候，会被作为一个slave挂到新的master上，自己的数据会被清空，从新的master复制数据</p></blockquote></li></ul><h3 id="解决异步复制和脑裂导致的数据丢失"><a href="#解决异步复制和脑裂导致的数据丢失" class="headerlink" title="解决异步复制和脑裂导致的数据丢失"></a>解决异步复制和脑裂导致的数据丢失</h3><hr><p>min-slaves-to-write 1<br> min-slaves-max-lag 10<br> 要求至少有1个slave，数据复制和同步的延迟不能超过10秒<br> 如果说一旦所有slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了。<br> （1）减少异步复制的数据丢失<br> 有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内<br> （2）减少脑裂的数据丢失<br> 如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求<br> 这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失<br> 上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求<br> 因此在脑裂场景下，最多就丢失10秒的数据</p><p><img src="/Redis哨兵机制/%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98.jpg" alt></p><p>集群脑裂导致的数据丢失问题.png</p><p><img src="/Redis哨兵机制/160983038536.jpg" alt="img"></p><p>脑裂导致数据丢失的问题如何降低损失.png</p><p><img src="/Redis哨兵机制/16098303.jpg" alt="img"></p><p>异步复制导致的数据丢失问题.png</p><p><img src="/Redis哨兵机制/16098303d31754.jpg" alt="img"></p><h3 id="哨兵模式的配置修改"><a href="#哨兵模式的配置修改" class="headerlink" title="哨兵模式的配置修改"></a>哨兵模式的配置修改</h3><hr><ul><li>实现步骤<ul><li>拷贝到etc目录<ul><li><strong>cp sentinel.conf /usr/local/redis/etc</strong></li></ul></li><li>修改sentinel.conf配置文件<ul><li><strong>sentinel monitor mymast 192.168.110.133 6379 1</strong> #主节点 名称 IP 端口号 选举次数</li><li>#配置主服务器的密码(如没设置密码，可以省略)<br>  <strong>sentinel auth-pass mymaster 123456</strong> </li></ul></li><li>修改心跳检测 5000毫秒<ul><li><strong>sentinel down-after-milliseconds mymaster 5000</strong></li></ul></li><li>做多多少合格节点<ul><li><strong>sentinel parallel-syncs mymaster 2</strong></li></ul></li><li>启动哨兵模式<ul><li><strong>./redis-server /usr/local/redis/etc/sentinel.conf –sentinel &amp;</strong></li></ul></li></ul></li></ul><blockquote><p>注意：</p><p>1.当启动哨兵模式之后，如果你的master服务器宕机之后，哨兵自动会在从redis服务器里面 投票选举一个master主服务器出来；这个主服务器也可以进行<strong>读写</strong>操作！</p><p>2.如果之前宕机的主服务器已经修好，可以正式运行了。那么这个服务器只能进行<strong>读</strong>的操作，会自动跟随由哨兵选举出来的新服务器！</p><p>3.大家可以进入./redis-cli，输入<strong>info，</strong>查看你的状态信息；</p></blockquote><p><img src="/Redis哨兵机制/20171004170405127.jpg" alt></p><h3 id="哨兵-Sentinel-总结"><a href="#哨兵-Sentinel-总结" class="headerlink" title="哨兵(Sentinel)总结"></a>哨兵(Sentinel)总结</h3><blockquote><p>1、<strong>Sentinel</strong>的作用：</p><p>A、Master 状态监测</p><p>B、如果Master 异常，则会进行Master-slave 转换，将其中一个Slave作为Master，将之前的Master作为Slave </p><p>C、Master-Slave切换后，master_redis.conf、slave_redis.conf和sentinel.conf的内容都会发生改变，即master_redis.conf中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换 </p><p>2、<strong>Sentinel</strong>的工作方式<strong>:</strong></p><p>1)：每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令。</p><p>2)：如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 </p><p>3)：如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 </p><p>4)：当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 。</p><p>5)：在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 。</p><p>6)：当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 。</p><p>7)：若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 </p><p>若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。</p><p>最后，如果大家看不太懂，推荐大家看两个博客，就明白了！</p><p>1.<a href="http://blog.csdn.net/zbw18297786698/article/details/52891695" target="_blank" rel="noopener">http://blog.csdn.net/zbw18297786698/article/details/52891695</a><br>2.<a href="http://blog.csdn.net/candy_rainbow/article/details/52842402" target="_blank" rel="noopener">http://blog.csdn.net/candy_rainbow/article/details/52842402</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Redis-哨兵机制&quot;&gt;&lt;a href=&quot;#Redis-哨兵机制&quot; class=&quot;headerlink&quot; title=&quot;Redis 哨兵机制&quot;&gt;&lt;/a&gt;Redis 哨兵机制&lt;/h1&gt;&lt;h3 id=&quot;什么是哨兵机制？&quot;&gt;&lt;a href=&quot;#什么是哨兵机制？&quot; class=&quot;headerlink&quot; title=&quot;什么是哨兵机制？&quot;&gt;&lt;/a&gt;什么是哨兵机制？&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Redis 的哨兵（sentinel）系统用于管理多个 Redis 服务器，&lt;strong&gt;哨兵是redis集群架构中非常重要的一个组件&lt;/strong&gt;，该系统执行以下三个任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;监控（Monitoring）&lt;/strong&gt;：哨兵（sentinel）会不断地检查你的 Master 和Slave 是否运作正常。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提醒（Notification）&lt;/strong&gt;：当别监控的某个 Redis 出现问题时，哨兵（sentinel）可以通过 API 向管理员或者其他应用程序发送通知。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自动故障迁移（Automatic failover）&lt;/strong&gt;：当一个Master 不能正常工作时，哨兵（sentinel）会开始一次自动故障迁移操作，它会将失效 Master 的其中一个 Slave 升级为新的 Master，并让失效 Master 的其他 Slave 改为复制新的 Master；当客户端视图连接失败的 Master时，集群也会向客户端返回新 Master 的地址，使得集群可以使用 Master 代替失效 Master。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;哨兵（sentinel）是一个分布式系统，作为一个哨兵集群去运行的，相互协同工作，你可以在一个架构中运行多个哨兵（sentinel）进程&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;​        (1)故障转移时，判断一个master node宕机了，需要大部分哨兵都同意才行，涉及到分布式选举问题。&lt;br&gt;​         (2)及时部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身就是单点，那么就不靠谱。        &lt;/p&gt;
&lt;p&gt;​        这些进程使用留言协议（gossipprotocols）来接收关于Master 是否下线的信息，并使用投票协议 （agreementprotocols）来决定是否执行自动故障迁移，以及选择哪个 Slave 作为新的 Master。&lt;/p&gt;
&lt;p&gt;​        每个哨兵（sentinel）会向其它哨兵（sentinel）、master、slave&lt;strong&gt;定时&lt;/strong&gt;发送消息，以确认对方是否 &lt;strong&gt;“活“ **着，如果发现对方在指定时间（可配置）内未响应，则暂时认为对方已挂（所谓的&lt;/strong&gt;”主观认为冗机“**Subjective Down,简称sdown)）&lt;/p&gt;
&lt;p&gt;​        若&lt;strong&gt;“哨兵群”&lt;/strong&gt;中的多数据sentinel，都报告某一 master 没响应，系统才认为该 master &lt;strong&gt;“彻底死亡”&lt;/strong&gt;(即:客观上的真正down机,Objective Down,简称odown),通过一定的vote算法,从剩下的slave节点中,选一台提升为master,然后自动修改相关配置。&lt;/p&gt;
&lt;p&gt;​         虽然&lt;strong&gt;哨兵(sentinel) *&lt;em&gt;释出为一个单独的可执行文件 *&lt;/em&gt;redis-sentinel **,但实际上它只是一个运行在特殊模式下的 Redis 服务器，你可以在启动一个普通 Redis 服务器时通过给定&lt;/strong&gt; –sentinel** 选项来启动&lt;strong&gt;哨兵(sentinel)&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​         哨兵(sentinel) 的一些设计思路和zookeeper非常类似&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/Redis哨兵机制/20171004163652928.jpg&quot; alt=&quot;哨兵&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="https://cy-blogs.cn/categories/Redis/"/>
    
    
      <category term="Redis哨兵机制" scheme="https://cy-blogs.cn/tags/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Redis 主从复制</title>
    <link href="https://cy-blogs.cn/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>https://cy-blogs.cn/Redis主从复制/</id>
    <published>2019-12-20T00:52:31.992Z</published>
    <updated>2019-12-20T01:59:27.187Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-主从复制"><a href="#Redis-主从复制" class="headerlink" title="Redis 主从复制"></a>Redis 主从复制</h1><ul><li><p>参考链接：</p><ul><li><p><a href="https://www.cnblogs.com/leeSmall/p/8398401.html" target="_blank" rel="noopener">Redis主从复制和哨兵 参考1</a></p><p><a href="https://www.cnblogs.com/chenhuabin/p/10048854.html" target="_blank" rel="noopener">Redis主从复制和哨兵 参考2</a></p><p><a href="https://www.cnblogs.com/lxx666/articles/10693844.html" target="_blank" rel="noopener">Redis主从架构和主从从架构集群搭建详细步骤</a></p><p><a href="https://www.cnblogs.com/wade-luffy/p/9639986.html" target="_blank" rel="noopener">Redis主从复制原理</a></p><p><a href="http://doc.redisfans.com/topic/replication.html" target="_blank" rel="noopener">Redis复制官方文档翻译</a></p></li></ul></li></ul><a id="more"></a><blockquote><p> ​        Redis 的定位是一个高可用的数据服务器，可是实际生产环境下，单机的 <code>redis</code> 服务器是无法满足真正意义上的高可用性的，</p><p>​        第一，单机的 <code>redis</code> 服务器很容易发生单点故障，即使 <code>redis</code> 提供了各种持久化的方法来避免数据的丢失，但是物理机上的故障（硬板损坏等）还是无法完全避免的。</p><p>​        第二，如果单台机器的性能进行纵向扩展，无论是<code>CPU</code>，内存还是磁盘容量都很容易达到瓶颈，无法满足实际需求。</p><p>​        针对这些问题，Redis提供了<strong>复制（replication）</strong>的功能，通过 “主从（一主多从）” 和 （集群（多住多从））的方式对 redis的服务进行水平扩展，用多台 redis 服务器共同构建一个高可用的 redis 服务系统。</p></blockquote><hr><p><img src="https://image-static.segmentfault.com/169/623/16962389-5c72b52170799_articlex" alt="图片描述">            </p><blockquote><p>​        主从复制，是指将一台<code>Redis</code>服务器的数据，复制到其它的 <code>Redis</code>服务器。前者称为主节点（master/leader），后者称为从节点（slave/follower）；数据的复制是单向的，只能由主节点到从节点。</p></blockquote><blockquote><p> ​            默认情况下，每台 <code>Redis</code>服务器都是主节点；且一个主节点可以有多个从节点（或没有从节点），但一个从节点只能有一个主节点。</p></blockquote><h3 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h3><hr><ul><li><strong>数据冗余</strong>：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li><strong>故障恢复</strong>：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li><strong>负载均衡</strong> ：在主从复制的基础上，配合读写分离，可以由主节点提供服务，由从节点提供读服务（即写 Redis 数据时应用连接主节点，读 Redis 数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。</li><li><strong>读写分离</strong>：可以用于实现读写分离，主库写，从库读，读写分离不仅可以提高服务器的负载能力，同时可根据需求的变化，改变从库的数量。</li><li><strong>高可用基石</strong> ：主从复制还是哨兵和肌群能够实施的基础，因此说主从复制是 Redis高可用的基础。</li></ul><h3 id="主从括扑结构"><a href="#主从括扑结构" class="headerlink" title="主从括扑结构"></a>主从括扑结构</h3><hr><ul><li><p><strong>一主一从</strong>：用于节点故障转移从节点，当主节点的 写 命令并发高且需要持久化，可以值在从节点开启AOF （主节点不需要），这样保证了数据的安全性，也避免持久化对主节点的影响。</p><p> <img src="https://images2017.cnblogs.com/blog/1227483/201802/1227483-20180201102310015-486760227.png" alt="img"></p></li><li><p><strong>一主多从</strong> ：针对 <code>读</code>较多的场景， <code>读</code>由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定</p><p>​     <img src="https://images2017.cnblogs.com/blog/1227483/201802/1227483-20180201103217750-831662244.png" alt="img"></p></li><li><p><strong>树状主从</strong>  ：一主多从的缺点（住节点推送次数多压力大）可用些方案解决，主节点只推送一次数据到从节点B，再由从节点B推送到C，减轻主节点推送的压力。</p></li></ul><p>  <img src="https://images2017.cnblogs.com/blog/1227483/201802/1227483-20180201103511703-1604168118.png" alt="img"></p><h3 id="Redis-主从复制启用"><a href="#Redis-主从复制启用" class="headerlink" title="Redis 主从复制启用"></a>Redis 主从复制启用</h3><hr><ul><li><p>主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。</p></li><li><p>从节点开启主从复制，有三种方式：</p><blockquote><ol><li><p>配置文件：在从服务器的配置文件中加入：slaveof <masterip><masterpory></masterpory></masterip></p></li><li><p>启动命令： redis-server 启动命令后加入 –slaveof <masterip><masterport></masterport></masterip></p></li><li><p>客户端命令：Reids 服务器启动后，直接通过客户端执行命令： slaveof <masterip> <masterport> ,则该Redis实例成为从节点。</masterport></masterip></p><p>通过 info  relication  命令可以看到复制的一些信息</p></li></ol></blockquote></li><li><p>断开主从复制</p><blockquote><p>​        通过 slaveof <masterip> <masterport> 命令建立主从复制关系以后，可以通过slaveof no one断开。</masterport></masterip></p><p>​        从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。</p></blockquote></li></ul><h3 id="Redis-主从复制原理"><a href="#Redis-主从复制原理" class="headerlink" title="Redis 主从复制原理"></a>Redis 主从复制原理</h3><hr><p>主从复制过程大体可以分为3个阶段：<strong>连接建立阶段（即准备阶段）</strong>、<strong>数据同步阶段</strong>、<strong>命令传播阶段</strong>：</p><p>在从节点执行 slaveof 命令后，复制过程便开始运作，下图大概可以看到,</p><p>从图中可以看出复制过程大致分为 6 个过程</p><p><img src="https://image-static.segmentfault.com/129/061/1290613498-5c72b64944189_articlex" alt="图片描述"></p><h4 id="从服务器故障后处理"><a href="#从服务器故障后处理" class="headerlink" title="从服务器故障后处理"></a><strong>从服务器故障后处理</strong></h4><blockquote><pre><code>当从服务器崩溃之后，重启之后进行初始化，会自动的同步主服务器的数据。在 redis的2.8版本之后，redis 采用了 **增量复制** 的方式优化了从服务器的初始化同步数据的过程。</code></pre></blockquote><h4 id="主服务器故障后处"><a href="#主服务器故障后处" class="headerlink" title="主服务器故障后处"></a><strong>主服务器故障后处</strong></h4><blockquote><pre><code>当主服务器崩溃之后，首先需要手动的选择一个从服务器升级为主服务器（需要手动调整所有相关的服务器），然后启动之前已经崩溃的主服务器做为从服务回到系统中。可以看到，redis 在主服务器崩溃之后需要繁琐的人工预来恢复服务，特别是在主数据库进制了持久化之后，上述步骤不能错乱，否则会导致主数据库重启后恢复了错误数据，进而导致从数据库也同步错误数据这一灾难性后果。为此，redis 提供了哨兵机制，用于自动化的监控和维持分布式 redis 系统的良好运转。    </code></pre></blockquote><h3 id="连接建立阶段"><a href="#连接建立阶段" class="headerlink" title="连接建立阶段"></a>连接建立阶段</h3><h4 id="step1：保存主节点信息"><a href="#step1：保存主节点信息" class="headerlink" title="step1：保存主节点信息"></a>step1：保存主节点信息</h4><p>​    从节点服务器内部维护了两个字段，即<strong>masterhost</strong>和<strong>masterport</strong>字段，用于存储主节点的<strong>ip</strong>和<strong>port</strong>信息。</p><p>​    <strong>slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。</strong></p><h4 id="step2：建立socket连接"><a href="#step2：建立socket连接" class="headerlink" title="step2：建立socket连接"></a>step2：建立socket连接</h4><p>​    <strong>从节点每秒1次调用复制定时函数replicationCron()</strong>，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。</p><p><strong>如果连接成功：</strong></p><p>​    <strong>从节点：</strong>为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。</p><p>​    <strong>主节点：</strong>接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。</p><h4 id="step3：发送ping命令"><a href="#step3：发送ping命令" class="headerlink" title="step3：发送ping命令"></a>step3：发送ping命令</h4><p>​    从节点成为主节点的客户端之后，发送ping命令进行首次请求，<strong>目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。</strong></p><p><strong>从节点发送ping命令后，可能出现3种情况：</strong></p><ol><li><p>返回ping：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。</p></li><li><p>超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。</p></li><li><p>返回ping以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。</p></li></ol><h4 id="step4：身份验证"><a href="#step4：身份验证" class="headerlink" title="step4：身份验证"></a>step4：身份验证</h4><p>如果从节点中设置了<strong>masterauth</strong>选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。</p><p>从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。</p><p>如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。</p><h4 id="step5：发送从节点端口信息"><a href="#step5：发送从节点端口信息" class="headerlink" title="step5：发送从节点端口信息"></a>step5：发送从节点端口信息</h4><p>身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；<strong>该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。</strong></p><h3 id="数据同步阶段"><a href="#数据同步阶段" class="headerlink" title="数据同步阶段"></a>数据同步阶段</h3><p>主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。</p><p>具体执行的方式是：从节点向主节点发送<strong>psync命令</strong>，开始同步。</p><p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为<strong>全量复制和部分复制</strong>。</p><blockquote><p>在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。</p></blockquote><h3 id="命令传播阶段"><a href="#命令传播阶段" class="headerlink" title="命令传播阶段"></a>命令传播阶段</h3><p>​    数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p><p>​    在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。</p><p><strong>PS：</strong></p><p>​    <strong>延迟与不一致：</strong>命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p><p>​    <strong>repl-disable-tcp-nodelay no：</strong>该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。</p><h3 id="【数据同步阶段】全量复制和部分复制"><a href="#【数据同步阶段】全量复制和部分复制" class="headerlink" title="【数据同步阶段】全量复制和部分复制"></a>【数据同步阶段】全量复制和部分复制</h3><p>在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；</p><p>在Redis2.8以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。</p><ol><li>全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。</li><li>部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。</li></ol><h4 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h4><p><strong>Redis通过psync命令进行全量复制的过程如下：</strong></p><ol><li><p>从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；</p></li><li><p>主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。</p></li><li><p>主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。</p></li><li><p>主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。</p></li><li><p>如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。</p></li></ol><p><strong>通过全量复制的过程可以看出，全量复制是非常重型的操作：</strong></p><ol><li><p>主节点通过<strong>bgsave</strong>命令<strong>fork</strong>子进程进行<strong>RDB</strong>持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；</p></li><li><p>主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗。</p></li><li><p>从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗。</p></li></ol><h4 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h4><p>​    由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。</p><p>​    部分复制的实现，依赖于三个重要的概念：复制偏移量，复制积压缓冲区，服务器运行ID</p><h5 id="offset-复制偏移量"><a href="#offset-复制偏移量" class="headerlink" title="offset 复制偏移量"></a>offset 复制偏移量</h5><p>​        在主从复制的Master(主节点)和Slave(从节点)双方都会各自维持一个offset，代表的是<strong>主节点向从节点传递的字节数</strong>；Master成功发送N个字节的命令后会将Master的offset加上N，Slave在接收到N个字节命令后同样会将Slave的offset增加N。Master和Slave如果状态是一致的那么它的的offset也应该是一致的。</p><p>​        offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。</p><h5 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h5><p>  复制积压缓冲区是由<strong>Master(主节点)维护的一个固定长度的FIFO队列(先进先出)</strong>，默认大小1MB；当主节点开始有从节点时创建，它的作用是缓存已经传播出去的命令。当Master进行命令传播时，不仅将命令发送给所有Slave，还会将命令写入到复制积压缓冲区里面。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。</p><p>​        除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。</p><p>​        由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。</p><p><strong>从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：</strong></p><ul><li><strong>如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；</strong></li><li><strong>如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。</strong></li></ul><h5 id="runid-服务器运行ID"><a href="#runid-服务器运行ID" class="headerlink" title="runid 服务器运行ID"></a>runid 服务器运行ID</h5><p>​        每个Redis服务器(无论主从)在启动时都会自动生成一个表明自己身份的随机ID(每次启动都不一样)，由40个随机的十六进制字符组成。在PSYNC中发送的这个ID是指之前连接的Master的ID，如果没保存这个ID，PSYNC命令会使用<strong>”PSYNC ? -1”</strong> 这种形式发送给Master，表示需要全量复制。</p><p>​        每个Redis节点，在启动时都会自动生成一个随机ID，由40个随机的十六进制字符组成；</p><p>runid用来唯一识别一个Redis节点。<strong>通过info Server命令，可以查看节点的runid。</strong></p><p>​        主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；</p><p><strong>主节点根据runid判断能否进行部分复制：</strong></p><ul><li><p>如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；</p></li><li><p>如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。</p></li></ul><h3 id="PSYNC命令"><a href="#PSYNC命令" class="headerlink" title="PSYNC命令"></a>PSYNC命令</h3><p>  Redis在2.8版本提供了PSYNC命令来带代替SYNC命令，为Redis主从复制提供了部分复制的能力。</p><h4 id="PSYNC命令格式"><a href="#PSYNC命令格式" class="headerlink" title="PSYNC命令格式"></a>PSYNC命令格式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PSYNC &lt;runid&gt; &lt;offset&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> runid:主服务器ID</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> offset:从服务器最后接收命令的偏移量</span></span><br></pre></td></tr></table></figure><p>  <strong>PSYNC执行过程中比较重要的概念有3个：runid、offset（复制偏移量）以及复制积压缓冲区。</strong></p><h4 id="psync命令的执行"><a href="#psync命令的执行" class="headerlink" title="psync命令的执行"></a>psync命令的执行</h4><p><img src="/Redis主从复制/C:%5CUsers%5Casus%5CDesktop%5C990532-20180913134017449-1623896661.png" alt="990532-20180913134017449-1623896661"></p><ol><li><p>首先从节点根据当前状态，决定如何调用psync命令：</p><ul><li>如果从节点之前未执行过<strong>slaveof</strong>或最近执行了<strong>slaveof no one</strong>，则从节点发送命令为<strong>psync ? -1</strong>，向主节点请求全量复制；</li><li>如果从节点之前执行了<strong>slaveof</strong>，则发送命令为 <strong>psync <runid> <offset> **，其中</offset></runid></strong>runid<strong>为上次复制的主节点的</strong>runid<strong>，</strong>offset**为上次复制截止时从节点保存的复制偏移量。</li></ul></li><li><p>主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：</p><ul><li>如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；</li><li>如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；</li><li>如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复<strong>+FULLRESYNC <runid> <offset></offset></runid></strong>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。</li></ul></li></ol><h3 id="【命令传播阶段】心跳机制"><a href="#【命令传播阶段】心跳机制" class="headerlink" title="【命令传播阶段】心跳机制"></a>【命令传播阶段】心跳机制</h3><p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。</p><h4 id="主-gt-从：PING"><a href="#主-gt-从：PING" class="headerlink" title="主-&gt;从：PING"></a>主-&gt;从：PING</h4><p>每隔指定的时间，<strong>主节点会向从节点发送PING命令</strong>，这个PING命令的作用，主要是为了让从节点进行超时判断。</p><p>PING发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是10s。</p><h4 id="从-gt-主：REPLCONF-ACK"><a href="#从-gt-主：REPLCONF-ACK" class="headerlink" title="从-&gt;主：REPLCONF ACK"></a>从-&gt;主：REPLCONF ACK</h4><p>在命令传播阶段，<strong>从节点会向主节点发送REPLCONF ACK命令，</strong>频率是每秒1次；</p><p><strong>命令格式为：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REPLCONF ACK &#123;offset&#125;# offset指从节点保存的复制偏移量。</span><br></pre></td></tr></table></figure><p><strong>REPLCONF ACK命令的作用包括：</strong></p><ol><li><p><strong>实时监测主从节点网络状态：</strong>该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1。</p></li><li><p><strong>检测命令丢失：</strong>从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。</p></li></ol><ul><li><strong>注意：offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。</strong></li></ul><ol start="3"><li><strong>辅助保证从节点的数量和延迟：</strong>Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。</li></ol><p>　　</p><h2 id="开启主从复制"><a href="#开启主从复制" class="headerlink" title="开启主从复制"></a>开启主从复制</h2><p>从节点开启主从复制，有3种方式：</p><ul><li>配置文件：在从服务器的配置文件中加入：<strong>slaveof <masterip> <masterport></masterport></masterip></strong></li><li>启动命令：redis-server启动命令后加入： <strong>–slaveof <masterip> <masterport></masterport></masterip></strong></li><li>客户端命令：Redis服务器启动后，直接通过客户端执行命令：<strong>slaveof <masterip> <masterport></masterport></masterip></strong>，则该Redis实例成为从节点。</li></ul><h3 id="修改配置文件方法："><a href="#修改配置文件方法：" class="headerlink" title="修改配置文件方法："></a>修改配置文件方法：</h3><h4 id="1-配置从服务配置文件redis-conf"><a href="#1-配置从服务配置文件redis-conf" class="headerlink" title="1. 配置从服务配置文件redis.conf"></a>1. 配置从服务配置文件redis.conf</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">slaveof 192.168.1.9 6379    #添加属于某台主机的从 服务</span><br><span class="line">masterauth 123456       #从服务连接主服的密码（访问主服务器的密码）</span><br><span class="line">slave-read-only yes     #从服务只读，不可在命令行写入数据</span><br><span class="line"></span><br><span class="line">5.0.4以后：</span><br><span class="line">replicaof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line">replica-read-only yes</span><br></pre></td></tr></table></figure><h4 id="2-重新启动从服务即实现主从连接"><a href="#2-重新启动从服务即实现主从连接" class="headerlink" title="2. 重新启动从服务即实现主从连接"></a>2. 重新启动从服务即实现主从连接</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. ./bin/redis-cli# 启动redis客户端</span><br><span class="line">2. 输入 info replication # 查看与复制相关的状态，了解主从节点的当前状态</span><br></pre></td></tr></table></figure><p><strong>输入info replication 后显示的内容：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Replication</span></span><br><span class="line">role:slave      # 表示此台服务器是主是从</span><br><span class="line">master_host:39.107.38.62     # 主服务器ip</span><br><span class="line">master_port:6379        # 主服务器端口号</span><br><span class="line">master_link_status:up       # 与主服务器是否连接成功 up为成功 down失败</span><br><span class="line">master_last_io_seconds_ago:9</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:808</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_replid:ea5230cc485f9c6f372b2c89a65613fb075aff8b</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:808</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:15</span><br><span class="line">repl_backlog_histlen:794</span><br></pre></td></tr></table></figure><h4 id="遇到的报错："><a href="#遇到的报错：" class="headerlink" title="遇到的报错："></a>遇到的报错：</h4><h5 id="1-Error-condition-on-socket-for-SYNC-Connection-refused"><a href="#1-Error-condition-on-socket-for-SYNC-Connection-refused" class="headerlink" title="1. Error condition on socket for SYNC: Connection refused"></a>1. Error condition on socket for SYNC: Connection refused</h5><p>  <strong>出现原因</strong>：</p><p>  ​    redis主服务器绑定了127.0.0.1，跨服务器IP的访问就会失败，只能本机才能访问，外部请求会被过滤。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">1. 主服务器绑定ip: bind 39.107.38.62</span><br><span class="line">3. bind 0.0.0.0</span><br><span class="line">2. 注释bind  # 会报下面的错↓</span><br></pre></td></tr></table></figure><h5 id="2-‘-DENIED-Redis-is-running-in-protected-mode-because-protected-mode-is-enabled-no-bind-address-was-specified-no-authentication-password-is-requested-to-clients-In-this-mode-connections-are-only-accepted-from-the-loopback-interface-If-you-want-to-connec"><a href="#2-‘-DENIED-Redis-is-running-in-protected-mode-because-protected-mode-is-enabled-no-bind-address-was-specified-no-authentication-password-is-requested-to-clients-In-this-mode-connections-are-only-accepted-from-the-loopback-interface-If-you-want-to-connec" class="headerlink" title="2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec"></a>2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec</h5><p>   <strong>出现原因</strong>：</p><p>   ​    处于保护模式，只能本地链接。没有绑定ip 没有设置验证密码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">1. 主服务器绑定ip： bind 39.107.38.62</span><br><span class="line">2. 设置主服务器访问密码：requirepass 12345</span><br></pre></td></tr></table></figure><h5 id="3-error-READONLY-You-can’t-write-against-a-read-only-replica"><a href="#3-error-READONLY-You-can’t-write-against-a-read-only-replica" class="headerlink" title="3. (error) READONLY You can’t write against a read only replica."></a>3. (error) READONLY You can’t write against a read only replica.</h5><p>​    <strong>出现原因</strong>：</p><p>​        从库只可读不可写</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解决方法：</span><br><span class="line">1. 设置slave-read-only no # 代表不限于只读</span><br></pre></td></tr></table></figure><h2 id="断开主从复制"><a href="#断开主从复制" class="headerlink" title="断开主从复制"></a>断开主从复制</h2><p>​    通过<strong>slaveof <masterip> <masterport></masterport></masterip></strong>命令建立主从复制关系以后，可以通过slaveof no one断开。</p><p>从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。</p><hr><h4 id="Redis-哨兵"><a href="#Redis-哨兵" class="headerlink" title="Redis 哨兵"></a>Redis 哨兵</h4><hr><ul><li><p>哨兵的介绍</p><blockquote><p>​        redis 的设计者为了让 redis 能够在主从模式下实现故障恢复的自动化，为此提供了 redis 的哨兵功能。哨兵是一个独立于数据服务器的进程，用于监控 redis 数据服务器的状态，当主从模式下最关键的主服务器出现故障时，能够被哨兵自动的察觉。同时哨兵会在剩余的从服务器中“<strong>选择</strong>”出新的主服务器，达到自动化恢复系统的目的。</p></blockquote></li><li><p>哨兵的使用</p><blockquote><p>​        redis 提供了<strong>redis-setine</strong> 脚本用于部署哨兵，启动时通过指定的哨兵配置文件来对哨兵的行为进行灵活的控制。哨兵的配置文件中至少需要包含被哨兵监控的主服务器<strong>IP</strong>、<strong>端口</strong>、投票决定数目，当然可以配置诸如 <strong>down-after-milliseconds</strong> （发送<strong>ping</strong>命令的时间间隔，用于监听）等选项。</p><p>​        <strong>sentinel monitor</strong> *”master_name” “IP” “PORT”***</p><p>​        <strong>down-after-milliseconds</strong> *”milliseconds”*　(“milliseconds”大于1000时，默认为1000)</p></blockquote></li><li><p><strong>哨兵的工作方式</strong></p><blockquote><p>​        哨兵启动时会与主服务器建立连接，并且间接的获得所属从服务器信息，完成哨兵的初始化。哨兵初始化完成之后，会周期性的和主从服务器、其他哨兵节点（通过消息频道的订阅）进行通信。</p><p>​        哨兵每10秒会向所有服务器发送一次<strong>INFO</strong>命令，获得相关 redis 服务器的当前状态以便决定是否需要故障恢复。</p><p>​        当一个哨兵在<strong>down-after-milliseconds</strong>规定时间内未收到主服务器的响应，则当前哨兵<strong>“主观”</strong>认为主服务器下线，同时和监视当前系统的其它哨兵进行投票决定，当超过当前哨兵配置中投票决定的数目时，则当前哨兵<strong>“客观”</strong>认为主服务器下线，哨兵集群会选举出领导哨兵来进行主从服务器集群主从状态的切换(使用Raft算法)。</p></blockquote></li></ul><h3 id="redis主从复制总结"><a href="#redis主从复制总结" class="headerlink" title="redis主从复制总结"></a>redis主从复制总结</h3><hr><ul><li><h4 id="乐观复制策略"><a href="#乐观复制策略" class="headerlink" title="乐观复制策略"></a>乐观复制策略</h4><blockquote><p>​        redis的主从复制采用的是乐观复制的策略，在一定的时间内允许主从服务器的数据不完全一致，但是保持主从数据库数据的最终一致性(按照<strong>CAP定理</strong>,放弃了<strong>C</strong>(强一致性))。</p><p>　　这意味着redis主从服务器之间的数据复制操作时异步的，主服务器不等待从服务器返回复制的结果，可以立即处理新的写入命令。这一策略使得主服务器的性能在复制时不会受到太大影响，但是从服务器会出现短时间内数据不一致的情况。redis允许用户配置主库的<strong>min-slaves-to-write</strong>(代表至少N台从服务器完成复制，才允许主服务器写入)和<strong>min-slaves-max-lag</strong>(允许从服务器断开连接的时间)这两个配置项来控制分区中数据不一致的影响。</p></blockquote></li><li><h4 id="和集群的区别"><a href="#和集群的区别" class="headerlink" title="和集群的区别"></a>和集群的区别</h4><blockquote><p>redis的主从复制特性为redis带来了很高的读取可用性，但是对于海量数据的持久化存储是力不从心的。因为主从复制结构下，任意的节点都保存了100%的存储数据，所以能够存储的数据规模还是受限于单例服务器存储容量的大小。</p><p>　　为此，在单主多从结构的基础上，redis还提供了集群特性。通过将存储数据合理的分片存储在不同的redis节点上，通过集群水平扩容之后的redis集群拥有了极高的读写可用性和分区容错性。理解redis的主从复制原理是理解更为复杂的集群特性的基础。</p></blockquote></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Redis-主从复制&quot;&gt;&lt;a href=&quot;#Redis-主从复制&quot; class=&quot;headerlink&quot; title=&quot;Redis 主从复制&quot;&gt;&lt;/a&gt;Redis 主从复制&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;参考链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/leeSmall/p/8398401.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis主从复制和哨兵 参考1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/chenhuabin/p/10048854.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis主从复制和哨兵 参考2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/lxx666/articles/10693844.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis主从架构和主从从架构集群搭建详细步骤&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/wade-luffy/p/9639986.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis主从复制原理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://doc.redisfans.com/topic/replication.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis复制官方文档翻译&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="https://cy-blogs.cn/categories/Redis/"/>
    
    
      <category term="Redis 主从复制" scheme="https://cy-blogs.cn/tags/Redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Docker 存储</title>
    <link href="https://cy-blogs.cn/docker%E5%AD%98%E5%82%A8/"/>
    <id>https://cy-blogs.cn/docker存储/</id>
    <published>2019-12-16T03:17:54.956Z</published>
    <updated>2019-12-20T09:21:24.729Z</updated>
    
    <content type="html"><![CDATA[<p>#Docker 存储</p><h3 id="Docek-镜像层的镜像分层结构"><a href="#Docek-镜像层的镜像分层结构" class="headerlink" title="Docek 镜像层的镜像分层结构"></a>Docek 镜像层的镜像分层结构</h3><ul><li>docker的镜像分层结构，如下所示：</li></ul><p><img src="/docker存储/container-layers.jpg" alt="基于Ubuntu映像的容器层"></p><ul><li><p>docker镜像中引入层layer概念，镜像的制作过程中的每一步都会生产一个新的镜像层</p></li><li><p>容器读写层的工作原理</p><blockquote><p>我们刚刚在说镜像的分层特性的时候说到镜像是只读的。而事实上当我们使用镜像启动一个容器的时候，我们其实是可以在容器里随意读写的，从结果上看，似乎与镜像的只读特性相悖。</p><p>我们继续看上面的图，其实可以看到在镜像的最上层，还有一个读写层。而这个读写层，即在容器启动时为当前容器单独挂载。每一个容器在运行时，都会基于当前镜像在其最上层挂载一个读写层。而用户针对容器的所有操作都在读写层中完成。一旦容器销毁，这个读写层也随之销毁。</p><blockquote><p>知识点： 容器=镜像+读写层</p></blockquote><p>而我们针对这个读写层的操作，主要基于两种方式：写时复制和用时分配。</p></blockquote></li></ul><a id="more"></a><hr><h3 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h3><p><img src="/docker存储/sharing-layers.jpg" alt="容器共享相同的图像"></p><ul><li><p>容器由最上面一个可写的容器层和若干个只读的镜像层组成，容器的数据就存在这些层中。这种分层结构最大的特点是Copy-on-Write。</p><ol><li><p>新数据会直接存放在最上面的容器层</p></li><li><p>修改现有数据会从镜像层复制文件到容器中，再在容器层修改并保存，镜像层的数据不会发生改变</p></li><li><p>若多个层中有命名相同的文件，用户只能看到最上面一层的文件</p></li></ol></li></ul><ul><li>分层结构使镜像和容器的创建、共享以及分发变得非常高效，而这些都要归功于 Docerk stoage driver。<strong>正是 storage driver 实现了多层数据的堆叠并为用户提供一个单一的合并之后的统一视图</strong>。</li></ul><hr><h3 id="Docker-为容器提供了两种存放数据的资源："><a href="#Docker-为容器提供了两种存放数据的资源：" class="headerlink" title="Docker 为容器提供了两种存放数据的资源："></a>Docker 为容器提供了两种存放数据的资源：</h3><ul><li>由storage driver（存储驱动） 管理的镜像层和容器层<ul><li>用来放一些无状态的数据<ul><li><strong>对于某些容器，直接将数据放在由</strong> storage driver <strong>维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。</strong></li></ul></li></ul></li><li>Data Volume。（数据卷）<ul><li>用来放一些有状态的数据，例如数据库<ul><li><strong>本质上是</strong> Docker Host （主机）<strong>文件系统中的目录或文件，能够直接被 ** mount （挂载）</strong>到容器的文件系统中**。</li></ul></li></ul></li></ul><h4 id="关于docker镜像的三问"><a href="#关于docker镜像的三问" class="headerlink" title="关于docker镜像的三问"></a>关于docker镜像的三问</h4><ul><li>基于镜像A创建镜像B时是否会拷贝A镜像中的所有文件：<code>是不会的</code></li><li>基于镜像创建容器时是否会拷贝镜像中的所有文件至文件层：<code>不会的</code></li><li>容器与镜像在结构上有什么区别：<code>没有区别容器会比镜像多了一个</code> <code>merged</code>文件</li></ul><blockquote><p>在讲原理前，先讲下写时复制和写时分配</p></blockquote><h4 id="写时复制（CoW）"><a href="#写时复制（CoW）" class="headerlink" title="写时复制（CoW）"></a>写时复制（CoW）</h4><blockquote><p>所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。所以无论多少个容器共享同一个image，所作的写操作都是从image中复制到自己的文件系统中的复制本上进行，并不会修改image的源文件，且多个容器操作同一个文件，会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离的，相互不影响。使用CoW可以有效的提高磁盘的利用率。</p></blockquote><h4 id="用时分配（allocate-on-demand）"><a href="#用时分配（allocate-on-demand）" class="headerlink" title="用时分配（allocate-on-demand）"></a>用时分配（allocate-on-demand）</h4><blockquote><p>而用时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。</p></blockquote><h4 id="Docker存储驱动的作用"><a href="#Docker存储驱动的作用" class="headerlink" title="Docker存储驱动的作用"></a>Docker存储驱动的作用</h4><blockquote><p>将这些分层的镜像文件堆叠起来，并且提供统一的视图.使container的文件系统看上去和我们普通的文件系统没什么区别。<br>当创建一个新的容器的时候,实际上是在镜像的分层上新添加了一层container layer（容器层）.之后所有对容器产生的修改,实际都只影响这一层。</p><p>注意</p><p>容器层：读写层(可写层)<br>镜像层：只读层</p></blockquote><blockquote><p> Docker 支持多种 storage driver，有 AUFS 、Device Mapper 、Btrfs 、OverlayFS 、VFS 和ZFS。它们都能实现分层的架构，同时又有各自的特性。对于Docker 用户来说，具体选择使用哪个 storage driver 是一个难题，因为：</p></blockquote><p>​            没有哪个driver 能够适应所有的场景。</p><p>​            driver 本身在快速发展和迭代。</p><blockquote><p>优先使用 Linux 发行版默认的 storage driver。Docker 安装时会根据当前系统的配置选择默认的 driver。默认 driver 具有最好的稳定性，因为默认 driver 在发行版上经过了严格的测试。</p></blockquote><blockquote><p>运行<code>docker info</code>可以查看可查看当前系统使用的<code>Storage driver</code>。</p><blockquote><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; &gt; [root@izbp1dg6m4eebtcm77n0smz ~]# docker info</span><br><span class="line">&gt; &gt; Client:</span><br><span class="line">&gt; &gt; <span class="builtin-name">Debug</span> Mode: <span class="literal">false</span></span><br><span class="line">&gt; &gt; </span><br><span class="line">&gt; &gt; Server:</span><br><span class="line">&gt; &gt; Containers: 6</span><br><span class="line">&gt; &gt; Running: 4</span><br><span class="line">&gt; &gt; Paused: 0</span><br><span class="line">&gt; &gt; Stopped: 2</span><br><span class="line">&gt; &gt; Images: 4</span><br><span class="line">&gt; &gt;<span class="built_in"> Server </span>Version: 19.03.5</span><br><span class="line">&gt; &gt; Storage Driver: overlay2</span><br><span class="line">&gt; &gt; Backing Filesystem: extfs</span><br><span class="line">&gt; &gt; Supports d_type: <span class="literal">true</span></span><br><span class="line">&gt; &gt; Native Overlay Diff: <span class="literal">false</span></span><br><span class="line">&gt; &gt;<span class="built_in"> Logging </span>Driver: json-file</span><br><span class="line">&gt; &gt; Cgroup Driver: cgroupfs</span><br><span class="line">&gt; &gt;</span><br></pre></td></tr></table></figure></blockquote></blockquote><blockquote></blockquote><hr><blockquote><p>Ubuntu 用的 <code>AUFS</code>，底层文件系统是 <code>extfs</code>，各层数据存放在 <code>/var/lib/docker/aufs</code>。<br>centos默认的<code>driver</code>用的是<code>overlay2</code>，底层的文件系统是xfs,各层数据存放在<code>/var/lib/docker</code></p></blockquote><blockquote><p>而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。</p><p>比如启动一个容器，并不是为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。</p></blockquote><ul><li>docker提供了多种的存储驱动来实现不同的方式存储镜像</li></ul><h5 id="Docker五种存储驱动原理及应用场景和性能测试对比"><a href="#Docker五种存储驱动原理及应用场景和性能测试对比" class="headerlink" title="Docker五种存储驱动原理及应用场景和性能测试对比"></a>Docker五种存储驱动原理及应用场景和性能测试对比</h5><blockquote><p><code>Docker</code> 最开始采用AUFS作为文件系统，也得益于AUFS分层的概念，实现了多个Container可以共享同一个image。但由于<code>AUFS</code> 为并入 <code>Linux</code>内核，且只支持 <code>Ubuntu</code>，考虑到兼容的问题，在 <code>Docker 0.7</code> 版本中引入了存储驱动，就如Docker官网上说的，没有单一的驱动适应所有的应用场景，要根据不同的场景选择合适的存储驱动，才能有效的提高Docker 的性能。如何选择适合的存储驱动，要先了解存储驱动原理才能更好的判断。</p></blockquote><blockquote><p>接下来我们说说这些分层的镜像是如何在磁盘中存储的。</p></blockquote><ul><li><p><code>docker</code> 提供了多种存储驱动来实现不同的方式存储镜像</p><ul><li><p>下列出了 <code>Docker</code> 中支持的存储驱动程序：</p><table><thead><tr><th align="center">技术</th><th align="center">存储驱动成名称</th></tr></thead><tbody><tr><td align="center"><code>OverlayFS</code></td><td align="center"><code>overlay</code> 或  <code>overlay2</code></td></tr><tr><td align="center"><code>AUFS</code></td><td align="center"><code>aufs</code></td></tr><tr><td align="center"><code>Btrfs</code></td><td align="center"><code>btrfs</code></td></tr><tr><td align="center"><code>Device Mapper</code></td><td align="center"><code>devicemapper</code></td></tr><tr><td align="center"><code>VFS</code></td><td align="center"><code>vfs</code></td></tr><tr><td align="center"><code>ZFS</code></td><td align="center"><code>zfs</code></td></tr></tbody></table></li></ul></li></ul><h5 id="AUFS"><a href="#AUFS" class="headerlink" title="AUFS"></a>AUFS</h5><blockquote><p>AUFS（AnotherUnionFS）是一种 Union FS ，是文件级的存储驱动。AUFS 是一个能透明覆盖一个或多个县有文件系统的层状文件系统，把多层合并成文件系统的单层表示。简单来说就是支持将不同目录挂载到同一个虚拟文件系统下的文件系统。这种文件可以一层一层地叠加修改文件。无论低下有多少层都是只读的，只有最上层的文件系统是可写的。当需要修改文件时，AUFS创建该文件的一个副本，使用CoW将文件从只读层复制到可写层进行修改，结果保存在可写层。在Docker中，低下的只读层就是image，可写层就是Container。结构如下图所示：</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/87af417e9f80a3eb8ae9716ae07b3dc1.jpg" target="_blank" rel="noopener"><img src="/docker存储/87af417e9f80a3eb8ae9716ae07b3dc1.jpg" alt="1.jpg"></a></p><blockquote><p><strong>历史</strong>：aufs驱动老早就在Docker中存在了！其实，他在使用<code>graphdriver</code>这个名字之前久存在了。如果你查看项目在那（即首次使用graphdriver名称）提交之前的历史，之前项目中当时只有一个aufs的实现。下边devicemapper部分会讲到更多关于graphdriver这个名称诞生的历史。</p><p><strong>实现</strong>：Aufs最初代表的意思“另一个联合文件系统（another union filesystem）”，试图对当时已经存在的UnionFS实现进行重写。正如你期望的那样，它是一个传统意义的上层覆盖，通过利用aufs称作为“分支（branch）”的特性，让堆叠的目录合并成一个堆叠内容单一挂载点视图。此驱动会将父级信息组合一个有序列表，并把它作为挂载参数，然后把重活移交给aufs来把这些分层组装成一个联合视图。更多的细节信息可以在aufs的<a href="http://aufs.sourceforge.net/aufs3/man.html" target="_blank" rel="noopener">帮助文档</a>上看到。</p><p><strong>优点</strong>：这可能是历史最久且测试最完善的graphdriver后端了。它拥有不错的性能，也比较稳定，适用于广泛的场景。尽管它只在Ubuntu或者Debian的内核上才可以启用（下边有说明），但是这两个发行版和Docker一起使用的场景已经非常多，这让它在广阔的环境中得到了验证。同时，通过让不同的容器从同一个分层里面加载相同的库（因为他们在磁盘上是相同的inode）达到了共享内存页的效果。</p><p><strong>缺点</strong>：Aufs从来没有被上游Linux内核社区接受。多年来Ubuntu和Debian都需要往内核集成一个历史久远的补丁包，且原作者已经放弃了让它被内核采纳的努力。可能与IPV4和IPv6的辩论有些类似，人们担心某一天内核更新后会出现难以整合aufs的补丁的情况，从而导致aufs没得玩。但是就如IPv6，替换aufs势在必行的决心讲了一年又一年。除此之外，它面临着很多其他比较棘手的问题。其中一个最麻烦的、也是比较有历史的问题（尽管某种程度上这是一个安全的特性），是关于在高层更改向上拷贝的文件的权限的，这个问题困扰了不少用户。最终在2015年早期的时候通过编号为<a href="http://dockone.io/docker/docker#11799" target="_blank" rel="noopener">#11799</a>的PR使用aufs的<code>dirperm1</code>特性修复了。自然，这需要内核中有具有<code>dirperm1</code>能力aufs，然而这在今天任何较新版本的Ubuntu或者Debian上都已经不成问题了。</p><p><strong>总结</strong>：如果你在使用Ubtuntu或者Debian，那默认的graphdriver就是aufs，它能满足你绝大多数需求。有人期望有一天它能被overlay的实现取代，但是考虑到overlay文件系统的诸多问题，以及在上游内核中的成熟程度等挑战，这尚未实现。最后，aufs中没有配额的支持。</p></blockquote><h5 id="Overlay"><a href="#Overlay" class="headerlink" title="Overlay"></a>Overlay</h5><blockquote><p>Overlay 是Linux内核3.18后支持的，也是一种Union FS，和AUFS的多层不同的是Overlay只有两层：一个upper文件系统和一个lower文件系统，分别代表Docekr的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。在Docekr中，底下的只读层就是image，可写层就是Container。目前最新的OverlayFS为Overlay2。结构图如下所示：</p></blockquote><p>  <a href="http://dockone.io/uploads/article/20190702/c12e244abea02f7ed1eb42f0ccdbcf1d.jpg" target="_blank" rel="noopener"><img src="/docker存储/c12e244abea02f7ed1eb42f0ccdbcf1d.jpg" alt="2.jpg"></a></p><blockquote><p><strong>历史</strong>：<strong>2014年8月</strong>，Red Hat的 Alex Larsson在编号为<a href="https://github.com/docker/docker/commit/453552c8384929d8ae04dcf1c6954435c0111da0" target="_blank" rel="noopener">453552c8384929d8ae04dcf1c6954435c0111da0</a>的代码提交中添加了针对OverlayFS（最初的上游内核的名称）的graphdriver。</p><p><strong>实现</strong>：Overlay是一个联合文件系统，它的概念较之aufs的分支模型更为简单。Overlay通过三个概念来实现它的文件系统：一个“下层目录（lower-dir）”，一个“上层目录（upper-dir）”，和一个做为文件系统合并视图的“合并（merged）”目录。受限于只有一个“下层目录”，需要额外的工作来让“下层目录”递归嵌套（下层目录自己又是另外一个overlay的联合），或者按照Docker的实现，将所有位于下层的内容都硬链接到“下层目录”中。正是这种可能潜在的inode爆炸式增长（因为有大量的分层和硬连接）阻碍了很多人采用Overlay。Overlay2通过利用更高内核（4.0以及以上的版本）中提供了的更优雅处理多个位于下层分层的机制解决了这个问题。</p><p><strong>优点</strong>：Overlay作为一个合并进主线Linux内核的一个有完整支持的联合文件系统有望成为人们的焦点。与aufs类似，通过使用磁盘上相同的共享库，它也能让分散的容器实现内存共享。Overlay同时有很多的上游Linux内核基于现代的应用场景，如Docker，被持续开发（参看overlay2）。</p><p><strong>缺点</strong>：硬链接的实现方式已经引发了 <a href="http://dockone.io/docker/docker#10613" target="_blank" rel="noopener">inode耗尽</a>的问题，这阻碍了它的大规模采用。inode耗尽并不是唯一的问题，还有其他一些与用户命名空间、SELinux支持有关的问题，且整体的成熟状况不足也阻碍着overlay直接取代aufs成为Docker默认的graphdriver。随着很多问题的解决，特别是在最新的内核发新版中，overlay的可用度越来越高了。如今出现的Overlay2修复了inode耗尽的问题，应该是从Docker 1.12版本之后的焦点，成为overlay驱动的后续开发对象。出于向后兼容的原因，<code>overlay</code>驱动将会继续留在Docker引擎中继续支持现有的用户。</p><p><strong>总结</strong>：考虑到aufs没有足够多的发行版的支持，能有一个上游集成的联合文件系统且拥有Linux内核文件系统社区的支持，overlay驱动的加入是一个重大进步。Overlay在过去的18-24个月已经成熟了很多，并且随着overlay2的出现，它之前一些麻烦的问题已经解决了。希望overlay（或者更具可能性的overlay2）会成为未来默认的graphdriver。为了overlay最好的体验，上游内核社区在4.4.x的内核系列里面修复了很多overlay实现中存在的问题；选择该系列中更新的版本可以获得overlay更好的性能和稳定性。</p></blockquote><h5 id="Overlay2"><a href="#Overlay2" class="headerlink" title="Overlay2"></a>Overlay2</h5><blockquote><p><strong>历史</strong>：<a href="https://github.com/dmcgowan" target="_blank" rel="noopener">Derek McGowan</a>在编号为<a href="https://github.com/docker/docker/pull/22126" target="_blank" rel="noopener">#22126</a>的PR中添加了overlay2的graphdriver，在<strong>2016年6月</strong>被合并进Docker 1.12版本，正如该PR的标题注明的，要取代之前overlay的主要原因是它能“支持多个下层目录”，能解决原先驱动中inode耗尽的问题。</p><p><strong>实现</strong>：在上面的overlay部分已经讲述了Linux内核中的Overlay的框架。上面链接的PR中改进了原有的设计，基于Linux内核4.0和以后版本中overlay的特性，可以允许有多个下层的目录。</p><p><strong>优点</strong>：overlay2解决了一些因为最初驱动的设计而引发的inode耗尽和一些其他问题。Overlay2继续保留overlay已有的优点，包括在同一个引擎的多个容器间从同一个分层中加载内库从而达到内存共享。</p><p><strong>缺点</strong>：现在可能唯一能挑出overlay2的问题是代码库还比较年轻。很多早期的问题已经在早期测试过程中发现并被及时解决了。但是Docker 1.12是第一个提供overlay2的发行版本，随着使用量的增长，相信可能还会发现其他问题。</p><p><strong>总结</strong>：将Linux内核中的一个现代的、广受支持的联合文件系统，和一个和Docker中一个性能优秀的graphdriver结合起来，这应该是Docker引擎未来打造默认的graphdriver最好的道路，只有这样才能获得各种Linux发行版广泛的支持。</p></blockquote><h5 id="Device-mapper"><a href="#Device-mapper" class="headerlink" title="Device mapper"></a>Device mapper</h5><blockquote><p>Device mapper 是Linux 内核 2.6.9 后支持的，提供的一种从逻辑设备到物理设备的映射框架机制，在该机制下，用户可以很方便的根据自己的需要制定实现存储资源的管理策略。前面讲的 AUFS 和 OverlayFS 都是文件级存储，而 Device mapper 是块级存储，所有的操作都是直接对块进行操作，而不是文件。Device mapper 驱动会先在块设备上创建一个资源池，然后在资源池上创建一个带有文件系统的基本设备，所有镜像都是这个基本设备的快照，而容器则是镜像的快照。所以在容器里看到文件系统是资源池上基本设备的文件系统的快照，并不有为容器分配空间。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个用时分配。当要修改已有文件时，再使用 CoW 为容器快照分配块空间，将要修改的数据复制在容器快照中新的块里在进行修改。Device mapper 驱动默认会创建一个 100 G 的文件包含镜像和容器。每个容器被限制在 10G 大小的卷内，可以自己设置调整。结构如下图所示：</p></blockquote><p>  <a href="/docker存储/0ef920a30190955999076f524229f321.jpg"><img src="/docker存储/0ef920a30190955999076f524229f321.jpg" alt="3.jpg"></a></p><blockquote><p> <strong>历史</strong>：Devicemapper很早就以Ｃ代码的包装器面貌存在了，用来和libdevmapper进行交互； 是2013的９月Alex Larsson在编号为<a href="https://github.com/docker/docker/commit/739af0a17f6a5a9956bbc9fd1e81e4d40bff8167" target="_blank" rel="noopener"> 739af0a17f6a5a9956bbc9fd1e81e4d40bff8167</a>的代码提交中添加的。几个月后的重构了才诞生了我们现在所知道的“graphdriver”这个词；Solomon Hykes在2013年10月份早期代码合并的注释中说：将devmapper和aufs整合进通用的“graphdriver”框架。</p><p>  <strong>实现</strong>：devicemapper这个graphdriver利用了Linux中devicemapper代码中众多特性之一，“轻配置（thin provisioning）”，或者简称为“thinp”。<em>（译注：根据Wikipedia，“thin provisioning是利用虚拟化技术，让人觉得有比实际可用更多的物理资源。如果系统的资源足够，能同时满足所有的虚拟化的资源，那就不能叫做thin-provisioned。”）</em> 这与之前提到的联合文件系统不同，因为devicemapper是基于块设备的。这些“轻配置（thin-provisioned）”的块设备带来的是如联合文件系统所提供的一样轻量的行为，但是最重要的一点是，他们不是基于文件的（而是基于块设备的）。正如你能推测的，这让计算分层之间的差别变得不再容易，也丧失了通过在容器间使用同样的库片段而共享内存的能力。</p><p>  <strong>优点</strong>：Devicemapper在过去的年间也被一些人感到不屑，但是它提供的一个非常重要的能力让红帽系（Fedora,RHEL，Project Atomic）也有了一个graphdriver。因为它是基于块设备而不是基于文件的，它有一些内置的能力如配额支持，而这在其他的实现中是不容易达到的。</p><p>  <strong>缺点</strong>：使用devicemapper没有办法达到开箱立即唾手可得很好的性能。你必须遵循<a href="https://docs.docker.com/engine/userguide/storagedriver/device-mapper-driver/#/configure-direct-lvm-mode-for-production" target="_blank" rel="noopener">安装和配置指示</a>才能得到性能还可以的配置。并且最重要的是，在任何需要用Docke引擎来做点正事的地方，都不要使用“虚拟设备（loopback）”模式（对于运行有devicemapper且负载高的系统，如延迟删除（ deferred removal）这样的特性绝对有必要的，这能减少引擎看起来好似夯住了一样的悲剧。）。它的一些特性依赖libdevmaper特定的版本，并且需要比较高级的技能来验证系统上所有的设置。同时，如果Docker Engine的二进制是静态编译的话，devicemapper会完全无法工作，因为它需要<a href="http://dockone.io/docker/docker#11412" target="_blank" rel="noopener">udev sync</a>的支持，而这不能被静态编译进引擎中。</p><p>  <strong>总结</strong>：对于红帽类发行版本来说，devicemapper已经成为“可以直接用”的选择，并且在过去几年间里得到了红帽团队的大力支持和改进。它质量上有优点也有缺点，如果安装/配置过程中没有特别格外注意的话，可能导致和其他选项比较起来性能低下、质量不高。鉴于overlay和overlay2受到了Fedora和RHEL最新的内核的支持，并且拥有SELinux的支持，除非在Red Hat场景中有某种必须使用devicemapper的需求，我想随着用户的成熟他们会转向overlay的怀抱。</p></blockquote><h5 id="Btrfs"><a href="#Btrfs" class="headerlink" title="Btrfs"></a>Btrfs</h5><blockquote><p>Btrfs 被称为下一代写时复制文件系统，并入Linux内核，也是文件级存储，但可以向 Device mapper 一直操作底层设备。 Btrfs 把文件系统的一部分配置为一个完整的子文件系统，称为 subvolume。那么采用 subvolume ，一个大的文件系统可以被划分为很多个子文件系统，这些子文件系统共享底层的设备空间，在需要磁盘空间使用时便从底层设备中分配，类似应用程序调用 malloc（）分配内存一样。为了灵活利用设备空间， Btrfs 将磁盘空间划分为多个 chunk。每个 chunk 可以使用不同的磁盘空间分配策略。比如某些 chunk 只存放 metadata ，某些chunk 只存放数据。这种模型有很多优点，比如 Btrfs 支持动态添加设备。用户在系统中添加新的磁盘之后，可以使用 Btrfs 的命令将该设备添加到文件系统中。Btrfs 把一个大的文件系统当成一个资源池，配置成多个完整的子文件系统，还可以往资源池里加新的子文件系统，而基础镜像则是子文件系统的快照，每个子镜像和容器都有自己的快照，这些快照都是 subvolume 的快照。</p></blockquote><p>   <a href="/docker存储/99ab3acda52806a948625219d9e96a0b.jpg"><img src="/docker存储/99ab3acda52806a948625219d9e96a0b.jpg" alt="4.jpg"></a></p><blockquote><p>当写入一个新文件时，为在容器的快照里为其分配一个新的数据块，文件写在这个空间里，这个叫做分配。而当要修改已有文件时，使用 CoW 复制分配一个新的原始数据和快照，在这个新分配的空间变更数据，变结束再跟新相关的数据结构指向新子文件系统和快照，原来的原始数据和快照没有指针指向，被覆盖。</p></blockquote><blockquote><p><strong>历史</strong>：<strong>2013年12月</strong>较晚的时候，Red Hat公司的Alex Larsson在编号为<a href="https://github.com/docker/docker/commit/e51af36a85126aca6bf6da5291eaf960fd82aa56" target="_blank" rel="noopener">e51af36a85126aca6bf6da5291eaf960fd82aa56</a>的提交中，让使用btrfs作为管理<code>/var/lib/docker</code>的文件系统成为可能。</p><p><strong>实现</strong>：Btrfs的原生特性中，有两个是“子卷（subvolumes）”和“快照（snapshots）”。<em>（译注：根据Wikipedia，“子卷在btrfs中不是一个块设备，也不应该被当做是一个块设备。相反，子卷可以被想象成POSIX文件的命名空间。这个命名空间可以通过顶层的子卷来访问到，也可以独立地被挂载。快照在Btrfs中实际上是一个子卷，通过使用Btrfs的写时复制来和其他的子卷共享数据，对快照的更改不会影响原先的子卷。” ）</em> graphdriver实现中主要结合了这两个能力，从而提供了堆叠和类似写时复制的特性。当然，graphdriver的根（默认情况下是：<code>/var/lib/docker</code>）需要是一个被btrfs文件系统格式化的磁盘。</p><p><strong>优点</strong>：Btrfs几年前发布的时候（2007-2009时代），它被视作一个未来的Linux文件系统并<a href="https://lwn.net/Articles/342892/" target="_blank" rel="noopener">受到了大量的关注</a>。如今在上游Linux内核中，该文件系统已经比较健壮，并受到良好的支持，是众多可选的文件系统之一。</p><p><strong>缺点</strong>：但是Btrfs并没有成为Linux发行版的主流选择，所以你不大可能已经有一个btrfs格式化的磁盘。因为这种在Linux发行版中采用不足的原因，它并没有受到类似其他graphdriver一样的关注和采用。</p><p><strong>总结</strong>：如果你正在使用btrfs，那很显然的这个graphdriver应该迎合了你的需求。在过去几年有过很多Bug，并且有一段时间缺乏对SELinux的支持，但是这已经<a href="http://dockone.io/docker/docker#16452" target="_blank" rel="noopener">被修复</a>了。同时，对btrfs配额的支持也直接加进了docker守护进程中，这是<a href="https://github.com/zhuguihua" target="_blank" rel="noopener">Zhu Guihua</a>在编号为<a href="http://dockone.io/docker/docker#19651" target="_blank" rel="noopener">#19651</a>的PR中添加的，这个特性包含在了Docker 1.12版本中。</p></blockquote><h5 id="ZFS"><a href="#ZFS" class="headerlink" title="ZFS"></a>ZFS</h5><blockquote><p>ZFS 文件系统是一个革命性的全新的文件系统，它从根本上改变了文件系统的管理方式， ZFS 完全抛弃了 “ 卷管理 ” ，不再创建虚拟的卷，而是把所有设备集中到一个存储池中进行管理，用 “ 存储池 ”  的概念来管理物理存储空间。过去，文件系统都是构建在物理设备之上的，为了管理这些物理设备，并为数据提供冗余，“ 卷管理 ” 的概念提供了一个单设备的映射。而 ZFS 创建在虚拟的，被称为 “ zpools ” 的存储池之上。每个存储池由若干虚拟设备（ virtual devices ，vdevs ）组成。这些虚拟设备可以是原始磁盘，也节能是一个RAID1 镜像设备，或是非标准 RAID 等级的多磁盘组。  于是 zpool 上的文件系统可以使用这些虚拟设备的总存储容量。</p></blockquote><p>  <a href="/docker存储/d6daba2b7adfe96daca62f9ed90bf0c4.jpg"><img src="/docker存储/d6daba2b7adfe96daca62f9ed90bf0c4.jpg" alt="5.jpg"></a></p><blockquote><p>下面看一下Docker 里ZFS的使用。首先从 zpool里分配一个ZFS 文件系统给镜像的基础层，而其他镜像层则是这个 ZFS 文件系统快照的克隆，快照是只读的，而克隆是可写的，当容器启动时则在镜像的顶层生成一个可写层。如下图所示：</p></blockquote><p>  <a href="/docker存储/34cc4c9ea6c96b6f83dabb961ed8950e.jpg"><img src="/docker存储/34cc4c9ea6c96b6f83dabb961ed8950e.jpg" alt="6.jpg"></a></p><blockquote><p>d当要写一个新文件时，使用按需分配，一个新的数据块从 zpool 里生成新的数据写入这个块，而这个新空间存于容器（ ZFS 的克隆 ）里。</p><p>当要修改一个已存在的文件时，使用写时复制，分配一个新空间并把原始数据复制到新空间完成修改。</p></blockquote><blockquote><p><strong>历史</strong>：ZFS的graphdriver是由Arthur Gautier和Jörg Thalheim一起在<a href="http://dockone.io/docker/docker#9411" target="_blank" rel="noopener">#9411</a>的PR中实现的，在<strong>2014年的5月</strong>被合并进了Docker引擎里面，并且从Docker 1.7版本开始用户可以使用。该实现依赖Go的一个三方包<a href="https://github.com/mistifyio/go-zfs" target="_blank" rel="noopener">go-zfs</a>进行相关zfs命令的交互。</p><p><strong>实现</strong>：与btrfs和devicemapper类似，要使用zfs驱动必需要有一个ZFS格式化的块设备挂载到graphdriver路径（默认是/var/lib/docker）。同时也需要安装好zfs工具（在绝大多数的发行版上是一个名为zfs-utils的包）供zfs Go库调用来执行相关操作。ZFS有能力创建快照（与btrfs类似），然后以快照的克隆作为分享层的途径（在ZFS的实现中成了一个快照）。因为ZFS不是一个基于文件的实现，aufs和overlay中所拥有的内存共享能力在ZFS是没有的。</p><p><strong>优点</strong>：ZFS正在受到越来越多的欢迎，在Ubuntu 16.04中，在Ubuntu的LXC/LXD中已经被使用。最初由Sun创建，ZFS已经存在很长的时间了，并且在Solaris和很多BSD的衍生版中使用，并且它的Linux移植版实现看起来也比较稳定，对于容器文件系统的场景也有足够合理性能。<code>ZFS</code>graphdriver也很及时的在Dockr 1.12中通过PR <a href="http://dockone.io/docker/docker#21946" target="_blank" rel="noopener">#21946</a>添加了配额的支持，这让它在配额支持方面和btrfs、devicemapper站在了同一起跑线上。</p><p><strong>缺点</strong>：除了没有基于文件（inode）的共享达到内库共享之外，很难说ZFS和其它同样基于块设备的实现相比有什么缺点。通过比较，ZFS看起来欢迎程度越来越高。对于那些完全支持或者正在使用ZFS的Linux发行版或者UNIX衍生版而言，zfs graphdriver可以是一个非常好的选择。</p><p><strong>总结</strong>：ZFS的支持为Docker引擎中稳定的graphdriver加了分。对于那些ZFS的使用者，或者那些ZFS扮演了更要角色的发行版来说，Docker能直接支持该文件系统，对这些社区来说是一个好消息。对于那些默认文件系统是ext4和xfs的发行版，默认采用overlay驱动的用户来说，时间会告诉我们他们是否会对zfs驱动产生更多的兴趣。</p></blockquote><h4 id="存储驱动的对比及适应场景"><a href="#存储驱动的对比及适应场景" class="headerlink" title="存储驱动的对比及适应场景"></a>存储驱动的对比及适应场景</h4><table><thead><tr><th><strong>存储驱动</strong></th><th><strong>特点</strong></th><th><strong>优点</strong></th><th><strong>缺点</strong></th><th><strong>适用场景</strong></th></tr></thead><tbody><tr><td>AUFS</td><td>联合文件系统、未并入内核主线、文件级存储</td><td>作为docker的第一个存储驱动，已经有很长的历史，比较稳定，且在大量的生产中实践过，有较强的社区支持</td><td>有多层，在做写时复制操作时，如果文件比较大且存在比较低的层，可能会慢一些</td><td>大并发但少IO的场景</td></tr><tr><td>overlayFS</td><td>联合文件系统、并入内核主线、文件级存储</td><td>只有两层</td><td>不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件消耗更多的时间</td><td>大并发但少IO的场景</td></tr><tr><td>Devicemapper</td><td>并入内核主线、块级存储</td><td>块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件</td><td>不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本，在很多容器启停的情况下可能会导致磁盘溢出</td><td>适合io密集的场景</td></tr><tr><td>Btrfs</td><td>并入linux内核、文件级存储</td><td>可以像devicemapper一样直接操作底层设备，支持动态添加设备</td><td>不支持共享存储，当有多个容器读同一个文件时，需要生成多个复本</td><td>不适合在高密度容器的paas平台上使用</td></tr><tr><td>ZFS</td><td>把所有设备集中到一个存储池中来进行管理</td><td>支持多个容器共享一个缓存块，适合内存大的环境</td><td>COW使用碎片化问题更加严重，文件在硬盘上的物理地址会变的不再连续，顺序读会变的性能比较差</td><td>适合paas和高密度的场景</td></tr></tbody></table><p><a href="/docker存储/747be895d53add6ea9ddf868f95ff8ec.jpg"><img src="/docker存储/747be895d53add6ea9ddf868f95ff8ec.jpg" alt="7.jpg"></a></p><h5 id="AUFS-VS-Overlay"><a href="#AUFS-VS-Overlay" class="headerlink" title="AUFS VS  Overlay"></a>AUFS VS  Overlay</h5><blockquote><p>AUFS和Overlay都是联合文件系统，但AUFS有多层，而Overlay只有两层，所以在做写时复制操作时，如果文件比较大且存在比较低的层，则AUSF可能会慢一些。而且Overlay并入了linux kernel mainline，AUFS没有，所以可能会比AUFS快。但Overlay还太年轻，要谨慎在生产使用。而AUFS做为docker的第一个存储驱动，已经有很长的历史，比较的稳定，且在大量的生产中实践过，有较强的社区支持。目前开源的DC/OS指定使用Overlay。</p></blockquote><h5 id="Overlay-VS-Device-mapper"><a href="#Overlay-VS-Device-mapper" class="headerlink" title="Overlay VS Device mapper"></a>Overlay VS Device mapper</h5><blockquote><p>Overlay是文件级存储，Device mapper是块级存储，当文件特别大而修改的内容很小，Overlay不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件要消耗更多的时间，而块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件，在这种场景下，显然device mapper要快一些。因为块级的是直接访问逻辑盘，适合IO密集的场景。而对于程序内部复杂，大并发但少IO的场景，Overlay的性能相对要强一些。</p></blockquote><h5 id="Device-mapper-VS-Btrfs-Driver-VS-ZFS"><a href="#Device-mapper-VS-Btrfs-Driver-VS-ZFS" class="headerlink" title="Device mapper VS Btrfs Driver VS ZFS"></a>Device mapper VS Btrfs Driver VS ZFS</h5><blockquote><p>Device mapper和Btrfs都是直接对块操作，都不支持共享存储，表示当有多个容器读同一个文件时，需要生活多个复本，所以这种存储驱动不适合在高密度容器的PaaS平台上使用。而且在很多容器启停的情况下可能会导致磁盘溢出，造成主机不能工作。Device mapper不建议在生产使用。Btrfs在docker build可以很高效。<br>ZFS最初是为拥有大量内存的Salaris服务器设计的，所在在使用时对内存会有影响，适合内存大的环境。ZFS的COW使碎片化问题更加严重，对于顺序写生成的大文件，如果以后随机的对其中的一部分进行了更改，那么这个文件在硬盘上的物理地址就变得不再连续，未来的顺序读会变得性能比较差。ZFS支持多个容器共享一个缓存块，适合PaaS和高密度的用户场景。</p></blockquote><h4 id="IO性能对比"><a href="#IO性能对比" class="headerlink" title="IO性能对比"></a>IO性能对比</h4><blockquote><p>测试工具：IOzone（是一个文件系统的benchmark工具，可以测试不同的操作系统中文件系统的读写性能）<br>测试场景：从4K到1G文件的顺序和随机IO性能<br>测试方法：基于不同的存储驱动启动容器，在容器内安装IOzone，执行命令：</p></blockquote><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./iozone -<span class="selector-tag">a</span> -n <span class="number">4</span>k -g <span class="number">1</span>g -<span class="selector-tag">i</span> <span class="number">0</span> -<span class="selector-tag">i</span> <span class="number">1</span> -<span class="selector-tag">i</span> <span class="number">2</span> -f /root/test<span class="selector-class">.rar</span> -Rb ./iozone.xls</span><br></pre></td></tr></table></figure><h5 id="测试项的定义和解释"><a href="#测试项的定义和解释" class="headerlink" title="测试项的定义和解释"></a>测试项的定义和解释</h5><blockquote><p>Write：测试向一个新文件写入的性能。<br>Re-write：测试向一个已存在的文件写入的性能。<br>Read：测试读一个已存在的文件的性能。<br>Re-Read：测试读一个最近读过的文件的性能。<br>Random Read：测试读一个文件中的随机偏移量的性能。<br>Random Write：测试写一个文件中的随机偏移量的性能。</p></blockquote><h5 id="测试数据对比"><a href="#测试数据对比" class="headerlink" title="测试数据对比"></a>测试数据对比</h5><blockquote><p>Write：</p><p><a href="/docker存储/f592fe0e47c24441541b3970f6775674.jpg"><img src="/docker存储/f592fe0e47c24441541b3970f6775674.jpg" alt="8.jpg"></a></p><p>Re-write:</p><p><a href="/docker存储/778f51a47542033e0ded1b1b1d0edd63.jpg"><img src="/docker存储/778f51a47542033e0ded1b1b1d0edd63.jpg" alt="9.jpg"></a></p><p>Read：</p><p><a href="/docker存储/3028c70ce9a0abcfa673459b199612a3.jpg"><img src="/docker存储/3028c70ce9a0abcfa673459b199612a3.jpg" alt="10.jpg"></a></p><p>Re-Read：</p><p><a href="http://dockone.io/uploads/article/20190702/fb9fe60305c941fbfbc564cb2351e588.jpg" target="_blank" rel="noopener"><img src="http://dockone.io/uploads/article/20190702/fb9fe60305c941fbfbc564cb2351e588.jpg" alt="11.jpg"></a></p><p>Random Read：</p><p><a href="/docker存储/ef273f23ee51927344a224ef3798e75a.jpg"><img src="/docker存储/ef273f23ee51927344a224ef3798e75a.jpg" alt="12.jpg"></a></p><p>Random Write：</p><p><a href="/docker存储/3a07e8a8a9b4de99602d02dc849b771b.jpg"><img src="/docker存储/3a07e8a8a9b4de99602d02dc849b771b.jpg" alt="13.jpg"></a></p></blockquote><ul><li>通过以上的性能数据可以看到：<ul><li>AUFS在读的方面性能相比Overlay要差一些，但在写的方面性能比Overlay要好。</li><li>device mapper在512M以上文件的读写性能都非常的差，但在512M以下的文件读写性能都比较好。</li><li>btrfs在512M以上的文件读写性能都非常好，但在512M以下的文件读写性能相比其他的存储驱动都比较差。</li><li>ZFS整体的读写性能相比其他的存储驱动都要差一些。 简单的测试了一些数据，对测试出来的数据原理还需要进一步的解析。</li></ul></li></ul><blockquote><p><code>Docker</code> 提供了可插拔的存储驱动程序架构。它使我们能够灵活地 <code>插入</code> <code>Docker</code>中的存储驱动程序。他完全基于<code>Linux</code>文件系统 。</p></blockquote><blockquote><p>要实现这一功能，我们必须 在<code>docker</code> 守护进程的开始时就设置驱动程序。 <code>Docker</code> 守护程序只能运行一个存储驱动程序，并且该守护程序实例创建的所有容器使用相同的存储驱动程序。</p></blockquote><ul><li><p>当前存储驱动</p><ul><li>查看守护程序使用哪个存储驱动程序，可以使用一下命令。</li></ul><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="meta">info</span></span><br></pre></td></tr></table></figure><blockquote><p>可以看到上面的命令显示了守护进程使用的存储驱动程序。备份文件系统 <code>extfs</code> 。 <code>extfs</code> 表示覆盖存储驱动程序在文件系统的顶部运行。</p><p>后备文件系统实质用于在 <code>/var/lib/docker</code> 录下创建 <code>Docker</code> 主机的本地存储区域的文件系统。</p></blockquote><ul><li><p>下表包含必须与主机备份文件系统相匹配的存储驱动程序。</p><table><thead><tr><th align="center">存储驱动</th><th align="center">常用</th><th align="center">已禁用</th></tr></thead><tbody><tr><td align="center">overlay</td><td align="center">ext4xfs</td><td align="center">btrfs  aufs  overlayzfs  eCryptfs</td></tr><tr><td align="center">overlay2</td><td align="center">ext4xfs</td><td align="center">btrfs  aufs  overlayzfs  eCryptfs</td></tr><tr><td align="center">aufs</td><td align="center">ext4xfs</td><td align="center">btrfs  aufs  eCryptfs</td></tr><tr><td align="center">aufs</td><td align="center">btrfsonly</td><td align="center">N/A</td></tr><tr><td align="center">devicemapper</td><td align="center">Direct-lvm</td><td align="center">N/A</td></tr><tr><td align="center">vfs</td><td align="center">debugging only</td><td align="center">N/A</td></tr><tr><td align="center"></td><td align="center"></td><td align="center">N/A</td></tr></tbody></table></li></ul><blockquote><p>注意 ：- “已禁用/Disabled on” 表示某些存储驱动程序无法在某些后台文件系统上运行</p></blockquote></li></ul><h4 id="设置存储驱动程序"><a href="#设置存储驱动程序" class="headerlink" title="设置存储驱动程序"></a>设置存储驱动程序</h4><blockquote><p>可以通过 <code>dockersd</code>命令按指定名称来设置存储驱动程序。以下命令启动守护程序并设置新的驱动程序。</p></blockquote><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ dockerd <span class="attribute">--storage-driver</span>=devicemapper</span><br></pre></td></tr></table></figure><blockquote><p>稍后，可以通过 <code>docker info</code> 命令检查 <code>docker</code> 服务驱动程序</p></blockquote><hr><p><strong>对于某些容器，直接将数据放在由</strong> storage driver <strong>维护的层中是很好的选择，比如那些无状态的应用。无状态意味着容器没有需要持久化的数据，随时可以从镜像直接创建。即存在与否依赖镜像的存在。</strong></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如一些工具箱，启动是为了执行命令，不需要保存数据供以后使用，使用完直接退出，容器删除时存在容器层的工作数据也一起删除，这没问题，下次启动新容器即可。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但对于另一类应用这种方式就不合适了，它们有持久化数据的需求，容器启动时需要加载已有的数据，容器销毁时希望保留产生的新数据，也就是说，这类容器是有状态的，例如数据库。</span></span><br><span class="line">这就要用到docker 的另一个存储机制：data <span class="keyword">volume</span><span class="bash"></span></span><br></pre></td></tr></table></figure><h3 id="Data-Volume（数据卷）"><a href="#Data-Volume（数据卷）" class="headerlink" title="Data Volume（数据卷）"></a>Data Volume（数据卷）</h3><hr><blockquote><p>对于有些容器，我们可能会持久化数据的需求，也就是容器启动时需要加载已有的数据，容器销毁时希望保留产生的数据，也就是说这类容器是有状态的。</p><p>这就需要用到 <code>Docker</code> 的 <code>Data Volume</code> 存储机制。<code>Data Volume</code>本质上是 <code>Docker host</code>文件系统中的目录或文件，能够直接被 <code>mount</code> 到容器的文件系统。</p><p>在具体的使用上，<code>Docekr</code> 提供了两种类型的Volume：bind mount 和docker managed volume。</p></blockquote><h5 id="附：bind-mount-与-docker-managed-volume-的区别"><a href="#附：bind-mount-与-docker-managed-volume-的区别" class="headerlink" title="附：bind mount 与 docker managed volume 的区别"></a>附：bind mount 与 docker managed volume 的区别</h5><ul><li>这两种 <strong>data volume</strong> 实际上都是使用 <strong>host</strong> 文件系统的中的某个路径作为 <strong>mount</strong> 源。它们不同之处在于：</li></ul><table><thead><tr><th><strong>不同点</strong></th><th><strong>bind mount</strong></th><th><strong>docker managed volume</strong></th></tr></thead><tbody><tr><td><strong>volume 位置</strong></td><td>可任意指定</td><td><strong>/var/lib/docker/volumes/…</strong></td></tr><tr><td><strong>对已有mount point 影响</strong></td><td>隐藏并替换为 <strong>volume</strong></td><td>原有数据复制到 <strong>volume</strong></td></tr><tr><td><strong>是否支持单个文件</strong></td><td>支持</td><td>不支持，只能是目录</td></tr><tr><td><strong>权限控制</strong></td><td>可设置为只读，默认为读写权限</td><td>无控制，均为读写权限</td></tr><tr><td><strong>移植性</strong></td><td>移植性弱，与 <strong>host path</strong> 绑定</td><td>移植性强，无需指定 <strong>host</strong> 目录</td></tr></tbody></table><h5 id="什么是数据卷"><a href="#什么是数据卷" class="headerlink" title="什么是数据卷"></a>什么是数据卷</h5><ul><li><p>Data Volume 数据卷 ：是可以存放在一个或多个容器内的 <strong>特定的目录</strong>，提供独立于容器之外的<strong>持久化存储</strong>；是经过<strong>特殊设计的目录</strong>，可以绕过联合文件系统（UFS），为一个或多个容器提供访问；</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Docker</span> Contrainer</span><br><span class="line">面向对象中的对象</span><br><span class="line"></span><br><span class="line">对象一旦被销毁，数据就不存在了</span><br><span class="line"></span><br><span class="line">容器一旦被销毁，则容器内的数据将一并被删除</span><br><span class="line"></span><br><span class="line">服务器中的图案也会一并销毁</span><br><span class="line"></span><br><span class="line">容器中的数据不是持久化状态的</span><br></pre></td></tr></table></figure><blockquote><p>不使用 <code>volume</code>的时候，对容器进行的改动是不会被保存的，使用 <code>volume</code>可以实现持久化存储；比如运行一个数据的操作，数据库的一个容器，数据库的数据应该被持久化存储的，<code>volume</code>就可以实现这个，并且 <code>volume</code>可以提供容器与容器之间的共享数据；</p></blockquote></li></ul><h5 id="Docker-的理念之一："><a href="#Docker-的理念之一：" class="headerlink" title="Docker 的理念之一："></a>Docker 的理念之一：</h5><blockquote><p>就是将其应用于其运行的环境打包，因此，通过<code>Docker</code> 容器的生存周期，都是与容器中运行的程序相一致的，而我们对数据的要求通常是持久化的；另一方面，<code>docker</code>容器之间也需要有一个 <strong>共享数据的渠道</strong> ，而这些需求就催生出了<code>docker</code>数据卷的产生；</p></blockquote><h5 id="数据卷的设计的目的："><a href="#数据卷的设计的目的：" class="headerlink" title="数据卷的设计的目的："></a>数据卷的设计的目的：</h5><blockquote><p>在于 <strong>数据的永久化</strong> ，它完全独立于容器的生存周期，因此，<code>Docekr</code>不会在容器删除时删除其挂载的数据卷，也不会存在类似垃圾收集机制，对容器引用的数据卷进行处理了；</p></blockquote><h5 id="数据卷特点："><a href="#数据卷特点：" class="headerlink" title="数据卷特点："></a>数据卷特点：</h5><ul><li><ol><li><code>Docker</code>数据卷是独立于<code>Docker</code>的存在，它存在于<code>Docker host</code>（宿主机）中，因此，它与容器的生存周期是分离的；</li><li><code>Docker</code>数据卷本质上是存在于<code>Docker</code>宿主机的本地文件系统中；</li><li><code>Docker</code> 数据卷可以是目录也可以是文件；（不是块设备）</li><li><code>Docker</code> 容器可以利用数据卷的技术与容器宿主机进行数据共享；</li><li>同一个目录或者文件，可以支持多个容器进行访问，这样其实实现了容器的数据共享和交换；</li><li>数据卷是在容器启动是进行初始化的，那么如果容器使用的镜像包含了的数据也会在容器启动时拷贝到容器的数据卷中；</li><li><code>数据卷可以在容器之间共享和重用</code>；</li><li><code>数据卷的修改会立马生效</code>；容器可以对数据卷里的内容直接修改；容器对数据卷进行的修改是及时的，所有的修改都会直接体现在数据卷中；</li><li><code>数据卷的更新不会影响镜像</code>；因为文件不会写到镜像中去，数据卷是独立于联合文件系统的，而镜像本身基于联合文件系统，so镜像与数据卷之间不会有相互影响的情况；</li><li><code>数据卷会一直存在，即使挂载数据卷的容器已经删除</code>因为数据均本质上是宿主机上的一个目录，同时为了提供数据的永久化，它的生存周期与容器是完全隔离的；</li></ol><p><img src="/docker存储/20190617160156293.png" alt="在这里插入图片描述"></p></li></ul><blockquote><p>Docker 容器中的数据操作经过了UFS 的，UFS 会在宿主机中写一次文件，这个文件在宿主机上是临时的，这时候就出现了重复写的情况，会影响系统的性能；此外，删除容器的时候，就没有人能够通过UFS 在访问到宿主机中的文件了；</p></blockquote><p><img src="/docker存储/20190617160937555.png" alt="在这里插入图片描述"></p><blockquote><p>容器卷可以绕过 UFS 直接操作主机上的文件，当容器删除的时候，宿主机上的文件还在，就在指定的目录下，在重新创建容器的时候们可以指定容器继续读取宿主机上的文件；</p></blockquote><p><img src="/docker存储/20190617161045446.png" alt="在这里插入图片描述"></p><h5 id="创建一个数据卷"><a href="#创建一个数据卷" class="headerlink" title="创建一个数据卷"></a>创建一个数据卷</h5><blockquote><p>包含数据卷挂载的容器在容器关闭时，如果修改了宿主机下的数据卷会，容器里面会产生改变吗？ </p></blockquote><ul><li><strong>bind mount 数据卷</strong></li></ul><blockquote><p>使用docker run –name nginx-test -p 8080:80 -d -v ~/myvolume:/usr/share/nginx/html nginx  创建一个bind mount 数据卷 是宿主机的存储位置必须是绝对路径。目录不存在则会生成</p></blockquote><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下两种情况创建的数据卷如果浏览器访问宿主机的ip:8080 会出现报错，因为这是创建的时候清空了容器数据卷下index.html</span></span><br><span class="line"><span class="comment"># 创建的宿主机和容器的数据卷都有读写的权限</span></span><br><span class="line">$ docker run <span class="params">--name</span> nginx-test -p 8080<span class="function">:80</span> -d -v ~<span class="string">/myvolume</span>:<span class="string">/usr/share/nginx/html</span> nginx</span><br><span class="line"><span class="comment"># 这样执行后的文件宿主机的~/myvolume 文件如果不存在直接创建，容器的文件路径不存在也会直接创建，如果/usr/share/nginx/html文件存在里面内容会清空</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 给容器里面的数据卷加权限</span></span><br><span class="line">$ docker run <span class="params">--name</span> nginx-test -p 8080<span class="function">:80</span> -d -v ~<span class="string">/myvolume</span>:<span class="string">/usr/share/nginx/html</span><span class="function">:ro</span> nginx</span><br><span class="line"><span class="comment"># 如果执行这个 :/usr/share/nginx/html:ro这个地方加的是 :ro 是设置的只有读取权限</span></span><br></pre></td></tr></table></figure><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行dockers inspect 容器名称或容器（ID） 是将容器的配置文件已json字符串的形式返回</span></span><br><span class="line"><span class="string">"Binds"</span>: [</span><br><span class="line">                <span class="string">"/root/myvolume:/usr/share/nginx/html"</span>   <span class="comment"># 宿主机数据卷位置: 容器的目录位置</span></span><br><span class="line">            ],</span><br><span class="line"></span><br><span class="line"><span class="string">"Mounts"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">"Type"</span>: <span class="string">"bind"</span>,</span><br><span class="line">                <span class="string">"Source"</span>: <span class="string">"/root/myvolume"</span>,   <span class="comment"># 是宿主机数据卷的存储位置</span></span><br><span class="line">                <span class="string">"Destination"</span>: <span class="string">"/usr/share/nginx/html"</span>,</span><br><span class="line">                <span class="string">"Mode"</span>: <span class="string">""</span>,</span><br><span class="line">                <span class="string">"RW"</span>: <span class="literal">true</span>,   <span class="comment"># 权限 true是可以读写 fales 是只读</span></span><br><span class="line">                <span class="string">"Propagation"</span>: <span class="string">"rprivate"</span></span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br></pre></td></tr></table></figure><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 在宿主机的数据卷下执行:</span></span><br><span class="line">vim index.html </span><br><span class="line"><span class="meta"># 在文件里写入hello ， 你在访问的时候就可以在页面上看到你写入得数据了</span></span><br></pre></td></tr></table></figure><blockquote><p>执行 docker exec -it 容器名称（容器ID） bahs进入到容器里面，每个容器都会包含一个迷你版的linux系统</p><p>执行 cd /usr/share/nginx/html  </p><p>执行 ls</p><p>你会看到容器目录里会有我们刚才创建好的文件</p><p>index.html</p><p>执行 cat index.html  可以看到里面我们加入的数据</p><p>如果是挂载数据卷的时候加 <code>:ro</code> 容器内修改文件，发现会提示该文件是只读的  </p></blockquote><hr><ul><li><strong>docker managed volume 数据卷</strong><ul><li>创建出来的两个都是有读写权限的</li></ul></li></ul><blockquote><p>使用docker run –name nginx-test2 -p 8080:80 -d -v /usr/share/nginx/html nginx 创建一个<strong>docker managed volume 数据卷</strong> </p><p>这种命令创建是不用指定宿主机数据卷存储位置的默认在 /var/lib/docker/volumes/ 下的文件名是经过<code>sha256</code> 摘要过的</p></blockquote><ul><li>查看宿主机创建出来的数据卷</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd  /var/<span class="class"><span class="keyword">lib</span>/<span class="title">docker</span>/<span class="title">volumes</span>/</span></span><br><span class="line">$ ls </span><br><span class="line"><span class="number">8</span>d668720aaeccee44b5fb554571912a6a257eb3a28cecf334203805a0c9b6fd3  <span class="comment">#这是自己创建出来的数据卷</span></span><br><span class="line"><span class="comment"># 执行 cd _data 进入这这个文件夹里面</span></span><br><span class="line">$ ls</span><br><span class="line"><span class="number">50</span>x.html  index.html   <span class="comment"># 这两个文件是把容器里文件给拷贝了出来</span></span><br></pre></td></tr></table></figure><blockquote><p>可以在宿主机或者容器里面都可以对文件进行读写操作</p></blockquote><h5 id="挂载多个目录实现数据卷的"><a href="#挂载多个目录实现数据卷的" class="headerlink" title="挂载多个目录实现数据卷的"></a>挂载多个目录实现数据卷的</h5><ul><li>就是执行多个 <code>-v</code> 就可以</li></ul><h5 id="容器间的数据共享"><a href="#容器间的数据共享" class="headerlink" title="容器间的数据共享"></a>容器间的数据共享</h5><ul><li>数据卷容器挂载了一个本地文件系统的目录，其它容器通过挂载这个数据卷容器来实现容器间的数据的共享；</li></ul><p><img src="/docker存储/20180524134945342.png" alt="这里写图片描述"></p><h5 id="容器间挂载"><a href="#容器间挂载" class="headerlink" title="容器间挂载"></a>容器间挂载</h5><blockquote><p>创建数据卷，只要在<code>docker run</code>命令后面跟上<code>-v</code>参数即可创建一个数据卷，当然也可以跟多个<code>-v</code>参数来创建多个数据卷，当创建好带有数据卷的容器后，就可以在其他容器中通过<code>--volumes-from</code>参数来挂载该数据卷了，而不管该容器是否运行。</p></blockquote><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">docker</span> <span class="comment">run</span> <span class="literal">-</span><span class="comment">tid</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">rm</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">volumes</span><span class="literal">-</span><span class="comment">from</span> <span class="comment">nginx</span><span class="literal">-</span><span class="comment">test</span> <span class="literal">-</span><span class="literal">-</span><span class="comment">name</span> <span class="comment">nginx</span><span class="literal">-</span><span class="comment">test3</span> <span class="comment">nginx</span></span><br></pre></td></tr></table></figure><blockquote><p>-i  : 以交互模式运行容器，通常与 -t 同时使用；</p><p>-t  : 为容器重新分配一个伪输入终端，通常与 -i 同时使用；</p><p>-d : 后台运行容器，并返回容器ID；</p></blockquote><ul><li>再创建一个nginx-test4，挂载nginx-test3中从nginx-test挂载的数据卷，当然也可以直接挂载初识的nginx-test容器的数据卷</li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">* </span>即使删除了初始的数据卷容器 nginx-test，或者是删除了其他容器，但只要是有容器在使用该数据卷，那么它里面的数据就不会丢失</span><br><span class="line"><span class="bullet">* </span>命令中的rm表示当容器退出即停止的时候，会自动删除该容器</span><br></pre></td></tr></table></figure><hr><h5 id="备份数据卷"><a href="#备份数据卷" class="headerlink" title="备份数据卷"></a>备份数据卷</h5><ul><li>创建一个容器container1，包含两个数据卷/usr/share/nginx/html1和/usr/share/nginx/html2（这两个目录是在容器里的数据卷路径）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container1 -p 8080:80 nginx</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建容器container1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker <span class="built_in">exec</span> -it container1 bash   <span class="comment">#进入创建好的容器里面</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> html1/  <span class="comment"># 进入到html1数据卷中</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> html1 &gt;&gt; 1.text <span class="comment"># 向 1.text 文件中追加数据，文件不存在则会创建文件</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> html2/  <span class="comment"># 进入到html2数据卷中</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> html2 &gt;&gt; 2.text <span class="comment"># 向 2.text 文件中追加数据，文件不存在则会创建文件</span></span></span><br></pre></td></tr></table></figure><ul><li>接下来进行数据卷的备份操作</li></ul><blockquote><p>使用  - -volumes-from 来创建一个加载 container1 容器卷的容器，并从宿主机挂载当前所在目录到容器的 /backup 目录，容器内会 tar 压缩 /var/colume1 目录下的文件到 /backup/backup1.tar，因为宿主机当前目录已经映射到 /backup 目录了，因此会在宿主机当前目录也存在该压缩包。备份完毕后 -rm 自动删除该创建的容器。</p></blockquote><ul><li>备份container1容器中的/usr/share/nginx/html1数据卷数据</li></ul><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份container1容器中的/usr/share/nginx/html1数据卷数据</span></span><br><span class="line"><span class="comment"># -tid 这个参数加不加都可以</span></span><br><span class="line"><span class="comment"># --rm 加上，备份后就会自动删除这个容器，如果不加这个 --rm 参数，name备份后的容器就会保留，docker ps -a就会查看到）</span></span><br><span class="line"><span class="comment"># $(pwd) </span></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]<span class="comment"># pwd</span></span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]<span class="comment"># docker run -tid --rm --volumes-from container1 -v $(pwd):/backup nginx tar cvf /backup/backup1.tar /usr/share/nginx/html1</span></span><br><span class="line">b3663a3bdd302a38036d6a156471cd448c8e5b9333a20f9480b3c61cbd9270df</span><br><span class="line"></span><br><span class="line">[root@iz2zefaujekcdpmfw1qs4az ~]<span class="comment"># ls</span></span><br><span class="line">backup1.tar</span><br></pre></td></tr></table></figure><blockquote><ul><li>–volumes-from [containerName]：这个命令来指定需要备份的容器的名字；（数据卷容器的名字）</li><li>-v $(pwd):/backup:权限：使用-v命令来指定希望备份文件存放的位置；本地存放目录：容器存放目录：读写权限；（默认权限是读写）</li><li>tar cvf /backup/backup.tar [container data volume]：tar表示执行备份的操作是：压缩文件的命令；</li><li>/backup/backup.tar是文件存放的地址， [container data volume]指定需要备份的目录；</li><li>tar cvf 压缩；tar xvf解压缩；</li></ul></blockquote><ul><li>备份container1容器中的/usr/share/nginx/html2数据卷数据</li></ul><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 备份container1容器中的/usr/share/nginx/html2数据卷数据</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-<span class="keyword">from</span> container1 -v $(pwd):/backup nginx tar cvf /backup/backup2.tar /usr/share/nginx/html2</span><br><span class="line"><span class="number">001129</span>bc393d5d0ed4665d053d4ca7972584cf2bd56980064be182ec758138cd</span><br><span class="line"></span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# ll</span><br><span class="line">total <span class="number">22464</span></span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">18</span>:<span class="number">52</span> backup1.tar  # 文件<span class="number">1</span></span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">19</span>:<span class="number">05</span> backup2.tar  # 文件<span class="number">2</span></span><br><span class="line">drwxr-xr-x <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">16</span> <span class="number">16</span>:<span class="number">45</span> myvolume</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root <span class="number">22973527</span> Mar <span class="number">26</span>  <span class="number">2019</span> Python<span class="number">-3.7</span><span class="number">.3</span>.tgz</span><br></pre></td></tr></table></figure><ul><li>备份container1 容器中的 /usr/share/nginx/html1 和 /usr/share/nginx/html2 数据卷数据</li></ul><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#  备份container1 容器中的 /usr/share/nginx/html2 和 /usr/share/nginx/html2 数据卷数据</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line"></span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# docker run -tid --rm --volumes-<span class="keyword">from</span> container1 -v $(pwd):/backup nginx tar cvf /backup/backup.tar /usr/share/nginx/html1</span><br><span class="line">/usr/share/nginx/html2</span><br><span class="line"><span class="number">441</span>df929e123cbe51564ca3d6bf3f06a5ea415298a34bb9871f1ed2b68a60102</span><br><span class="line"></span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# ll</span><br><span class="line">total <span class="number">22476</span></span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">18</span>:<span class="number">52</span> backup1.tar</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">19</span>:<span class="number">05</span> backup2.tar</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">19</span>:<span class="number">09</span> backup.tar</span><br><span class="line">drwxr-xr-x <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">16</span> <span class="number">16</span>:<span class="number">45</span> myvolume</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root <span class="number">22973527</span> Mar <span class="number">26</span>  <span class="number">2019</span> Python<span class="number">-3.7</span><span class="number">.3</span>.tgz</span><br></pre></td></tr></table></figure><h5 id="恢复数据给同一个容器"><a href="#恢复数据给同一个容器" class="headerlink" title="恢复数据给同一个容器"></a>恢复数据给同一个容器</h5><blockquote><p>之前的数据卷是从 container1 中备份的，现在模拟 container1 数据卷丢失，然后直接用之前备份的 backup.tar 进行恢复</p></blockquote><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了测试恢复，先删除容器里原先的数据（注意：数据卷目录不能删除，只能删除其中的数据）</span></span><br><span class="line">[root<span class="variable">@iz2zefaujekcdpmfw1qs4az</span> ~]<span class="comment"># docker exec -it container1 bash </span></span><br><span class="line"><span class="comment">#进入到创建的容器里</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/</span><span class="comment"># ls</span></span><br><span class="line">bin  boot  devetc  home  liblib64  media  mnt  optproc  root  run  sbin  srv  sys  tmp  usr  var</span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/</span><span class="comment"># cd /usr/share/nginx  </span></span><br><span class="line"><span class="comment">#进入到容器里面的数据卷所在的目录</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># ls</span></span><br><span class="line">html  html1  html2  </span><br><span class="line"></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># cd html1</span></span><br><span class="line"><span class="comment"># 进入到 html1 数据卷目录</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx/html1</span><span class="comment"># ls</span></span><br><span class="line"><span class="number">1</span>.text</span><br><span class="line"></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx/html1</span><span class="comment"># rm -rf 1.text </span></span><br><span class="line"><span class="comment"># 删除 1.text 文件</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx/html1</span><span class="comment"># ls</span></span><br><span class="line"></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># cd html2</span></span><br><span class="line"><span class="comment"># 进入到 html2 的数据卷目录</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx/html2</span><span class="comment"># ls</span></span><br><span class="line"><span class="number">2</span>.text</span><br><span class="line"></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx/html2</span><span class="comment"># rm -rf 2.text </span></span><br><span class="line"><span class="comment"># 删除 2.text 文件</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx/html2</span><span class="comment"># ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行数据卷恢复，恢复数据卷中的所有数据</span></span><br><span class="line">注意-C后面的路径，表示将数据恢复到容器里的路径直接使用压缩包中文件的各个路径。比如压缩包中的结果如下：</span><br><span class="line">tar -xvf backup.tar   <span class="comment">#解压压缩文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据1</span></span><br><span class="line">usr/share/nginx/html1/<span class="number">1</span>.text</span><br><span class="line">--usr</span><br><span class="line">--share</span><br><span class="line">--nginx</span><br><span class="line">--html1</span><br><span class="line">--<span class="number">1</span>.text</span><br><span class="line"><span class="comment"># 数据2</span></span><br><span class="line">usr/share/nginx/html2/<span class="number">2</span>.text</span><br><span class="line">--usr</span><br><span class="line">--share</span><br><span class="line">--nginx</span><br><span class="line">--html2</span><br><span class="line">--<span class="number">2</span>.text</span><br><span class="line"><span class="comment"># 直接将文件解压到 /usr/share/nginx/html1 和 /usr/share/nginx/html2 目录</span></span><br><span class="line">[root<span class="variable">@iz2zefaujekcdpmfw1qs4az</span> ~]<span class="comment"># docker run --rm --volumes-from container1 -v $(pwd):/backup nginx tar xvf /backup/backup.tar -C /</span></span><br><span class="line">usr/share/nginx/html1/</span><br><span class="line">usr/share/nginx/html1/<span class="number">1</span>.text</span><br><span class="line">usr/share/nginx/html2/</span><br><span class="line">usr/share/nginx/html2/<span class="number">2</span>.text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接进入容器查看</span></span><br><span class="line">[root<span class="variable">@iz2zefaujekcdpmfw1qs4az</span> ~]<span class="comment"># docker exec -it container1 bash</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/</span><span class="comment"># cd /usr/share/nginx/ </span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># ls</span></span><br><span class="line">html  html1  html2</span><br><span class="line"><span class="comment"># 查看数据是否存在</span></span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># ls html1</span></span><br><span class="line"><span class="number">1</span>.text</span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># ls html2</span></span><br><span class="line"><span class="number">2</span>.text</span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># cat html1/1.text </span></span><br><span class="line">html1</span><br><span class="line">root<span class="variable">@6869560e6ff5</span><span class="symbol">:/usr/share/nginx</span><span class="comment"># cat html2/2.text </span></span><br><span class="line">html2</span><br></pre></td></tr></table></figure><ul><li><h5 id="如果你备份的数据里面有，不是设置的数据卷里面的数据，使用这个命令是恢复不了的（恢复的是设置的数据卷里面的数据）"><a href="#如果你备份的数据里面有，不是设置的数据卷里面的数据，使用这个命令是恢复不了的（恢复的是设置的数据卷里面的数据）" class="headerlink" title="!  如果你备份的数据里面有，不是设置的数据卷里面的数据，使用这个命令是恢复不了的（恢复的是设置的数据卷里面的数据）"></a><strong>!</strong>  如果你备份的数据里面有，不是设置的数据卷里面的数据，使用这个命令是恢复不了的（恢复的是设置的数据卷里面的数据）</h5></li><li><h5 id="你可以创一个新的容器多一个，你数据卷挂载你备份数据时候，备份的文件的路径就可以解决了"><a href="#你可以创一个新的容器多一个，你数据卷挂载你备份数据时候，备份的文件的路径就可以解决了" class="headerlink" title="你可以创一个新的容器多一个，你数据卷挂载你备份数据时候，备份的文件的路径就可以解决了"></a>你可以创一个新的容器多一个，你数据卷挂载你备份数据时候，备份的文件的路径就可以解决了</h5></li></ul><h5 id="恢复数据给新的容器"><a href="#恢复数据给新的容器" class="headerlink" title="恢复数据给新的容器"></a>恢复数据给新的容器</h5><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 新建一个容器container2</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# docker run -tid -v /usr/share/nginx/html1 -v /usr/share/nginx/html2 --name container2 nginx</span><br><span class="line"><span class="number">89</span>abb55858fb1e3dddc07c2066d05614349aaf78ba446a1ea12f1241b98e4896</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line"><span class="number">89</span>abb55858fb        nginx               <span class="string">"/bin/bash"</span>         <span class="number">9</span> seconds ago       Up <span class="number">8</span> seconds        <span class="number">80</span>/tcp              container2</span><br><span class="line"><span class="number">6869560e6f</span>f5        nginx               <span class="string">"/bin/bash"</span>         <span class="number">2</span> hours ago         Up <span class="number">2</span> hours          <span class="number">80</span>/tcp              container1</span><br><span class="line"></span><br><span class="line"># 开始恢复数据</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# pwd</span><br><span class="line">/root</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# ll</span><br><span class="line">total <span class="number">22476</span></span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">18</span>:<span class="number">52</span> backup1.tar</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">19</span>:<span class="number">05</span> backup2.tar</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root    <span class="number">10240</span> Dec <span class="number">16</span> <span class="number">19</span>:<span class="number">09</span> backup.tar</span><br><span class="line">drwxr-xr-x <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">16</span> <span class="number">16</span>:<span class="number">45</span> myvolume</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root <span class="number">22973527</span> Mar <span class="number">26</span>  <span class="number">2019</span> Python<span class="number">-3.7</span><span class="number">.3</span>.tgz</span><br><span class="line"></span><br><span class="line"># 恢复数据</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# docker run --rm --volumes-<span class="keyword">from</span> container2 -v $(pwd):/backup nginx tar xvf /backup/backup.tar -C /</span><br><span class="line">usr/share/nginx/html1/</span><br><span class="line">usr/share/nginx/html1/<span class="number">1.</span>text</span><br><span class="line">usr/share/nginx/html2/</span><br><span class="line">usr/share/nginx/html2/<span class="number">2.</span>text</span><br><span class="line"></span><br><span class="line"># 查看确实已经恢复了</span><br><span class="line">[<span class="symbol">root@</span>iz2zefaujekcdpmfw1qs4az ~]# docker exec -it container2 bash</span><br><span class="line"><span class="symbol">root@</span><span class="number">89</span>abb55858fb:/# ls /usr/share/nginx/</span><br><span class="line">html  html1  html2</span><br><span class="line"><span class="symbol">root@</span><span class="number">89</span>abb55858fb:/# ls /usr/share/nginx/html1</span><br><span class="line"><span class="number">1.</span>text</span><br><span class="line"><span class="symbol">root@</span><span class="number">89</span>abb55858fb:/# ls /usr/share/nginx/html2</span><br><span class="line"><span class="number">2.</span>text</span><br><span class="line"><span class="symbol">root@</span><span class="number">89</span>abb55858fb:/# cat /usr/share/nginx/html1/<span class="number">1.</span>text </span><br><span class="line">html1</span><br><span class="line"><span class="symbol">root@</span><span class="number">89</span>abb55858fb:/# cat /usr/share/nginx/html2/<span class="number">2.</span>text </span><br><span class="line">html2</span><br></pre></td></tr></table></figure><blockquote><p>注意：</p><ul><li><p>–volumes-from [containerName]：这个命令来指定需要备份的容器的名字；（数据卷容器的名字）</p></li><li><p>-v $(pwd):/backup:权限：使用-v命令来指定希望备份文件存放的位置；本地存放目录：容器存放目录：读写权限；（默认权限是读写）</p></li><li><p>tar cvf /backup/backup.tar [container data volume]：tar表示执行备份的操作是：压缩文件的命令；</p></li><li><p>/backup/backup.tar是文件存放的地址， [container data volume]指定需要备份的目录；</p></li><li><p>tar cvf 压缩；tar xvf解压缩；</p></li><li><p>新容器创建时挂载的数据卷路径最好和之前备份的数据卷路径一致</p></li><li><p>新容器创建时，如果挂载的数据卷只是备份卷的一部分，那么恢复的时候也只是恢复一部分数据。</p></li><li><p>比如新建容器挂载数据卷为 <code>-v /usr/share/nginx/html1</code> ,那么使用 <code>backup.tar</code> 恢复时，只会恢复 <code>/usr/share/nginx/html1</code> 的数据， <code>/usr/share/nginx/html2</code> 的数据是不会恢复的</p></li><li><p>比如新容器创建时挂载的数据卷目录和备份的数据卷目录不一致，那么数据恢复不了，除非修改 - C 后面的路径，比如新建容器时指定数据卷目录为 <code>/usr/share/nginx/html</code> ，恢复时也是用 <code>-C /usr/share/nginx/html</code>，则是可以成功恢复的</p></li></ul></blockquote><h5 id="删除数据卷"><a href="#删除数据卷" class="headerlink" title="删除数据卷"></a>删除数据卷</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">volume</span><span class="bash"> ls     列出所有的数据卷</span></span><br><span class="line">docker <span class="keyword">volume</span><span class="bash"> ls --filter dangling=<span class="literal">true</span>     过滤不在使用的数据卷</span></span><br><span class="line">docker <span class="keyword">volume</span><span class="bash"> rm [volume name]     删除一个数据卷，容器正在使用的数据卷不能删除，绑定挂载的数据卷无法删除</span></span><br></pre></td></tr></table></figure><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume rm <span class="keyword">my</span>-volio  删除数据卷 <span class="keyword">my</span>-volio</span><br></pre></td></tr></table></figure><blockquote><p>数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。</p></blockquote><ul><li>无主的数据卷可能会占据很多空间，要清理请使用以下命令</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="keyword">volume</span><span class="bash"> prune</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;#Docker 存储&lt;/p&gt;&lt;h3 id=&quot;Docek-镜像层的镜像分层结构&quot;&gt;&lt;a href=&quot;#Docek-镜像层的镜像分层结构&quot; class=&quot;headerlink&quot; title=&quot;Docek 镜像层的镜像分层结构&quot;&gt;&lt;/a&gt;Docek 镜像层的镜像分层结构&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;docker的镜像分层结构，如下所示：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;/docker存储/container-layers.jpg&quot; alt=&quot;基于Ubuntu映像的容器层&quot;&gt;&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;docker镜像中引入层layer概念，镜像的制作过程中的每一步都会生产一个新的镜像层&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;容器读写层的工作原理&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们刚刚在说镜像的分层特性的时候说到镜像是只读的。而事实上当我们使用镜像启动一个容器的时候，我们其实是可以在容器里随意读写的，从结果上看，似乎与镜像的只读特性相悖。&lt;/p&gt;
&lt;p&gt;我们继续看上面的图，其实可以看到在镜像的最上层，还有一个读写层。而这个读写层，即在容器启动时为当前容器单独挂载。每一个容器在运行时，都会基于当前镜像在其最上层挂载一个读写层。而用户针对容器的所有操作都在读写层中完成。一旦容器销毁，这个读写层也随之销毁。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;知识点： 容器=镜像+读写层&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而我们针对这个读写层的操作，主要基于两种方式：写时复制和用时分配。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://cy-blogs.cn/categories/Docker/"/>
    
    
      <category term="Docker" scheme="https://cy-blogs.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Linux用户组及权限管理</title>
    <link href="https://cy-blogs.cn/Linux%E7%94%A8%E6%88%B7%E7%BB%84%E5%8F%8A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"/>
    <id>https://cy-blogs.cn/Linux用户组及权限管理/</id>
    <published>2019-12-11T05:10:16.031Z</published>
    <updated>2019-12-11T04:56:36.622Z</updated>
    
    <content type="html"><![CDATA[<h3 id="用户和组"><a href="#用户和组" class="headerlink" title="用户和组"></a>用户和组</h3><hr><blockquote><p><code>Linux</code> 是哟个多用户的操作系统，引入用户，可以更加方便管理 <code>Linux</code> 服务器</p><p>系统默认需要以一个用户的身份登入，而且在系统上启动进程也需要以一个用户身份器运行，用户可以限制某些进程对特定资源的权限控制</p></blockquote><a id="more"></a><h3 id="Linux用户及组"><a href="#Linux用户及组" class="headerlink" title="Linux用户及组"></a>Linux用户及组</h3><hr><blockquote><p><code>Linux</code> 操作系统对多用户的管理，是非常繁琐的，所以用组的概念来管理用户就变到的简单，每个用户可以在一个独立的组，每个组也可以有零个用户或者多个用户。</p><p><code>Linux</code> 系统用户是根据用户 <code>ID</code> 来识别的，默认 <code>ID</code> 长度为 <code>32</code> 位，默认 <code>ID</code> 编号从 <code>0</code> 开始，但是为了和老式系统兼容，用户 <code>ID</code>限制在 <code>60000</code>一下， <code>Linux</code> 用户总共分为三种，分别如下：</p></blockquote><ul><li>超级用户： <code>root</code>， <code>ID</code> 为0</li><li>系统用户：<code>ID</code> 从1 到499</li><li>普通用户：<code>ID</code>为500以上</li></ul><blockquote><p><code>Linux</code> 系统中的每个文件或者文件夹，都有一个所属用户及所属组</p><p>使用 <code>ID</code> 命令可以显示当前用户的信息，使用 <code>passwd</code> 命令可以修改当前用户密码。 <code>Linux</code>操作系统用户的特点如下</p></blockquote><ul><li>每个用户拥有一个 <code>UserID</code>，操作系统实际读取的是 <code>UID</code>，而非用户名；</li><li>每个用户属于一个主组；属于一个或多个附属组，一个用户最多有 <code>31</code>个附属组；</li><li>每个组用有一个 <code>GroupID</code>;</li><li>每个进程以一个用户身份进行，该用户可以对进程拥有资源控制权限；</li><li>每个可登录用户拥有一个指定的 <code>Shell</code>环境</li></ul><h4 id="创建新用户"><a href="#创建新用户" class="headerlink" title="创建新用户"></a>创建新用户</h4><hr><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">useradd</span> usertest <span class="comment"># 创建用户usertest</span></span><br></pre></td></tr></table></figure><blockquote><p>创建新用户，可以使用命令<code>useradd</code>，执行命令即可创建新用户</p><p>同时会创建一个同名的组，默认该用户属于该用户组</p></blockquote><blockquote><p>创建用户，会根据如下步骤进行操作</p></blockquote><ul><li>在<code>/etc/passwd</code>文件中添加用户信息</li><li>如使用<code>passwd</code>命令创建密码，密码会被加密保存在<code>/etc/shdaow</code>中</li><li>为用户创建家目录：<code>/home/usertest</code>，创建目录操作应操作系统而异</li><li>将<code>/etc/skel</code>中的<code>.bash</code>开头的文件复制至用户家目录</li><li>创建与用户名相同的组，该用户默认属于这个同名组，组信息保存在<code>/etc/group</code>配置文件中</li></ul><blockquote><p>其他命令可选参数如下所示</p></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-d <span class="comment"># 指定新用户的主目录-G # 指定新用户的组列表-s # 新用户所使用的shell环境</span></span><br><span class="line">useradd usertest -s <span class="regexp">/bin/</span>bash -d <span class="regexp">/home/u</span>sertest<span class="comment"># 创建新用户usertest，指定shell环境为bash，主目录在/home/usertest</span></span><br></pre></td></tr></table></figure><h4 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h4><hr><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">userdel # 保留用户的家目录userdel –r usertest # 删除用户及用户家目录，用户login系统无法删除userdel –rf usertest # 强制删除用户及该用户家目录，不论是否login系统</span><br></pre></td></tr></table></figure><blockquote><p>当一个用户创建之后，我们可以通过<code>usermod</code>命令来修改用户及组的属性</p></blockquote><ul><li><code>linux</code>下命令选项</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">选项：  -c, --comment 注释            GECOS 字段的新值  -d, --home HOME_DIR           用户的新主目录  -e, --expiredate EXPIRE_DATE  设定帐户过期的日期为 EXPIRE_DATE  -f, --inactive INACTIVE       过期 INACTIVE 天数后，设定密码为失效状态  -g, --gid<span class="built_in"> GROUP </span>              强制使用<span class="built_in"> GROUP </span>为新主组  -G, --groups GROUPS           新的附加组列表 GROUPS  -a, --append<span class="built_in"> GROUP </span>           将用户追加至上边 -G 中提到的附加组中，                                并不从其它组中删除此用户  -h, --help                    显示此帮助信息并推出  -l, --login LOGIN             新的登录名称  -L, --lock                    锁定用户帐号  -m, --move-home               将家目录内容移至新位置 (仅于 -d 一起使用)  -o, --non-unique              允许使用重复的(非唯一的) UID  -p, --password PASSWORD       将加密过的密码 (PASSWORD) 设为新密码  -R, --root CHROOT_DIR         chroot 到的目录  -s, --shell SHELL             该用户帐号的新登录 shell  -u, --uid UID                 用户帐号的新 UID  -U, --unlock                  解锁用户帐号  -Z, --selinux-user  SEUSER       用户账户的新 SELinux 用户映射</span><br><span class="line">groups username# 查看用户所属组</span><br></pre></td></tr></table></figure><h4 id="修改用户所属组"><a href="#修改用户所属组" class="headerlink" title="修改用户所属组"></a>修改用户所属组</h4><hr><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">usermod usertest -G old_normal# 将用户usertest修改加入old_normal组中</span><br><span class="line">usermod usertest -a -G other_normal# 将用户追加至other_normal组中，且不影响原有组状态</span><br><span class="line">cat /etc<span class="built_in">/group </span>| grep usertest # 可以查看到usertest用户当前所属组的情况</span><br></pre></td></tr></table></figure><h4 id="修改用户家目录及启动shell"><a href="#修改用户家目录及启动shell" class="headerlink" title="修改用户家目录及启动shell"></a>修改用户家目录及启动shell</h4><hr><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod usertest -d /home<span class="built_in">/user </span>-s /bin/sh</span><br></pre></td></tr></table></figure><h4 id="修改用户名"><a href="#修改用户名" class="headerlink" title="修改用户名"></a>修改用户名</h4><hr><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod -l <span class="keyword">new</span> <span class="keyword">old</span># 将<span class="keyword">old</span>用户名变为<span class="keyword">new</span></span><br></pre></td></tr></table></figure><h4 id="锁定-解锁用户"><a href="#锁定-解锁用户" class="headerlink" title="锁定/解锁用户"></a>锁定/解锁用户</h4><hr><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod -L usertest;# 锁定usertest用户usermod -U usertest;# 解锁usertest用户</span><br></pre></td></tr></table></figure><h3 id="Linux组管理"><a href="#Linux组管理" class="headerlink" title="Linux组管理"></a>Linux组管理</h3><hr><blockquote><p>所有的<code>Linux</code>或者<code>Windows</code>系统都有组的概念，通过组可以更加方便的管理用户</p><p>组的概念应用于各行行业，例如企业会使用部门、职能或地理区域的分类方式来管理成员，映射在<code>Linux</code>系统，同样可以创建用户，并用组的概念对其管理</p><p>Linux组有如下特点</p></blockquote><ul><li>每个组有一个组<code>ID</code></li><li>组信息保存在<code>/etc/group</code>中</li><li>每个用户至少拥有一个主组，同时还可以拥有<code>31</code>个附属组</li></ul><h4 id="创建新组"><a href="#创建新组" class="headerlink" title="创建新组"></a>创建新组</h4><hr><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">groupadd <span class="keyword">normal</span> <span class="comment"># 创建normal组</span></span><br><span class="line">groupadd -g <span class="number">1000</span> <span class="keyword">normal</span> <span class="comment"># 创建ID为1000的分组</span></span><br></pre></td></tr></table></figure><h4 id="其他组属性"><a href="#其他组属性" class="headerlink" title="其他组属性"></a>其他组属性</h4><hr><blockquote><p>常见参数</p></blockquote><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-r # 系统账户-f # 如果指定的组已经存在，则退出-g # 指定当前组id-n --new --old # 修改组名</span><br><span class="line">groupmod -n old_normal normal# 修改normal组名为old_normal</span><br><span class="line">groupmod -g <span class="number">1001</span> old_normal# 修改old_normal组id为<span class="number">1001</span></span><br></pre></td></tr></table></figure><h2 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h2><blockquote><p>设置好了用户和组，那么接下来就可以对其进行权限控制</p><p>由于linux下处处皆文件，所谓权限也就是对文件的<strong>读</strong>、<strong>写</strong>、<strong>执行</strong>，至少这三种</p><p>当操作系统下某个进程在运行时，进程的权限，也相当于这个进程的运行用户身份权限</p></blockquote><table><thead><tr><th align="left">权限</th><th align="left">文件</th><th align="left">目录</th></tr></thead><tbody><tr><td align="left">r</td><td align="left">读取文件</td><td align="left">列出目录</td></tr><tr><td align="left">w</td><td align="left">修改文件</td><td align="left">修改目录内文件</td></tr><tr><td align="left">x</td><td align="left">执行文件</td><td align="left">进入目录</td></tr></tbody></table><ul><li>权限分组</li></ul><blockquote><p>默认的linux的权限分为三种角色</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; user`、`group`、`other</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>每个文件将基于<strong>UGO</strong>三种权限进行设置</p><p>一般一个文件创建之后，谁创建该文件，默认成为该文件的所有者</p></blockquote><h3 id="用户及组权限"><a href="#用户及组权限" class="headerlink" title="用户及组权限"></a>用户及组权限</h3><hr><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls -ahl# 查看文件所有者</span><br><span class="line">chmod g+rwx <span class="meta">file</span># 给<span class="meta">file</span>文件增加rwx权限chmod g-<span class="meta">x</span> <span class="meta">file</span># 给<span class="meta">file</span>文件减少<span class="meta">x</span>权限</span><br></pre></td></tr></table></figure><h3 id="用户及组修改"><a href="#用户及组修改" class="headerlink" title="用户及组修改"></a>用户及组修改</h3><hr><blockquote><p>修改某个文件或目录所属<strong>用户</strong>或<strong>组</strong></p></blockquote><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R root <span class="keyword">file</span># 修改<span class="keyword">file</span>文件所属用户为root</span><br><span class="line">chown -R :root <span class="keyword">file</span># 修改<span class="keyword">file</span>文件所属用户为rootchgrp -R root <span class="keyword">file</span># 修改<span class="keyword">file</span>文件所属组为root</span><br></pre></td></tr></table></figure><h3 id="二进制权限"><a href="#二进制权限" class="headerlink" title="二进制权限"></a>二进制权限</h3><hr><blockquote><p>linux下具备权限设置为1，反之为0，那么一个权限按照二进制位数来计算，如下所示</p></blockquote><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--x: <span class="number">001</span> <span class="number">1</span>-wx: <span class="number">011</span> <span class="number">3</span>rwx: <span class="number">111</span> <span class="number">7</span></span><br></pre></td></tr></table></figure><blockquote><p>很清晰，对应的权限位置所代表的数字分别是：<strong>r=4</strong>，<strong>w=2</strong>，<strong>x=1</strong></p></blockquote><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 775 <span class="meta">file</span># 修改<span class="meta">file</span>文件权限为 rwxrwxr-<span class="meta">x</span></span><br></pre></td></tr></table></figure><h3 id="权限掩码"><a href="#权限掩码" class="headerlink" title="权限掩码"></a>权限掩码</h3><hr><blockquote><p>神奇的事情需要我们考虑，每次创建文件，默认都会具备一定的权限，而这个权限是如何分配而来的呢？</p><p>是通过一个叫做权限掩码的东西来维护的，这个码可以通过<strong>umask</strong>命令看到</p><p>默认系统的掩码是<strong>022</strong></p></blockquote><ul><li>文件权限由默认权限减去掩码</li></ul><blockquote><p>文件默认权限：666<br>那么创建一个文件真实的权限是：666-022=644</p></blockquote><blockquote><p>目录的默认权限：777</p><p>一个目录的真实权限是：777-022=755</p></blockquote><ul><li>设置默认掩码</li></ul><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">umask -S <span class="number">011</span></span><br></pre></td></tr></table></figure><h3 id="特殊权限"><a href="#特殊权限" class="headerlink" title="特殊权限"></a>特殊权限</h3><hr><table><thead><tr><th align="left">权限</th><th align="left">对文件的影响</th><th align="left">对目录的影响</th></tr></thead><tbody><tr><td align="left"><strong>suid</strong></td><td align="left">以文件的所属用户身份执行，而非执行文件的用户</td><td align="left">无</td></tr><tr><td align="left"><strong>sgid</strong></td><td align="left">以文件所属组身份去执行</td><td align="left">在该目录中创建任意新文件的所属组与该目录的所属组相同</td></tr><tr><td align="left"><strong>sticky</strong></td><td align="left">无</td><td align="left">对目录拥有写入权限的用户仅可以删除其拥有的文件，无法删除其他用户所拥有的文件</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;用户和组&quot;&gt;&lt;a href=&quot;#用户和组&quot; class=&quot;headerlink&quot; title=&quot;用户和组&quot;&gt;&lt;/a&gt;用户和组&lt;/h3&gt;&lt;hr&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Linux&lt;/code&gt; 是哟个多用户的操作系统，引入用户，可以更加方便管理 &lt;code&gt;Linux&lt;/code&gt; 服务器&lt;/p&gt;
&lt;p&gt;系统默认需要以一个用户的身份登入，而且在系统上启动进程也需要以一个用户身份器运行，用户可以限制某些进程对特定资源的权限控制&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://cy-blogs.cn/categories/Linux/"/>
    
    
      <category term="Linux用户组及权限管理" scheme="https://cy-blogs.cn/tags/Linux%E7%94%A8%E6%88%B7%E7%BB%84%E5%8F%8A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用命令</title>
    <link href="https://cy-blogs.cn/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://cy-blogs.cn/linux常用命令/</id>
    <published>2019-12-11T05:10:16.027Z</published>
    <updated>2019-12-11T03:56:22.829Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><hr><blockquote><p>随着IT产业的不断发展，<code>linux</code> 操作系统应用领域越来越广泛，尤其是近年来 <code>linux</code>在服务器领域飞速的发展，主要得益于 <code>linux</code>操作系统具备的如下优点</p></blockquote><a id="more"></a><ul><li>开源免费</li><li>系统迭代更新</li><li>系统性能稳定</li><li>安全性高</li><li>多任务/多用户</li><li>耗资源小，无需图形化界面</li><li>内核小</li><li>应用领域广泛</li><li>使用及入门容易</li></ul><h3 id="操作系统分类介绍"><a href="#操作系统分类介绍" class="headerlink" title="操作系统分类介绍"></a>操作系统分类介绍</h3><hr><blockquote><p>学习 <code>Linux</code> 操作系统，需要悬着不同的发行版本</p><p><code>Linux</code> 操作系统是一个大类别， <code>Linux</code> 操作系统主流发型版本包括： <code>Red Hat Linux</code> 、 <code>CentOS</code> , <code>Ubuntu</code> , <code>SUSE Linux</code>  , <code>Fedore Linux</code> 等，具体发行版本区别如下</p></blockquote><ul><li><code>Red Hat Linux</code></li></ul><blockquote><p> <code>Red Hat Linux</code>  是最早的 <code>Linux</code> 发行版本之一</p><p>同时也是最著名的 <code>Linux</code> 版本， <code>Red Hat Linux</code> 已经创造了自己的品牌，也是读者经常听到的 ’‘ 红帽操作系统’‘</p><p><code>Red Hat 1994</code> 年创立，目前公司全世界有 <code>3000</code> 多人，一直致力于开放的源代码体系，向用户提供一套完整的服务，这使得它特别适合在公共网络中使用</p><p>这个版本的 <code>Liunx</code> 也使用最新的内核，还拥有大多数人都需要使用的主要软件包</p></blockquote><ul><li><code>Centos</code></li></ul><blockquote><p>社区企业版操作系统（<code>Community Enterprise Operating System</code>，<code>CentOS</code>）是<code>Linux</code>发行版之一，它是来自于<code>Red Hat Enterprise Linux</code>依照开放源代码所编译而成。由于出自同样的源代码，因此有些要求高度稳定性的服务器以<code>CentOS</code>替代商业版的<code>Red Hat Enterprise Linux</code>使用。</p><p><code>CentOS</code>于<code>Red Hat Linux</code>不同之处在于<code>CentOS</code>并不包含封闭的源代码软件，可以开源免费使用，得到运维人员、企业、程序员的青睐，<code>CentOS</code>发行版操作系统是目前企业使用最多的系统之一</p><p><code>2016年12月12日</code>，<code>CentOS</code>基于<code>Red Hat Enterprise Linux的CentOS Linux 7 (1611)</code>系统正式对外发布</p></blockquote><ul><li><code>Ubuntu</code></li></ul><blockquote><p><code>Ubuntu</code>是一个以桌面应用为主的<code>Linux</code>操作系统，其名称来自非洲南部祖鲁语或豪萨语的“<code>ubuntu</code>”一词（译为吾帮托或乌班图），意思是“人性”、“我的存在是因为大家的存在”，是非洲传统的一种价值观</p><p><code>Ubuntu</code>基于<code>Debian</code>发行版和<code>GNOME</code>桌面环境，<code>Ubuntu</code>发行版操作系统的目标在于为一般用户提供一个最新的、同时稳定的以开放自由软件构建而成的操作系统，目前<code>Ubuntu</code>具有庞大的社区力量，用户可以方便地从社区获得帮助</p></blockquote><ul><li><code>SUSE Linux</code></li></ul><blockquote><p><code>SUSE</code>(发音 /ˈsuːsə/)，<code>SUSE Linux</code>出自德国，<code>SuSE Linux AG</code>公司发行维护的<code>Linux</code>发行版，是属于此公司的注册商标<code>2003年11月4日</code>，<code>Novell</code>表示将会对<code>SUSE</code>提出收购。收购的工作于<code>2004年1月</code>完成。</p><p><code>Novell</code>也向大家保证<code>SUSE</code>的开发工作仍会继续下去，<code>Novell</code>更把公司内全线电脑的系统换成<code>SUSE LINUX</code>，并同时表示将会把<code>SUSE</code>特有而优秀的系统管理程序 - <code>YaST2</code>以<code>GPL</code>授权释出</p></blockquote><ul><li><code>Fedora Linux</code></li></ul><blockquote><p><code>Fedora</code>是一个知名的<code>Linux</code>发行版，是一款由全球社区爱好者构建的面向日常应用的快速、稳定、强大的操作系统。</p><p>它允许任何人自由地使用、修改和重发布，无论现在还是将来。它由一个强大的社群开发。</p><p>这个社群的成员以自己的不懈努力，提供并维护自由、开放源码的软件和开放的标准。<code>Fedora</code>约每六个月会发布新版本</p></blockquote><h3 id="Linux命令"><a href="#Linux命令" class="headerlink" title="Linux命令"></a>Linux命令</h3><hr><p><code>cd</code> </p><blockquote><p>目录切换</p></blockquote><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">..</span>   <span class="comment">#上一层目录</span></span><br><span class="line"><span class="keyword">cd</span>   <span class="comment"># 家目录</span></span><br><span class="line"><span class="keyword">cd</span> ~  <span class="comment"># 家目录</span></span><br><span class="line"><span class="keyword">cd</span> / <span class="comment"># 根目录</span></span><br></pre></td></tr></table></figure><p><code>ls</code></p><blockquote><p>浏览目录下的文件或文件夹</p></blockquote><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ls</span> -a <span class="comment"># 列举所有文件或目录，包含.开头的隐藏文件</span></span><br><span class="line"><span class="keyword">ls</span> -l <span class="comment"># 详细信息列举文件或目录</span></span><br><span class="line"><span class="keyword">ls</span> -i <span class="comment"># 列出每个文件的Inode号</span></span><br><span class="line"><span class="keyword">ls</span> -t <span class="comment"># 根据修改时间列出文件</span></span><br></pre></td></tr></table></figure><p><code>pwd</code></p><blockquote><p>显示当前所处目录</p></blockquote><p><code>mkdir</code></p><blockquote><p>创建目录</p></blockquote><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir <span class="keyword">a</span> <span class="comment"># 创建a目录</span></span><br><span class="line">mkdir -p <span class="keyword">a</span>/b/c <span class="comment"># 递归创建目录</span></span><br></pre></td></tr></table></figure><p><code>rm</code></p><blockquote><p>删除文件或目录</p></blockquote><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm <span class="keyword">a</span> <span class="comment"># 删除a文件</span></span><br><span class="line">rm -r <span class="keyword">a</span> <span class="comment"># 删除a 目录</span></span><br><span class="line">rm -rf <span class="keyword">a</span> <span class="comment"># 强制删除a 文件，不提示确认</span></span><br></pre></td></tr></table></figure><p><code>cp</code></p><blockquote><p>拷贝或备份文件</p></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp <span class="regexp">/root/</span><span class="number">1</span>.py <span class="regexp">/hoom/</span><span class="number">1</span>.py  <span class="comment"># 拷贝文件至新目录下</span></span><br></pre></td></tr></table></figure><p><code>mv</code></p><blockquote><p>重命名或移动文件或目录</p></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv <span class="regexp">/root/</span><span class="number">1</span>.py <span class="regexp">/hoome/</span><span class="number">1</span>.py.bak <span class="comment"># 移动文件并重命名</span></span><br></pre></td></tr></table></figure><p><code>touch</code></p><blockquote><p>创建普通文件</p></blockquote><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">touch</span> <span class="number">1.</span>py # 创建<span class="number">1.</span>py文件</span><br></pre></td></tr></table></figure><p><code>cat</code></p><blockquote><p>查看文件内容</p></blockquote><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat <span class="meta-keyword">/etc/</span>redis/redis.conf <span class="meta"># 查看redis.conf文件</span></span><br><span class="line">car -n <span class="meta"># 对输出所有进行编号</span></span><br><span class="line">car -b <span class="meta"># 对输出非空进行编号</span></span><br></pre></td></tr></table></figure><p><code>head</code></p><blockquote><p>查看文件头部内容，通常为十行</p></blockquote><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">head -3 /etc/memcached.conf <span class="comment"># 查看前三行</span></span><br><span class="line">head -n<span class="number"> 100 </span><span class="comment"># 查看前100行</span></span><br><span class="line">head -c<span class="number"> 3 </span><span class="comment"># 查看前三字节</span></span><br></pre></td></tr></table></figure><p><code>tail</code></p><blockquote><p>查看文件头部内容，通常为十行</p></blockquote><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tail -n <span class="number">3</span> <span class="number">1.</span>txt # 查看后<span class="number">3</span>行</span><br><span class="line">tail -f # 阻塞并即时输出文件变化后追加的数据</span><br></pre></td></tr></table></figure><p><code>chmod</code></p><blockquote><p>修改文件或目录权限</p></blockquote><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod <span class="number">775</span> <span class="number">1.</span>py # 赋予文件<span class="number">775</span>权限 rwx rwx r-w</span><br></pre></td></tr></table></figure><p><code>chown</code></p><blockquote><p>修改文件或目录所属组及所属用户</p></blockquote><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown -R root.root <span class="regexp">/tmp/</span>test.txt <span class="comment"># 文件所属用户及所属组均为root</span></span><br></pre></td></tr></table></figure><p><code>df</code></p><blockquote><p>磁盘信息查询</p></blockquote><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">df</span> -h <span class="comment"># 查询磁盘使用量</span></span><br><span class="line">df -i <span class="comment"># 分区Inode使用量</span></span><br></pre></td></tr></table></figure><p><code>du</code></p><blockquote><p>查看文件大小</p></blockquote><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">du -h <span class="number">1.</span>txt # 查看<span class="number">1.</span>txt文件大小</span><br></pre></td></tr></table></figure><p><code>echo</code></p><blockquote><p>打印或输出内容</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'hello'</span> <span class="comment"># 输出hello</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hello'</span> &gt; 1.md <span class="comment"># 以hello内容覆盖1.md</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'hello'</span> &gt;&gt; 1.md <span class="comment"># 以hello追加至1.md文件中</span></span><br></pre></td></tr></table></figure><p><code>tar</code></p><blockquote><p>解压或压缩文件</p></blockquote><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -<span class="keyword">jxvf </span> <span class="comment"># 解压bz2属性的压缩包</span></span><br><span class="line">tar -zxvf  <span class="comment"># 解压gz属性的压缩包</span></span><br></pre></td></tr></table></figure><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tar</span> -czcf <span class="comment"># 使用gzip格式压缩文件</span></span><br><span class="line">tar -cjvf <span class="comment"># 使用bzip2格式压缩文件</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Linux&quot;&gt;&lt;a href=&quot;#Linux&quot; class=&quot;headerlink&quot; title=&quot;Linux&quot;&gt;&lt;/a&gt;Linux&lt;/h3&gt;&lt;hr&gt;&lt;blockquote&gt;
&lt;p&gt;随着IT产业的不断发展，&lt;code&gt;linux&lt;/code&gt; 操作系统应用领域越来越广泛，尤其是近年来 &lt;code&gt;linux&lt;/code&gt;在服务器领域飞速的发展，主要得益于 &lt;code&gt;linux&lt;/code&gt;操作系统具备的如下优点&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://cy-blogs.cn/categories/Linux/"/>
    
    
      <category term="Linux常用命令" scheme="https://cy-blogs.cn/tags/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Ansible-PlayBook</title>
    <link href="https://cy-blogs.cn/Ansible-PlayBook/"/>
    <id>https://cy-blogs.cn/Ansible-PlayBook/</id>
    <published>2019-12-11T05:10:16.013Z</published>
    <updated>2019-12-11T05:03:39.327Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ansible-playbook"><a href="#ansible-playbook" class="headerlink" title="ansible-playbook"></a>ansible-playbook</h2><blockquote><p>在之前的<code>ansible</code>使用中，我们都是通过命令行的形式实现对应远程主机的响应管理</p><p>但这样的工作方式功能上来说还是有一定的局限性，并且维护并不方便，引入<code>playbook</code>可以更加方便我们对于功能的编写维护，并且具有良好的灵活性</p><p><code>playbook</code>也可以理解为命令行功能的一个合集脚本，用来编写更加复杂的业务</p></blockquote><a id="more"></a><h3 id="yaml语法"><a href="#yaml语法" class="headerlink" title="yaml语法"></a>yaml语法</h3><blockquote><p><code>Yaml</code>为通用数据串行化格式语法，简洁而强大</p><p><code>ansible</code>中的配置文件就采用了<code>Yaml</code>格式语法存在，以下就是对<code>Yaml</code>语法的介绍</p></blockquote><ul><li><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">yaml</span></span><br></pre></td></tr></table></figure><p>基本语法规则如下</p><ul><li>大小写敏感</li><li>使用缩进表示层级关系</li><li>缩进的空格数目不唯一，只要相同层级元素左侧对齐即可</li><li><code>#</code>号表示注释</li></ul></li><li><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">yaml</span></span><br></pre></td></tr></table></figure><p>语法支持的数据结构有三种：</p><ul><li>键值对：相当于<code>hash</code>表映射关系，字典</li><li>序列：相当于数组或列表</li><li>纯量（标量）：单独的值，无法继续拆分，比如字符串、整数、浮点数、<code>Null</code>、布尔值（<code>true</code>、<code>false</code>）</li></ul></li></ul><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><ul><li>字符串定义时，默认可以不使用引号标注</li></ul><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str_1: abc</span><br><span class="line">&#123;'str_1': 'abc',&#125; <span class="meta"># 对应Python中数据类型</span></span><br></pre></td></tr></table></figure><ul><li>如字符串中出现特殊字符或包含空格，需要使用引号标注</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str_2: <span class="symbol">'abc</span>: bbb'</span><br><span class="line">&#123;<span class="symbol">'str_2'</span>: <span class="symbol">'abc</span>: bbb'&#125; # 对应<span class="type">Python</span>中数据类型</span><br></pre></td></tr></table></figure><ul><li>双引号不会对字符串中特殊字符进行转义</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">str_3: <span class="symbol">'abc</span>: \n bbb'</span><br><span class="line">str_4: <span class="string">"abc: \n bbb"</span></span><br><span class="line">&#123;<span class="symbol">'abc</span>: \\n bbb', <span class="symbol">'str_4'</span>: <span class="symbol">'abc</span>: \n bbb'&#125; # 对应<span class="type">Python</span>中数据类型</span><br></pre></td></tr></table></figure><ul><li>单引号字符串还有引号，需要使用两个单引号进行转义</li></ul><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">str_5: 'a''b'</span><br><span class="line">&#123;'str_5': <span class="string">"a'b"</span>&#125; <span class="meta"># 对应Python中数据类型</span></span><br></pre></td></tr></table></figure><ul><li>当字符串需要换行时，从第二行开始的下面几行，需要有对齐缩进，换行会被解释为空格，其余缩进前空格会忽略</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">str_6: <span class="symbol">'abc</span></span><br><span class="line">    aaa</span><br><span class="line">    bbb</span><br><span class="line">    ccc'</span><br><span class="line">&#123;<span class="symbol">'str_6'</span>: <span class="symbol">'abc</span> aaa bbb ccc'&#125; # 对应<span class="type">Python</span>中数据类型</span><br></pre></td></tr></table></figure><ul><li>多行字符串可以使用 <code>|</code>保留换行符形成段落，或使用<code>&gt;</code>将换行符替换为空格</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">str_7: &gt;  bbb  aaastr_8: |  bbb  aaa&#123;<span class="symbol">'str_7'</span>: <span class="symbol">'bbb</span> aaa\n', <span class="symbol">'str_8'</span>: <span class="symbol">'bbb</span>\naaa\n'&#125; # str_7: &gt;</span><br><span class="line">  bbb</span><br><span class="line">  aaa</span><br><span class="line"></span><br><span class="line">str_8: |</span><br><span class="line">  bbb</span><br><span class="line">  aaa</span><br><span class="line">&#123;<span class="symbol">'str_7'</span>: <span class="symbol">'bbb</span> aaa\n', <span class="symbol">'str_8'</span>: <span class="symbol">'bbb</span>\naaa\n'&#125; # 对应<span class="type">Python</span>中数据类型</span><br><span class="line">对应<span class="type">Python</span>中数据类型</span><br></pre></td></tr></table></figure><ul><li><code>+</code>表示保留字符串末位的换行，<code>-</code>表示删除字符串末位的换行</li></ul><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str_9: <span class="string">|+</span></span><br><span class="line">  aaabbb</span><br><span class="line"></span><br><span class="line">str_10: <span class="string">|-</span></span><br><span class="line">  aaabbb</span><br><span class="line">'str_9': 'aaabbb\n', 'str_10': 'aaabbb'&#125; <span class="meta"># 对应Python中数据类型</span></span><br></pre></td></tr></table></figure><h4 id="键值对"><a href="#键值对" class="headerlink" title="键值对"></a>键值对</h4><ul><li>Yaml中的键值对数据通过冒号定义，冒号后的数据与冒号之间存在一个空格</li></ul><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dict_1: adict_2: &#123; <span class="number">1</span> : <span class="keyword">a</span> &#125;dict_3: dict_1: <span class="keyword">a</span></span><br><span class="line">dict_2: &#123; <span class="number">1</span> : <span class="keyword">a</span> &#125;</span><br><span class="line">dict_3:</span><br><span class="line">  <span class="variable">a:</span> <span class="number">1</span></span><br><span class="line">  <span class="variable">b:</span> <span class="number">2</span></span><br><span class="line">&#123;<span class="string">'dict_1'</span>: <span class="string">'a'</span>, <span class="string">'dict_2'</span>: &#123;<span class="number">1</span>: <span class="string">'a'</span>&#125;, <span class="string">'dict_3'</span>: &#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;&#125; # 对应Python中数据类型</span><br><span class="line"> <span class="variable">a:</span> <span class="number">1</span>  <span class="variable">b:</span> <span class="number">2</span>&#123;<span class="string">'dict_1'</span>: <span class="string">'a'</span>, <span class="string">'dict_2'</span>: &#123;<span class="number">1</span>: <span class="string">'a'</span>&#125;, <span class="string">'dict_3'</span>: &#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">2</span>&#125;&#125; # 对应Python中数据类型</span><br></pre></td></tr></table></figure><h4 id="序列"><a href="#序列" class="headerlink" title="序列"></a>序列</h4><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- list_1</span><br><span class="line">- list_2</span><br><span class="line">-</span><br><span class="line"> - a_1</span><br><span class="line"> - a_2</span><br><span class="line">[<span class="string">'list_1'</span>, <span class="string">'list_2'</span>, [<span class="string">'a_1'</span>, <span class="string">'a_2'</span>]] # 对应<span class="symbol">Python</span>中数据类型</span><br><span class="line">- list_1- list_2- - a_1 - a_2[<span class="string">'list_1'</span>, <span class="string">'list_2'</span>, [<span class="string">'a_1'</span>, <span class="string">'a_2'</span>]] # 对应<span class="symbol">Python</span>中数据类型</span><br></pre></td></tr></table></figure><h4 id="数据嵌套使用"><a href="#数据嵌套使用" class="headerlink" title="数据嵌套使用"></a>数据嵌套使用</h4><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- test_1:</span><br><span class="line">  - a</span><br><span class="line">  - b</span><br><span class="line">- test_2:</span><br><span class="line">    var_1: <span class="literal">true</span></span><br><span class="line">    var_2: <span class="number">0.2</span></span><br><span class="line">[&#123;<span class="string">'test_1'</span>: [<span class="string">'a'</span>, <span class="string">'b'</span>]&#125;, &#123;<span class="string">'test_2'</span>: &#123;<span class="string">'var_1'</span>: <span class="literal">True</span>, <span class="string">'var_2'</span>: <span class="number">0.2</span>&#125;&#125;] <span class="meta"># 对应Python中数据类型</span></span><br></pre></td></tr></table></figure><h3 id="playbook"><a href="#playbook" class="headerlink" title="playbook"></a>playbook</h3><ul><li><code>playbook</code>的编写使用<code>yaml</code>语法规则，先来看一下最简单的<code>playbook</code></li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">- hosts: all</span><br><span class="line">  remote_user: root</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Yum Install Apache</span><br><span class="line">    yum: <span class="attribute">name</span>=httpd <span class="attribute">state</span>=installed</span><br><span class="line">    - name: Start Apache Server</span><br><span class="line">    service: <span class="attribute">name</span>=httpd <span class="attribute">state</span>=started</span><br></pre></td></tr></table></figure><blockquote><p>第一行：<code>---</code>指明<code>Ymal</code>将文件解释为正确的文档的要求，<code>Yaml</code>允许可以有多个文档同时出现在一个文件里，每个文档之间由<code>---</code>进行分割，目前我们的<code>playbook</code>中只需要有一个文档即可</p><p>第二行：<code>hosts</code>指明当前<code>playbook</code>将要操作的目标主机有哪些，这里我们选择全部</p><p>第三行：<code>remote_user</code>指明当前操作所使用的远程主机用户</p><p>第四行：<code>tasks</code>为任务列表，<code>playbook</code>将按照从上到下的定义顺序执行其中的模块对应的操作，<code>name</code>属性为一个字符串用以标示当前任务的介绍，第一个任务将使用<code>yum</code>模块安装<code>apache</code>服务，第二个任务使用<code>ansible</code>模块<code>service</code>，使<code>httpd</code>服务启动</p></blockquote><ul><li>执行<code>playbook</code>使用<code>ansible-playbook</code></li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook <span class="regexp">/etc/</span>ansible<span class="regexp">/playbook.yml</span></span><br></pre></td></tr></table></figure><h3 id="包含"><a href="#包含" class="headerlink" title="包含"></a>包含</h3><blockquote><p>当遇到较为复杂的情况时，单独的<code>playbook</code>可能无法应对业务需求，那么可能需要编写多个<code>playbook</code></p><p>这时，如果在<code>playbook</code>中的<code>handlers</code>或<code>tasks</code>可能在多个<code>playbook</code>中重复使用，就可以通过<code>ansible</code>所提供的<code>include</code>功能，将复用的部分单独写成一个文件，在需要的地方<code>include</code>包含进来即可</p></blockquote><ul><li>比如有这样的一个功能是需要多次复用的，这个文件叫做<code>tasks.yaml</code></li></ul><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--- </span><br><span class="line">- name: Yum Install Nginx</span><br><span class="line">yum: name=nginx <span class="keyword">state</span>=installed</span><br></pre></td></tr></table></figure><ul><li>那么在一个主要<code>playbook</code>文件中可以这样引入</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">- hosts:</span> <span class="string">all</span>  </span><br><span class="line"><span class="attr">tasks:</span></span><br><span class="line"><span class="attr">    - include:</span> <span class="string">tasks.yml</span></span><br></pre></td></tr></table></figure><ul><li>执行该<code>playbook</code></li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook <span class="regexp">/etc/</span>ansible<span class="regexp">/playbook.yml</span></span><br></pre></td></tr></table></figure><ul><li><code>include</code>包含的其他<code>playbook</code>支持模板变量，可以通过定义<code>vars</code>变量覆盖，或者像这样</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Yum</span> <span class="string">Install</span> <span class="string">Nginx</span> </span><br><span class="line"><span class="attr">yum:</span> <span class="string">name=&#123;&#123;</span> <span class="string">server_name</span> <span class="string">&#125;&#125;</span> <span class="string">state=installed</span></span><br></pre></td></tr></table></figure><ul><li><code>playbook</code>文件</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- hosts:</span> <span class="string">all</span> </span><br><span class="line"><span class="attr">tasks:</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="attr">include:</span> <span class="string">tasks.yml</span> <span class="string">server_name=nginx</span></span><br></pre></td></tr></table></figure><ul><li>此外在<code>1.4</code>及以上版本中，还支持字典、列表形式的参数传递</li></ul><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--- </span><br><span class="line">-name: Yum Install Nginx  </span><br><span class="line">yum: name=&#123;&#123; server_name &#125;&#125; <span class="keyword">state</span>=installed</span><br></pre></td></tr></table></figure><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">---</span> </span><br><span class="line"><span class="selector-tag">-hosts</span>: <span class="selector-tag">all</span> </span><br><span class="line"><span class="selector-tag">tasks</span>:  </span><br><span class="line"><span class="selector-tag">-</span> &#123; <span class="attribute">include</span>: tasks.yml, server_name: nginx &#125;</span><br></pre></td></tr></table></figure><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><blockquote><p>除去通过<code>include</code>功能将不同的任务分别写入不同的文件，然后按需<code>include</code>包含进来，在<code>ansible</code>中还有一种标准规范叫做<code>role</code>角色</p><p>通过不同级别的层级目录和文件来对变量、任务、配置模板等进行拆分管理，提高扩展性和可维护性</p></blockquote><ul><li>一般来说，一个<code>role</code>角色定义目录结构如下</li></ul><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">role_name/<span class="comment"># 角色名目录，playbook调用时需要</span></span><br><span class="line">    <span class="built_in">file</span>/<span class="comment"># 存放copy或script等模块调用文件</span></span><br><span class="line">    tasks/<span class="comment"># 存放各种task任务，需要包含一个main.yml</span></span><br><span class="line">    handlers/<span class="comment"># 存放各种handlers任务，需要包含一个main.yml</span></span><br><span class="line">    vars/<span class="comment"># 存放定义好的变量，需要包含一个main.yml</span></span><br><span class="line">    templates/<span class="comment"># 存放需要使用到的配置模板</span></span><br><span class="line">    meta/<span class="comment"># 当前角色的特殊设定及其依赖，需要包含一个main.yml</span></span><br></pre></td></tr></table></figure><ul><li>角色目录存放的路径可以在<code>ansible</code>的配置文件中定义</li></ul><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># <span class="regexp">/etc/</span>ansible<span class="regexp">/ansible.cfgroles_path = /</span>etc<span class="regexp">/ansible/</span>roles</span><br></pre></td></tr></table></figure><ul><li>示例目录结构</li></ul><p><a href="https://lienze.tech/blog/images/1562121857022.png" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/1562121857022.png" alt="1562121857022"></a></p><ul><li>任务<code>tasks</code>目录下<code>main</code>文件内容</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tasks/main.yml- <span class="type">name</span>: Install Apache <span class="keyword">Server</span>  yum: <span class="type">name</span>=httpd state=installed- <span class="type">name</span>: <span class="keyword">Write</span> Apache Config  <span class="keyword">template</span>: src=httpd.j2 dest=/etc/httpd/conf/httpd.conf  <span class="keyword">notify</span>: <span class="keyword">Restart</span> Apache <span class="keyword">Server</span></span><br></pre></td></tr></table></figure><ul><li><code>handlers</code>目录下<code>main</code>文件内容</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># handlers/main.yml- <span class="type">name</span>: <span class="keyword">Restart</span> Apache <span class="keyword">Server</span>  service: <span class="type">name</span>=httpd state=restarted</span><br></pre></td></tr></table></figure><ul><li><code>templates</code>下配置模板</li></ul><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># templates/httpd.j2#上面内容太多省略，只保留模板变量部分Listen &#123;&#123; listen_port &#125;&#125;</span><br></pre></td></tr></table></figure><ul><li>变量<code>vars</code>目录下<code>main</code>文件</li></ul><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># vars/main.ymllisten_port: 8000</span></span><br></pre></td></tr></table></figure><ul><li>调用<code>role</code>的<code>playbook</code>文件内容</li></ul><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">hosts:</span> all  <span class="string">remote_user:</span> root  <span class="string">roles:</span> - apache</span><br></pre></td></tr></table></figure><ul><li>在执行角色<code>role</code>此处为<code>apache</code>任务时，会将文件夹下的<code>main.yml</code>文件自动导入合并，执行结果如下</li></ul><p><a href="https://lienze.tech/blog/images/1562122149050.png" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/1562122149050.png" alt="1562122149050"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ansible-playbook&quot;&gt;&lt;a href=&quot;#ansible-playbook&quot; class=&quot;headerlink&quot; title=&quot;ansible-playbook&quot;&gt;&lt;/a&gt;ansible-playbook&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在之前的&lt;code&gt;ansible&lt;/code&gt;使用中，我们都是通过命令行的形式实现对应远程主机的响应管理&lt;/p&gt;
&lt;p&gt;但这样的工作方式功能上来说还是有一定的局限性，并且维护并不方便，引入&lt;code&gt;playbook&lt;/code&gt;可以更加方便我们对于功能的编写维护，并且具有良好的灵活性&lt;/p&gt;
&lt;p&gt;&lt;code&gt;playbook&lt;/code&gt;也可以理解为命令行功能的一个合集脚本，用来编写更加复杂的业务&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://cy-blogs.cn/categories/Linux/"/>
    
    
      <category term="Linux,Ansible-PlayBook" scheme="https://cy-blogs.cn/tags/Linux-Ansible-PlayBook/"/>
    
  </entry>
  
  <entry>
    <title>Paramiko</title>
    <link href="https://cy-blogs.cn/Paramiko/"/>
    <id>https://cy-blogs.cn/Paramiko/</id>
    <published>2019-12-11T05:10:16.009Z</published>
    <updated>2019-12-11T05:09:54.323Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Paramiko"><a href="#Paramiko" class="headerlink" title="Paramiko"></a>Paramiko</h2><blockquote><p><code>Paramiko</code>是<code>SSHv2</code>协议的<code>Python</code>实现，提供客户端和服务器功能</p><p><code>Paramiko</code>本身是一个围绕<code>SSH</code>网络概念的纯<code>Python</code>接口</p><p>利用<code>paramiko</code>我们可以通过<code>Python</code>方便的进行<code>ssh</code>操作</p></blockquote><a id="more"></a><p>+++</p><blockquote><p>paramiko<code>包含两个核心组件：</code>SSHClient<code>和</code>SFTPClient</p></blockquote><h3 id="SSHClient"><a href="#SSHClient" class="headerlink" title="SSHClient"></a>SSHClient</h3><p>+++</p><blockquote><p><code>SSHClient</code>的作用类似于<code>Linux</code>的<code>ssh</code>命令，是对<code>SSH</code>会话的封装</p><p>该类封装了传输<code>Transport</code>，通道<code>Channel</code>及<code>SFTPClient</code>建立的方法<code>open_sftp</code>，通常用于执行远程命令</p></blockquote><h4 id="API"><a href="#API" class="headerlink" title="API"></a>API</h4><ul><li><code>class paramiko.client.SSHClient</code></li></ul><blockquote><p>创建<code>SSH</code>客户端实例</p></blockquote><ul><li><code>SSHClient.connect(hostname, port=22, username=None, password=None, pkey=None, key_filename=None, timeout=None, allow_agent=True, look_for_keys=True, compress=False..)</code></li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数解释</span></span><br><span class="line">- hostname：连接的目标主机</span><br><span class="line">- <span class="attribute">port</span>=SSH_PORT：指定端口</span><br><span class="line">- <span class="attribute">username</span>=None：验证的用户名</span><br><span class="line">- <span class="attribute">password</span>=None：验证的用户密码</span><br><span class="line">- <span class="attribute">pkey</span>=None：私钥方式用于身份验证</span><br><span class="line">- <span class="attribute">key_filename</span>=None：一个文件名或文件列表，指定私钥文件</span><br><span class="line">- <span class="attribute">timeout</span>=None：可选的tcp连接超时时间</span><br><span class="line">- <span class="attribute">allow_agent</span>=<span class="literal">True</span>：是否允许连接到ssh代理，默认为True 允许</span><br><span class="line">- <span class="attribute">look_for_keys</span>=<span class="literal">True</span>：是否在~/.ssh中搜索私钥文件，默认为True 允许</span><br><span class="line">- <span class="attribute">compress</span>=<span class="literal">False</span>：是否打开压缩</span><br></pre></td></tr></table></figure><blockquote><p>通过验证连接远程服务端</p></blockquote><hr><ul><li><code>SSHClient.exec_command(command, bufsize=-1, timeout=None, get_pty=False, environment=None)</code></li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># 参数解释</span></span><br><span class="line"><span class="bullet">- </span>command：要执行的命令</span><br><span class="line"><span class="bullet">- </span>bufsize：与Python中文件对象的同名函数解释相同，缓冲区大小</span><br><span class="line"><span class="bullet">- </span>timeout：设置命令的超时相应事件</span><br><span class="line"><span class="bullet">- </span>get_pty：从服务器请求一个伪终端（默认为假）</span><br><span class="line"><span class="bullet">- </span>environment：一个当前shell环境的字典，远程命令的默认执行环境</span><br></pre></td></tr></table></figure><blockquote><p><code>command</code>参数为要执行的<code>shell</code>命令，打开一个新通道并执行请求的命令</p><p>该函数的返回结果为一个元组，其中包含<code>stdin</code>、<code>stdout</code>和<code>stderr</code>，也就是我们常见的标准输入，输出以及出错</p><p>一般来说，命令的结果我们将通过<code>stdout</code>进行获取</p></blockquote><hr><ul><li><code>SSHClient.close()</code></li></ul><blockquote><p>关闭<code>SSH</code>连接</p></blockquote><hr><ul><li><code>SSHClient.invoke_shell(term=’vt100’, width=80, height=24, width_pixels=0, height_pixels=0, environment=None)</code></li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># 参数解释</span></span><br><span class="line"><span class="bullet">- </span>term：模拟终端类型</span><br><span class="line"><span class="bullet">- </span>width：终端长度</span><br><span class="line"><span class="bullet">- </span>height：终端宽度</span><br><span class="line"><span class="bullet">- </span>width_pixels：终端的像素宽度</span><br><span class="line"><span class="bullet">- </span>height_pixels：终端的像素高度</span><br><span class="line"><span class="bullet">- </span>environment：命令的shell环境</span><br></pre></td></tr></table></figure><blockquote><p>在<code>ssh</code>服务器上启动交互式<code>shell</code>会话</p><p>一个新的通道被打开并连接到，使用请求的终端类型和大小的伪终端，并作为返回值</p><p>换句通俗的话来讲，就是创建了一个实际的<code>shell</code>窗口空间进行命令交互</p></blockquote><hr><ul><li><code>SSHClient.set_missing_host_key_policy(policy)</code></li></ul><blockquote><p>设置连接到没有已知主机密钥的服务器时要使用的策略</p><p>常见使用策略为<code>paramiko.client.AutoAddPolicy</code>，其意义为自动将主机名和新主机密钥添加到本地主机密钥对象并保存</p></blockquote><h4 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h4><blockquote><p>以下是一个简单的通过<code>SSHClient</code>建立的通道进行命令的传输与返回结果的获取的代码！</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paramiko </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connect</span><span class="params">(hostname,username,password)</span>:</span></span><br><span class="line">client = paramiko.SSHClient() </span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">client.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line">    <span class="comment"># 设置密钥策略</span></span><br><span class="line">client.connect(hostname,username=username,password=password)</span><br><span class="line">    <span class="comment"># 连接主机</span></span><br><span class="line"><span class="keyword">return</span> client</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exec_cmd</span><span class="params">(client,cmd)</span>:</span></span><br><span class="line">stdin,stdout,stderr = client.exec_command(cmd)</span><br><span class="line"><span class="keyword">return</span> stdout.read().decode(),stderr.read().decode()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">hostname = <span class="string">'192.168.0.104'</span></span><br><span class="line">username = <span class="string">'pi'</span></span><br><span class="line">password = <span class="string">'123456'</span></span><br><span class="line">cmd = <span class="string">'ps -aux'</span></span><br><span class="line"></span><br><span class="line">client = connect(hostname,username,password)</span><br><span class="line">res = exec_cmd(client, cmd)</span><br><span class="line"><span class="keyword">if</span> res[<span class="number">0</span>]:</span><br><span class="line">print(res[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">if</span> res[<span class="number">1</span>]:</span><br><span class="line">print(<span class="string">'[E]:\n'</span>,res[<span class="number">1</span>])</span><br><span class="line">client.close()</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">main()</span><br></pre></td></tr></table></figure><blockquote><p>上面的代码通过默认建立好的连接对象进行命令的传输以及返回结果的获取</p></blockquote><h4 id="invoke-shell"><a href="#invoke-shell" class="headerlink" title="invoke_shell"></a>invoke_shell</h4><ul><li>接下来使用<code>invoke_shell</code>进行虚拟终端的连接，首先初始化<code>SSH</code>通道</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSHChannle</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, host, username, password, port=<span class="number">22</span>)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            初始化SSH通道</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.sh = paramiko.SSHClient()</span><br><span class="line">        self.sh.set_missing_host_key_policy(paramiko.AutoAddPolicy())</span><br><span class="line">        self.sh.connect(host, username=username, password=password)</span><br><span class="line">        self.channle = self.sh.invoke_shell()</span><br><span class="line">        self.cmd = <span class="string">''</span></span><br></pre></td></tr></table></figure><ul><li>思路为开启两个线程，分别负责命令的接收与命令的发送</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_ssh_recv</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        接收SSH通道中发来的消息</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> self.channle.exit_status_ready():</span><br><span class="line">        <span class="comment"># 如果远程进程已退出并返回退出状态，则返回true</span></span><br><span class="line">        time.sleep(<span class="number">0.1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            buf = self.channle.recv(<span class="number">1024</span>).decode(<span class="string">'utf-8'</span>)</span><br><span class="line">            print(buf,end=<span class="string">''</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">            print(ex)</span><br><span class="line">        sys.stdout.flush()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_ssh_cmd</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        发送命令给SSH通道</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> self.channle.exit_status_ready():</span><br><span class="line">        self.cmd = input()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.channle.send(self.cmd + <span class="string">'\r'</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">            print(ex)</span><br><span class="line">        <span class="comment"># sys.stdin.flush()</span></span><br></pre></td></tr></table></figure><ul><li>在实例中定义<code>run</code>函数用来开启两个线程并负责线程的资源回收以及SSH通道的关闭</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">    ssh_recv_thread = threading.Thread(target=self.get_ssh_recv)</span><br><span class="line">    ssh_send_thread = threading.Thread(target=self.send_ssh_cmd)</span><br><span class="line">    ssh_recv_thread.start()</span><br><span class="line">    ssh_send_thread.start()</span><br><span class="line"></span><br><span class="line">    ssh_recv_thread.join()</span><br><span class="line">    ssh_send_thread.join()</span><br><span class="line"></span><br><span class="line">    self.sh.close()  <span class="comment"># 关闭通道</span></span><br></pre></td></tr></table></figure><ul><li>在<code>win</code>下的<code>CMD</code>中查看效果，其中的乱码格式其实为连接后命令传输的特殊标记格式，可以在后面结合前端中类似<code>xterm.js</code>等插件查看到实际花里胡哨的效果</li></ul><p><a href="https://lienze.tech/blog/images/invoke_shell.gif" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/invoke_shell.gif" alt="invoke_shell"></a></p><h3 id="SFTPClient"><a href="#SFTPClient" class="headerlink" title="SFTPClient"></a>SFTPClient</h3><blockquote><p><code>SFTPClient</code>的作用类似与<code>Linux</code>的<code>sftp</code>命令，是对<code>SFTP</code>客户端的封装</p><p>用以实现远程文件操作，如文件上传、下载、修改文件权限等操作</p></blockquote><h4 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h4><ul><li>官方文档</li></ul><blockquote><p>docs.paramiko.org/en/2.4/api/sftp.html</p></blockquote><ul><li><code>sftp=paramiko.SFTPClient.from_transport(t,window_size=None,max_packet_size=None)</code></li></ul><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 参数解释- t：该参数可以通过paramiko.<span class="constructor">Transport( (<span class="params">ip</span>,<span class="params">port</span> )</span>)，创建一个已通过验证的传输通道，参数为IP和端口的二元组</span><br></pre></td></tr></table></figure><blockquote><p>根据参数<code>t</code>指定的已验证传输通道进行<code>SFTP</code>客户端的创建</p></blockquote><ul><li><code>sftp.put(localpath, remotepath, callback=None, confirm=True)</code></li></ul><blockquote><p>上传本地路径为<code>localpath</code>的文件到目标主机<code>remotepath</code>处</p></blockquote><ul><li><code>sftp.get(remotepath, localpath, callback=None)</code></li></ul><blockquote><p>下载远程路径为<code>remotepath</code>路径的的文件到本地主机<code>localpath</code>处</p></blockquote><ul><li><code>open(filename, mode=’r’, bufsize=-1)</code></li></ul><blockquote><p>打开位于远程主机上的文件，与<code>open</code>函数类似，返回文件对象</p></blockquote><ul><li><code>listdir(path=&#39;.&#39;)</code></li></ul><blockquote><p>返回给定路径下文件及目录的列表，默认路径为当前工作目录</p></blockquote><ul><li><code>chdir(path=None)</code></li></ul><blockquote><p>修改当前<code>SFTP</code>连接会话的工作目录</p></blockquote><ul><li><code>lstat(path)</code></li></ul><blockquote><p>检索当前<code>path</code>所指向的文件信息</p></blockquote><ul><li><code>mkdir(path,mode=511)</code></li></ul><blockquote><p>根据<code>path</code>在目标主机创建默认权限为<code>511</code>的目录</p></blockquote><ul><li><code>rmdir(path)</code></li></ul><blockquote><p>删除给定<code>path</code>所指向的目录</p></blockquote><ul><li><code>remove(path)</code></li></ul><blockquote><p>删除给定<code>path</code>所指向的文件</p></blockquote><h4 id="实例代码-1"><a href="#实例代码-1" class="headerlink" title="实例代码"></a>实例代码</h4><blockquote><p>以下是一个比较简陋的关于<code>SFTPClient</code>的测试代码</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paramiko</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">connecnt</span><span class="params">(hostname,username,password)</span>:</span> <span class="comment">#创建连接对象</span></span><br><span class="line">    client = paramiko.Transport( (hostname,<span class="number">22</span>))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        client.connect(username=username,password=password)</span><br><span class="line">    <span class="keyword">except</span> paramiko.SSHException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    sftp_client = paramiko.SFTPClient.from_transport(client)</span><br><span class="line">    <span class="keyword">return</span> sftp_client</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    hostname = <span class="string">'192.168.0.104'</span></span><br><span class="line">    username = <span class="string">'pi'</span></span><br><span class="line">    password = <span class="string">'123456'</span></span><br><span class="line">    sftp_client = connecnt(hostname,username,password)</span><br><span class="line">    remotefile_path = <span class="string">'/home/pi/test'</span> <span class="comment"># 目标主机文件路径</span></span><br><span class="line">    localfile_path = <span class="string">'/home/test'</span> <span class="comment"># 本地主机文件路径</span></span><br><span class="line"></span><br><span class="line">    sftp_client.put(localfile_path, remotefile_path) <span class="comment">#上传本地test文件到远程</span></span><br><span class="line">    sftp_client.get(remotefile_path, localfile_path) <span class="comment">#下载远程test文件到本地</span></span><br><span class="line">    print(sftp_client.listdir())</span><br><span class="line">    print(<span class="string">'--------------------'</span>)</span><br><span class="line">    print(sftp_client.lstat(remotefile_path))</span><br><span class="line">    print(<span class="string">'--------------------'</span>)</span><br><span class="line">    <span class="keyword">with</span> sftp_client.open(remotefile_path) <span class="keyword">as</span> fp:</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Paramiko&quot;&gt;&lt;a href=&quot;#Paramiko&quot; class=&quot;headerlink&quot; title=&quot;Paramiko&quot;&gt;&lt;/a&gt;Paramiko&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Paramiko&lt;/code&gt;是&lt;code&gt;SSHv2&lt;/code&gt;协议的&lt;code&gt;Python&lt;/code&gt;实现，提供客户端和服务器功能&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Paramiko&lt;/code&gt;本身是一个围绕&lt;code&gt;SSH&lt;/code&gt;网络概念的纯&lt;code&gt;Python&lt;/code&gt;接口&lt;/p&gt;
&lt;p&gt;利用&lt;code&gt;paramiko&lt;/code&gt;我们可以通过&lt;code&gt;Python&lt;/code&gt;方便的进行&lt;code&gt;ssh&lt;/code&gt;操作&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://cy-blogs.cn/categories/Linux/"/>
    
    
      <category term="Paramiko" scheme="https://cy-blogs.cn/tags/Paramiko/"/>
    
  </entry>
  
  <entry>
    <title>Ansible</title>
    <link href="https://cy-blogs.cn/Ansible/"/>
    <id>https://cy-blogs.cn/Ansible/</id>
    <published>2019-12-10T12:35:38.500Z</published>
    <updated>2019-12-10T12:35:24.192Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h2><blockquote><p><code>ansible</code>基于Python开发，集合了众多运维工具（<code>puppet</code>、<code>cfengine</code>、<code>chef</code>、<code>func</code>、<code>fabric</code>）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能<br>在使用时，<code>ansible</code>不需要在被控制安装客户端，<code>ansible</code>工作基于<code>ssh</code>，只要被控制端服务器有<code>ssh</code>服务，加上一个<code>Python</code>环境，就可以使用<code>ansible</code><br>另外，<code>ansible</code>在15年的时候，以1.5亿美元被<code>RedHat</code>公司收购，新版的<code>RedHat</code>操作系统内置<code>ansible</code>软件，很厉害的</p></blockquote><a id="more"></a><p>##Ansible部署</p><blockquote><p><code>ansible</code>安装可以通过源码，<code>yum</code>源以及<code>python</code>所提供的<code>pip</code>管理工具进行安装</p></blockquote><ul><li>使用pip管理工具进行安装</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install ansible</span><br></pre></td></tr></table></figure><ul><li>使用<code>yum</code>进行安装</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install epel-release <span class="comment"># 安装扩展源</span></span><br><span class="line">yum install ansible</span><br></pre></td></tr></table></figure><h2 id="Ansible配置"><a href="#Ansible配置" class="headerlink" title="Ansible配置"></a>Ansible配置</h2><blockquote><p>安装之后，默认<code>ansible</code>工具的配置文件在<code>/etc/ansible</code>下</p><p>如通过<code>pip</code>命令安装，是没有这个目录的，需要我们手动创建，其中所需主要配置文件如下</p></blockquote><ul><li><code>ansible.cfg</code>：<code>ansible</code>主配置文件</li><li><code>hosts</code>：被管理主机<code>IP</code>或者主句名列表文件，也是比较重要的一个文件</li><li><code>roles</code>：角色或插件目录（默认为空）</li></ul><blockquote><p>此外除了默认的<code>ansible</code>的配置文件路径，关于<code>ansible</code>的配置文件路径选择还有如下几种，按照序列表示优先级</p></blockquote><ul><li><code>export ANSIBLE_CONFI</code>：指定的全局变量</li><li><code>./ansible.cfg</code>：当前目录下的配置文件</li><li><code>~/.ansible.cfg</code>：当前用户目下的配置文件</li><li><code>/ext/ansible/ansible.cfg</code>：<code>etc</code>目录下的配置文件</li></ul><blockquote><p>如果以上四个路径下均没有<code>cfg</code>配置文件，则使用默认配置</p><p>如果通过源码进行安装，那么在<code>/etc/ansible</code>目录下会自动包含<code>ansible.cfg</code>文件</p><p>也可以通过访问在线的配置文件地址进行获取</p></blockquote><blockquote><p><a href="https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg" target="_blank" rel="noopener">https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg</a></p></blockquote><ul><li><code>ansible</code>配置文件中可以进行<code>ansible</code>的各项参数的设置，包括并发线程数量、用户、模块路径、调优等等<ul><li><code>defaluts</code>：默认的配置项，一般不需要修改</li><li><code>privilege_escalation</code>：执行命令的用户权限设置</li><li><code>paramiko_connection</code>：<code>paramiko</code>插件设置</li><li><code>ssh_connection</code>：<code>ssh</code>连接设置</li></ul></li><li>默认<code>ansible</code>使用<code>hosts</code>文件列举监控主句，格式为<code>ini</code>，可以进行<code>IP</code>的分组以及<code>IP</code>规则设置，比如如下的例子</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[webserver]</span></span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.1</span><span class="selector-class">.1001</span><span class="selector-pseudo">:22</span></span><br></pre></td></tr></table></figure><blockquote><p><code>ansible</code>支持很多模块来进行对被控制主机的管理，包括：<code>command</code>、<code>shell</code>、<code>script</code>、<code>yum</code>、<code>copy</code>、<code>File</code>、<code>async</code>、<code>docker</code>、<code>cron</code>、<code>mysql_user</code>、<code>ping</code>、<code>sysctl</code>、<code>user</code>、<code>acl</code>、<code>add_host</code>、<code>easy_install</code>、<code>haproxy</code>等。默认在执行命令时，使用模块为、<code>command</code>，接下来会进行介绍</p></blockquote><h2 id="Ansible使用参数"><a href="#Ansible使用参数" class="headerlink" title="Ansible使用参数"></a>Ansible使用参数</h2><blockquote><p><code>ansible</code>在工作时，需要使用我们安装好的、<code>ansible</code>来执行命令</p><p>经常在使用、<code>ansible</code>模块进行工作时，可能还需要额外提供一些参数来辅助工作，下面是常用参数</p></blockquote><table><thead><tr><th>命令参数</th><th>解释</th></tr></thead><tbody><tr><td><code>-v</code></td><td>打印详细信息</td></tr><tr><td><code>-m</code></td><td>指定使用的模块，默认为 <code>command</code>模块</td></tr><tr><td><code>-k</code></td><td>要求输入远程主机密码</td></tr><tr><td><code>-a</code></td><td>将参数或命令传入模块</td></tr><tr><td><code>-c</code></td><td>测试执行过程，但不真正执行</td></tr><tr><td><code>-sudo</code></td><td>基于 <code>sudo</code>用户执行</td></tr><tr><td><code>--list-hosts</code></td><td>列举命令生效的主机</td></tr><tr><td><code>-l</code></td><td>限制匹配规则的主机数</td></tr><tr><td><code>-i</code></td><td>指定 <code>hosts</code>文件路径</td></tr><tr><td><code>-u</code></td><td><code>SSH</code> 连接所使用用户</td></tr></tbody></table><blockquote><p>现在看到这些命令参数你可能有一些懵，不过不要着急，结合模块使用，你将很快了解这些参数的实际意义</p></blockquote><h2 id="配置免密登陆"><a href="#配置免密登陆" class="headerlink" title="配置免密登陆"></a>配置免密登陆</h2><blockquote><p>由于 <code>ansible</code>是通过 <code>ssh</code> 服务进行命令下达执行，那避免不了用户认证</p><p>但是在批量执行时，多次的重复认证会导致我们的效率极其低下，这里可以通过配置主控端与被控端知己之间 <code>SSH</code> 免密登陆来实现用户认证的跳过，可谓是一次配置，轻松很久</p></blockquote><ul><li>在主控服务器 <code>192.168.1.104</code> 下生成密钥</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="comment"># -t 指定加密的方式，默认为rsa</span></span><br></pre></td></tr></table></figure><ul><li>进行秘钥的分布</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub root@<span class="number">192.168</span><span class="number">.1</span><span class="number">.101</span></span><br></pre></td></tr></table></figure><ul><li>输入对应远程主机的 <code>ssh</code> 账号密码之后，接下来在主控服务器就可以不进行 <code>SSH</code> 的用户认证也可以访问到被控制端，这里测试主机为 <code>192.168.1.104</code> （主控）， <code>192.168.1.101</code> （被控）</li></ul><h2 id="定义主机及组规则"><a href="#定义主机及组规则" class="headerlink" title="定义主机及组规则"></a>定义主机及组规则</h2><blockquote><p><code>ansible</code> 通过定义好的主句以组规则（<code>Inventory</code>） 在执行命令时通过匹配进行远程操作</p><p>这个文件默认就是我们上面所说的 <code>/etc/ansible/hosts</code> 文件，其中定义的几种方式如下</p></blockquote><ul><li>直接 <code>IP</code> 写入</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.101</span></span><br></pre></td></tr></table></figure><ul><li>规则分组</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[webserver]</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.101</span>:<span class="number">2333</span></span><br><span class="line">www.example.com</span><br></pre></td></tr></table></figure><blockquote><p>可以在规则的 <code>IP</code> 后指定端口</p></blockquote><ul><li>规则命名</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">myhost ansible_ssh_host=<span class="number">192.168</span><span class="number">.1</span><span class="number">.101</span></span><br><span class="line">[webservers]</span><br><span class="line">myhost</span><br></pre></td></tr></table></figure><blockquote><p>在使用时，直接利用<code>myhost</code>即可</p><p>除去示例中的指定方式，还有如下一些参数可以利用</p></blockquote><ul><li><code>ansible_ssh_host</code>：目标主机地址</li><li><code>ansible_ssh_port</code>：目标主机<code>ssh</code>服务端口</li><li><code>ansible_ssh_user</code>：目标主机<code>ssh</code>登录用户</li><li><code>ansible_ssh_pass</code>：目标主机<code>ssh</code>登录密码</li><li><code>ansible_connection</code>：连接类型：<code>local</code>、<code>ssh</code>、<code>paramiko</code></li><li><code>ansible_ssh_priveate_key_file</code>：连接所需<code>ssh</code>私钥文件；</li><li><code>ansible_shell_type</code>：目标主机的shell类型：<code>ash</code>、<strong>bash</strong>（默认使用的<code>shell</code>，可以结合<code>help</code>查看帮助文档）、<code>ksh</code>（支持42个内部命令）、<code>csh</code>、<code>zsh</code>（最庞大的shell，支持84个内部命令）</li><li>正则规则</li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">webservers</span>][<span class="symbol">a:z</span>]bc.example.com192.168.1.10[1:5]</span><br></pre></td></tr></table></figure><blockquote><p>在主机处填写对应的正则规则，可以更加方便的映射某个网段下的<code>ip</code>地址</p></blockquote><h3 id="Ping模块"><a href="#Ping模块" class="headerlink" title="Ping模块"></a>Ping模块</h3><blockquote><p>ping模块可以判断被控主机是否在线， 返回值为changed和ping</p><p>首先在<code>/etc/ansible/hosts</code>文件下添加被控主机，并建立分组为<strong>webservers</strong></p></blockquote><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-attr">[webservers]</span>192<span class="selector-class">.168</span><span class="selector-class">.1</span><span class="selector-class">.101</span><span class="selector-pseudo">:22</span></span><br></pre></td></tr></table></figure><ul><li><code>ping</code>命令的用法，要进入到<code>python</code>安装目录下，找到对应的<code>ansible</code>可执行文件</li></ul><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible <span class="keyword">all</span> -m ping</span><br></pre></td></tr></table></figure><blockquote><p>返回值<code>ping</code>如果为<code>pong</code>则代表可以<code>ping</code>通</p><p><code>ansible</code>命令行第二个参数可以是一个主机的正则规则，<code>all</code>代表所有<code>hosts</code>文件下<code>IP</code>，也可以指定使用某个分组</p></blockquote><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible webservers -m <span class="built_in">ping</span></span><br></pre></td></tr></table></figure><h3 id="Command模块"><a href="#Command模块" class="headerlink" title="Command模块"></a>Command模块</h3><blockquote><p>通过<code>ansible</code>执行命令时，默认使用<code>command</code>模块，该模块主要用于执行<code>linux</code>基础命令</p></blockquote><ul><li>注意：对比之后的<code>Shell</code>及<code>Script</code>功能模块，<code>Command</code>模块不支持管道</li><li><code>command</code>支持的额外参数</li></ul><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">./ansible-doc</span> -s <span class="keyword">command</span><span class="comment"># 文档</span></span><br></pre></td></tr></table></figure><table><thead><tr><th align="left">参数</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left"><code>chdir</code></td><td align="left">执行命令时，先进入到该目录下</td></tr><tr><td align="left"><code>creates</code></td><td align="left">给定文件存在时，不执行该命令</td></tr><tr><td align="left"><code>free_form</code></td><td align="left">需要执行的脚本</td></tr><tr><td align="left"><code>removes</code></td><td align="left">给定文件存在，则执行该命令</td></tr></tbody></table><ul><li>对远程主机执行命令</li></ul><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">./ansible</span> webservers -m <span class="keyword">command</span> -a <span class="string">"ifconfig"</span></span><br></pre></td></tr></table></figure><ul><li>执行命令时更改工作目录</li></ul><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">./ansible</span> webservers -m <span class="keyword">command</span> -a <span class="string">"ls chdir=/home/"</span></span><br></pre></td></tr></table></figure><h3 id="Shell模块"><a href="#Shell模块" class="headerlink" title="Shell模块"></a>Shell模块</h3><blockquote><p><code>shell</code>使用远程主机下的<code>/bin/sh</code>进行命令执行，支持比<code>command</code>模块更多的命令，常用参数如下</p></blockquote><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible-doc -s <span class="keyword">shell</span><span class="bash"><span class="comment"># 文档</span></span></span><br></pre></td></tr></table></figure><ul><li>额外参数</li></ul><table><thead><tr><th align="left">参数</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left"><code>chdir</code></td><td align="left">执行命令时，先进入到该目录下</td></tr><tr><td align="left"><code>creates</code></td><td align="left">给定文件存在时，不执行该命令</td></tr><tr><td align="left"><code>free_form</code></td><td align="left">需要执行的脚本</td></tr><tr><td align="left"><code>removes</code></td><td align="left">给定文件存在，则执行该命令</td></tr><tr><td align="left"><code>executable</code></td><td align="left">更换执行命令所使用的<code>shell</code>环境</td></tr></tbody></table><ul><li>远程主机编写<code>sh</code>脚本，向屏幕输出<code>hello</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"hello"</span></span><br></pre></td></tr></table></figure><ul><li>执行远程主机的<code>shell</code>脚本</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible webservers -m <span class="keyword">shell</span><span class="bash"> -a <span class="string">"sh ~/test.sh"</span></span></span><br></pre></td></tr></table></figure><h3 id="Script模块"><a href="#Script模块" class="headerlink" title="Script模块"></a>Script模块</h3><blockquote><p>该模块可以方便运行当前管理机上的脚本直接到远程被控端，而不需要先将脚本拷贝到远程主机后在执行</p></blockquote><ul><li>在主控制<code>home</code>目录下创建<code>sh</code>脚本</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"this is Control"</span></span><br></pre></td></tr></table></figure><ul><li>将这个<code>sh</code>脚本通过<code>script</code>模块执行到远程被控端</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible webservers -m<span class="built_in"> script </span>-a <span class="string">"/root/test.sh"</span></span><br></pre></td></tr></table></figure><h3 id="Copy模块"><a href="#Copy模块" class="headerlink" title="Copy模块"></a>Copy模块</h3><blockquote><p><code>copy</code>模块可以方便的将当前主机下文件拷贝到远程主机，类似<code>scp</code>命令等</p></blockquote><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible-doc -s <span class="keyword">copy</span><span class="bash"><span class="comment"># 文档地址</span></span></span><br></pre></td></tr></table></figure><ul><li>支持的参数</li></ul><table><thead><tr><th align="left">参数</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left"><code>src</code></td><td align="left">将本地路径复制到远程服务器; 可以是绝对路径或相对的。如果是一个目录，它将被递归地复制。如果路径以/结尾，则只有该目录下内容被复制到目的地，如果没有使用/来结尾，则包含目录在内的整个内容全部复制</td></tr><tr><td align="left"><code>content</code></td><td align="left">当用<code>content</code>代替<code>src</code>参数的时候，可以把文档的内容设置到特定的值</td></tr><tr><td align="left"><code>dest</code></td><td align="left">目标绝对路径。如果<code>src</code>是一个目录，<code>dest</code>也必须是一个目录。如果<code>dest</code>是不存在的路径，并且如果<code>dest</code>以/结尾或者<code>src</code>是目录，则<code>dest</code>被创建。如果<code>src</code>和<code>dest</code>是文件，如果<code>dest</code>的父目录不存在，任务将失败</td></tr><tr><td align="left"><code>backup</code></td><td align="left">如果文件修改，则在覆盖之前将原文件备份，备份文件包含时间信息</td></tr><tr><td align="left"><code>directory_mode</code></td><td align="left">设定目录的权限，在新建时使用，不会影响已存在的目录</td></tr><tr><td align="left"><code>force</code></td><td align="left">当目标内容不同于源时，将替换远程文件。设置为<code>no</code>时，只有在目标文件不存在的情况下才会传输文件</td></tr><tr><td align="left"><code>group</code></td><td align="left">设置文件/目录的所属组</td></tr><tr><td align="left"><code>mode</code></td><td align="left">设置文件权限</td></tr><tr><td align="left"><code>owner</code></td><td align="left">设置文件/目录的所属用户</td></tr></tbody></table><h3 id="Copy前备份"><a href="#Copy前备份" class="headerlink" title="Copy前备份"></a>Copy前备份</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible all -m copy -a <span class="string">"src=/root/ansible_copy_file backup=yes dest=/home/"</span></span><br></pre></td></tr></table></figure><blockquote><p>在第一次拷贝时，由于目标主机还并没有这个文件， 备份动作不生效</p><p>在对文件内容进行修改后重新执行该命令拷贝文件</p><p>此时目标主机下，不光会有我们上传的拷贝文件，还有之前文件的一个备份</p></blockquote><h4 id="覆盖内容"><a href="#覆盖内容" class="headerlink" title="覆盖内容"></a>覆盖内容</h4><blockquote><p>直接通过<code>content</code>参数指定内容，并对目标主机上已存在的<code>test_copy</code>文件进行覆盖</p></blockquote><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible all -m <span class="keyword">copy</span><span class="bash"> -a <span class="string">"content='这是命令修改\n'  dest=/home/test_copy"</span></span></span><br></pre></td></tr></table></figure><blockquote><p>这条命令将会把远程主机<code>home</code>目录下的<code>test_copy</code>文件覆盖为我们的<code>content</code>内容</p></blockquote><h3 id="Stat模块"><a href="#Stat模块" class="headerlink" title="Stat模块"></a>Stat模块</h3><blockquote><p>该模块可以获取远程主机下的文件信息，需要使用<code>path</code>参数指明文件路径</p></blockquote><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible all -m stat -<span class="selector-tag">a</span> <span class="string">"path=/home/test_copy"</span></span><br></pre></td></tr></table></figure><h3 id="Yum模块"><a href="#Yum模块" class="headerlink" title="Yum模块"></a>Yum模块</h3><blockquote><p>该模块可以对远程主机上的软件安装、卸载进行管理</p></blockquote><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible-doc -s <span class="keyword">copy</span><span class="bash"><span class="comment"># 文档</span></span></span><br></pre></td></tr></table></figure><ul><li>支持参数</li></ul><table><thead><tr><th align="left">参数</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">name</td><td align="left">必须参数，用于指定需要管理的软件包，比如<code>nginx</code></td></tr><tr><td align="left">state</td><td align="left">用于指定软件包的状态，默认值为<code>present</code>，表示确保软件包已经安装 除了<code>present</code>，其他可用值有<code>installed</code>、<code>latest</code>、<code>absent</code>、<code>removed</code> 其中<code>installed</code>与<code>present</code>等效，<code>latest</code>表示安装<code>yum</code>中最新的版本，<code>absent</code>和<code>removed</code>等效，表示删除对应的软件包</td></tr></tbody></table><ul><li>在远程主机下安装<code>nginx</code></li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible all -m yum -<span class="selector-tag">a</span> <span class="string">"name=nginx state=installed"</span></span><br></pre></td></tr></table></figure><ul><li>查看<code>nginx</code>服务状态</li></ul><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl status nginx</span></span><br></pre></td></tr></table></figure><h3 id="Service模块"><a href="#Service模块" class="headerlink" title="Service模块"></a>Service模块</h3><blockquote><p>该模块主要用于远程服务器上对应的服务管理，比如开启或关闭<code>apache</code>服务等</p></blockquote><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">./ansible-doc</span> -s yum<span class="comment"># 文档</span></span><br></pre></td></tr></table></figure><ul><li>支持参数</li></ul><table><thead><tr><th align="left">参数</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left"><code>name</code></td><td align="left">需要管理的服务名称，如<code>nginx</code></td></tr><tr><td align="left"><code>state</code></td><td align="left">此参数用于指定服务的状态 比如，我们想要启动远程主机中的<code>nginx</code>，则可以将<code>state</code>的值设置为<code>started</code> 如果想要停止远程主机中的服务，则可以将<code>state</code>的值设置为<code>stopped</code> 此参数的可用值有<code>started</code>、<code>stopped</code>、<code>restarted</code>、<code>reloaded</code></td></tr><tr><td align="left"><code>enabled</code></td><td align="left">此参数用于指定是否将服务设置为开机启动项，设置为<code>yes</code>表示将对应服务设置为开机启动，设置为<code>no</code>表示不会开机启动</td></tr></tbody></table><ul><li>将远程主机下的<code>httpd</code>服务开启</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./ansible all -m<span class="built_in"> service </span>-a <span class="string">"name=httpd state=started"</span></span><br></pre></td></tr></table></figure><h3 id="File模块"><a href="#File模块" class="headerlink" title="File模块"></a>File模块</h3><blockquote><p><code>file</code>模块可以帮助我们完成一些对文件的基本操作</p><p>比如，<strong>创建文件</strong>或<strong>目录</strong>、<strong>删除文件</strong>或<strong>目录</strong>、<strong>修改文件权限</strong>等</p></blockquote><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">./ansible-doc</span> -s yum<span class="comment"># 文档</span></span><br></pre></td></tr></table></figure><ul><li>支持参数</li></ul><table><thead><tr><th align="left">参数</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left"><code>path</code></td><td align="left">指明需要操作的文件或目录路径</td></tr><tr><td align="left"><code>state</code></td><td align="left">此参数非常灵活，其对应的值需要根据情况设定。比如，我们想要在远程主机上创建<code>/testdir/a/b</code>目录，那么则需要设置<code>path=/testdir/a/b</code>，但是，我们无法从<code>/testdir/a/b</code>这个路径看出<code>b</code>是一个文件还是一个目录，<code>ansible</code>也同样无法单单从一个字符串就知道你要创建文件还是目录，所以，我们需要通过<code>state</code>参数进行说明 当我们想要创建的<code>/testdir/a/b</code>是一个目录时，需要将<code>state</code>的值设置为<code>directory</code>，<code>directory</code>为目录之意，当它与<code>path</code>结合，<code>ansible</code>就能知道我们要操作的目标是一个目录 当我们想要操作的<code>/testdir/a/b</code>是一个文件时，则需要将<code>state</code>的值设置为<code>touch</code> 当我们想要创建软链接文件时，需将<code>state</code>设置为<code>link</code>；想要创建硬链接文件时，需要将<code>state</code>设置为<code>hard</code> 当我们想要删除一个文件时（删除时不用区分目标是文件、目录、还是链接），则需要将<code>state</code>的值设置为<code>absent</code>，<code>absent</code>为缺席之意，当我们想让操作的目标”缺席”时，就表示我们想要删除目标</td></tr><tr><td align="left"><code>src</code></td><td align="left"><code>src</code>参数：当<code>state</code>设置为<code>link</code>或者<code>hard</code>时，表示我们想要创建一个软链或者硬链 所以，我们必须指明软链或硬链链接的哪个文件，通过<code>src</code>参数即可指定链接源</td></tr><tr><td align="left"><code>force</code></td><td align="left">当<code>state=link</code>的时候，可配合此参数强制创建链接文件，当<code>force=yes</code>时，表示强制创建链接文件。不过强制创建链接文件分为三种情况 情况一：当要创建的链接文件指向的源文件并不存在时，使用此参数，可以先强制创建出链接文件 情况二：当要创建链接文件的目录中已经存在与链接文件同名的文件时，将<code>force</code>设置为<code>yes</code>，会将同名文件覆盖为链接文件，相当于删除同名文件，创建链接文件 情况三：当要创建链接文件的目录中已经存在与链接文件同名的文件，并且链接文件指向的源文件也不存在，这时会强制替换同名文件为链接文件</td></tr><tr><td align="left"><code>owner</code></td><td align="left">指定文件所属用户</td></tr><tr><td align="left"><code>group</code></td><td align="left">指定文件所属组</td></tr><tr><td align="left"><code>mode</code></td><td align="left">指定文件权限</td></tr></tbody></table><ul><li>将远程主机下的<code>Python3</code>创建软连接到<code>home</code>目录</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.<span class="regexp">/ansible all -m file -a "path=/</span>home<span class="regexp">/python3 state=link src=/u</span>sr<span class="regexp">/local/</span>python3<span class="regexp">/bin/</span>python3<span class="string">"</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Ansible&quot;&gt;&lt;a href=&quot;#Ansible&quot; class=&quot;headerlink&quot; title=&quot;Ansible&quot;&gt;&lt;/a&gt;Ansible&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;ansible&lt;/code&gt;基于Python开发，集合了众多运维工具（&lt;code&gt;puppet&lt;/code&gt;、&lt;code&gt;cfengine&lt;/code&gt;、&lt;code&gt;chef&lt;/code&gt;、&lt;code&gt;func&lt;/code&gt;、&lt;code&gt;fabric&lt;/code&gt;）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能&lt;br&gt;在使用时，&lt;code&gt;ansible&lt;/code&gt;不需要在被控制安装客户端，&lt;code&gt;ansible&lt;/code&gt;工作基于&lt;code&gt;ssh&lt;/code&gt;，只要被控制端服务器有&lt;code&gt;ssh&lt;/code&gt;服务，加上一个&lt;code&gt;Python&lt;/code&gt;环境，就可以使用&lt;code&gt;ansible&lt;/code&gt;&lt;br&gt;另外，&lt;code&gt;ansible&lt;/code&gt;在15年的时候，以1.5亿美元被&lt;code&gt;RedHat&lt;/code&gt;公司收购，新版的&lt;code&gt;RedHat&lt;/code&gt;操作系统内置&lt;code&gt;ansible&lt;/code&gt;软件，很厉害的&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="https://cy-blogs.cn/categories/Linux/"/>
    
    
      <category term="Linux" scheme="https://cy-blogs.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>GitHub操作</title>
    <link href="https://cy-blogs.cn/Git/"/>
    <id>https://cy-blogs.cn/Git/</id>
    <published>2019-12-09T11:56:21.542Z</published>
    <updated>2019-12-09T11:58:51.734Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GitHub操作起来真的是太简单啦！"><a href="#GitHub操作起来真的是太简单啦！" class="headerlink" title="GitHub操作起来真的是太简单啦！"></a>GitHub操作起来真的是太简单啦！</h1><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><blockquote><p>Git是一个<strong>免费的开源</strong>分布式版本控制系统，旨在快速高效地处理从小型到大型项目的所有事务。</p><p>Git易于学习， 占地面积小，具有闪电般快速的性能。它超越了Subversion，CVS，Perforce和ClearCase等SCM工具，具有廉价本地分支，便捷的<strong>临时区域</strong>和<strong>多个工作流程</strong>等功能</p></blockquote><a id="more"></a><h3 id="git流程"><a href="#git流程" class="headerlink" title="git流程"></a>git流程</h3><p><a href="https://lienze.tech/blog/images/git流程图.jpg" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/git%E6%B5%81%E7%A8%8B%E5%9B%BE.jpg" alt="git流程图"></a></p><ul><li><code>workspace</code>：工作区</li><li><code>Index/Stage</code>：暂存区</li><li><code>Repository</code>：仓库区/本地仓库</li><li><code>Remote</code>：远程仓库</li></ul><h3 id="SVN与Git的区别"><a href="#SVN与Git的区别" class="headerlink" title="SVN与Git的区别"></a>SVN与Git的区别</h3><ul><li><code>SVN</code></li></ul><blockquote><p>SVN是集中式版本控制系统，版本库是集中放在中央服务器的、而干活的时候，用的都是自己的电脑</p><p>首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器</p><p>集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就纳闷了</p></blockquote><ul><li><code>Git</code></li></ul><blockquote><p>Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库</p><p>这工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了</p><p>Git在本地磁盘上就保存着所有有关当前项目的历史更新，并且Git中的绝大多数操作都只需要访问本地文件和资源，不用连网，所以处理起来速度飞快</p><p>用SVN的话，没有网络或者断开VPN你就无法做任何事情</p><p>但用Git的话，就算你在飞机或者火车上，都可以非常愉快地频繁提交更新，等到了有网络的时候再上传到<strong>远程的镜像仓库</strong>。换作其他版本控制系统，这么做几乎不可能，抑或是非常麻烦</p></blockquote><h3 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h3><ul><li><code>Windows</code>：<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a></li><li><code>Linux</code>：</li></ul><h3 id="Git配置"><a href="#Git配置" class="headerlink" title="Git配置"></a><code>Git配置</code></h3><ul><li><code>git config --global</code>：全局git配置，这台机器所有的Git仓库均会使用这个配置</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git<span class="built_in"> config </span>--global user.name <span class="string">"eastside"</span> # 你的名字</span><br><span class="line">git<span class="built_in"> config </span>--global user.email <span class="string">"..@xx.com"</span> # 你的邮箱</span><br></pre></td></tr></table></figure><h3 id="git操作"><a href="#git操作" class="headerlink" title="git操作"></a>git操作</h3><h4 id="创建版本库"><a href="#创建版本库" class="headerlink" title="创建版本库"></a>创建版本库</h4><ul><li>什么是版本库？</li></ul><blockquote><p>版本库又名仓库，英文名repository</p><p>你可以简单的理解一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改，删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻还可以将文件还原</p></blockquote><ul><li>选择，进入某个目录</li></ul><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> projectcd project</span><br></pre></td></tr></table></figure><ul><li>初始化目录为本地仓库</li></ul><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">git init</span></span><br></pre></td></tr></table></figure><ul><li>初始化之后，目录下会多一个隐藏目录<code>.git</code>，该目录是<code>git</code>用来管理版本的，</li></ul><h3 id="添加项目文件"><a href="#添加项目文件" class="headerlink" title="添加项目文件"></a>添加项目文件</h3><ul><li>以创建django项目为例，在<code>git</code>本地仓库开启一个django项目</li></ul><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">django-admin startproject testpro</span></span><br></pre></td></tr></table></figure><ul><li>添加项目文件或目录至暂存区</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">add</span><span class="bash"> testpro</span></span><br></pre></td></tr></table></figure><ul><li>将暂存区内容提交至本地仓库</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">commit</span> -m <span class="string">"a django project"</span></span><br><span class="line">$ git <span class="keyword">commit</span> -m <span class="string">"a django project"</span>[<span class="keyword">master</span> (root-<span class="keyword">commit</span>) adb00b3] a django <span class="keyword">project</span> <span class="number">5</span> files <span class="keyword">changed</span>, <span class="number">172</span> insertions(+) <span class="keyword">create</span> <span class="keyword">mode</span> <span class="number">100644</span> testpro/manage.py <span class="keyword">create</span> <span class="keyword">mode</span> <span class="number">100644</span> testpro/testpro/__init__.py <span class="keyword">create</span> <span class="keyword">mode</span> <span class="number">100644</span> testpro/testpro/settings.py <span class="keyword">create</span> <span class="keyword">mode</span> <span class="number">100644</span> testpro/testpro/urls.py <span class="keyword">create</span> <span class="keyword">mode</span> <span class="number">100644</span> testpro/testpro/wsgi.py</span><br></pre></td></tr></table></figure><blockquote><p><code>-m</code>参数指定提交注释</p></blockquote><ul><li>查看此时仓库状态</li></ul><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br><span class="line">lienze<span class="variable">@DESKTOP</span>-BIDA1PF MINGW64 ~<span class="regexp">/Desktop/project</span> (master)<span class="variable">$ </span>git statusOn branch masternothing to commit, working tree clean</span><br></pre></td></tr></table></figure><h3 id="文件修改提交"><a href="#文件修改提交" class="headerlink" title="文件修改提交"></a>文件修改提交</h3><blockquote><p>如果在开发过程中，对其中的某个文件进行了修改，那么<code>git</code>在对比文件指纹的过程中发现了差异，此时也需要将新修改的文件进行提交</p></blockquote><ul><li>修改<code>settings.py</code>文件配置</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ALLOWED_HOSTS</span> = [<span class="string">"*"</span>,]<span class="comment"># ALLOWED_HOSTS = []</span></span><br></pre></td></tr></table></figure><ul><li>查看仓库状态</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br><span class="line">$ git statusOn branch masterChanges <span class="keyword">not</span> staged <span class="keyword">for</span> <span class="keyword">commit</span>:  (use "git add &lt;file&gt;..." <span class="keyword">to</span> <span class="keyword">update</span> what will be <span class="keyword">committed</span>)  (use "git checkout -- &lt;file&gt;..." <span class="keyword">to</span> <span class="keyword">discard</span> changes <span class="keyword">in</span> working directory)        modified:   settings.pyno changes added <span class="keyword">to</span> <span class="keyword">commit</span> (use "git add" <span class="keyword">and</span>/<span class="keyword">or</span> "git commit -a")</span><br></pre></td></tr></table></figure><blockquote><p>此时仓库说，<code>modified: settings.py</code>，我们对其中某个文件进行了修改</p></blockquote><ul><li>将修改之后的文件加入暂存区</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">add</span><span class="bash"> -A</span></span><br></pre></td></tr></table></figure><ul><li>此时查看状态</li></ul><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git status</span><br><span class="line">$ git statusOn branch masterChanges <span class="keyword">to</span> <span class="keyword">be</span> committed:  (use <span class="string">"git reset HEAD &lt;file&gt;..."</span> <span class="keyword">to</span> unstage)        modified:   settings.<span class="keyword">py</span></span><br></pre></td></tr></table></figure><ul><li>将暂存区的内容提交至本地仓库</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">commit</span> -m <span class="string">'change settings'</span></span><br><span class="line"><span class="keyword">On</span> branch masternothing <span class="keyword">to</span> <span class="keyword">commit</span>, working tree clean</span><br></pre></td></tr></table></figure><ul><li>丢弃修改，可以丢弃工作区对于文件的修改</li></ul><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout <span class="comment">-- settings.py</span></span><br></pre></td></tr></table></figure><ul><li>注意：命令<code>git checkout -- settings.py</code>中的<code>--</code>很重要，如果没有<code>--</code>的话，那么命令变成创建分支了</li></ul><h3 id="文件删除提交"><a href="#文件删除提交" class="headerlink" title="文件删除提交"></a>文件删除提交</h3><ul><li>在<code>django</code>项目的隔壁创建一个<code>1.py</code>文件</li></ul><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">touch</span> <span class="number">1.</span>py</span><br></pre></td></tr></table></figure><ul><li>添加该文件</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">add</span><span class="bash"> -Agit commit -m <span class="string">"add 1.py"</span></span></span><br></pre></td></tr></table></figure><ul><li>删除该文件</li></ul><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm <span class="number">1.</span>py</span><br></pre></td></tr></table></figure><ul><li>恢复删除文件</li></ul><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout <span class="comment">-- 1.py</span></span><br></pre></td></tr></table></figure><ul><li>提交至本地工作区</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -<span class="selector-tag">a</span> -m <span class="string">"rm 1.py"</span></span><br></pre></td></tr></table></figure><blockquote><p><code>git commit -a</code>：提交全部修改</p></blockquote><h2 id="git远程仓库"><a href="#git远程仓库" class="headerlink" title="git远程仓库"></a>git远程仓库</h2><blockquote><p>在团队开发中，我们需要每个开发者彼此配合，对同一款项目代码进行编写，此时需要我们借助线上仓库</p></blockquote><ul><li><code>github</code>：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com</a></li><li><code>gitee</code>：<a href="https://gitee.com/" target="_blank" rel="noopener">https://gitee.com</a></li></ul><blockquote><p>由于网络环境，此处选择<code>gitee</code></p></blockquote><ul><li>将远程仓库添加到本地</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote <span class="keyword">add</span><span class="bash"> edu git@gitee.com:eastside/edu.git</span></span><br></pre></td></tr></table></figure><blockquote><p>添加一个远程库，库名为<code>edu</code>，地址是<code>git@gitee.com:eastside/edu.git</code></p></blockquote><ul><li>列举当前所有的远程库</li></ul><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">git remote</span></span><br></pre></td></tr></table></figure><ul><li>删除某个远程库</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote <span class="builtin-name">remove</span> edu</span><br></pre></td></tr></table></figure><ul><li>将本地的仓库推到名为<code>edu</code>的远程仓库中</li></ul><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 仓库地址：https:<span class="comment">//gitee.com/eastside/edu.gitgit push edu master</span></span></span><br></pre></td></tr></table></figure><ul><li>将远程仓库的代码拉取到本地，在第一次拉取时，可能因为缺少远程服务器上的<code>README.txt</code>文件，而导致远程和本地的分支不一样，通过以下命令</li></ul><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git pull --rebase origin <span class="keyword">master</span> <span class="title"># 新建 README</span>文件</span><br><span class="line">git pull edu <span class="keyword">master</span> <span class="title">--allow-unrelated-histories</span></span><br></pre></td></tr></table></figure><ul><li>将远程仓库克隆到本地</li></ul><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">clone</span> <span class="title">https</span>://gitee.com/eastside/edu.git</span><br></pre></td></tr></table></figure><blockquote><p>这是一个已经和远程仓库<code>master</code>分支关联的本地仓库</p></blockquote><ul><li>git全局配置多个用户名冲突时</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  git<span class="built_in"> config </span>--global --replace-all user.email <span class="string">"输入你的邮箱"</span> $  git<span class="built_in"> config </span>--global --replace-all user.name <span class="string">"输入你的用户名"</span></span><br></pre></td></tr></table></figure><h3 id="GIT分支"><a href="#GIT分支" class="headerlink" title="GIT分支"></a>GIT分支</h3><blockquote><p>每次提交，<code>Git</code>都把它们串成一条时间线，这条时间线就是一个分支</p><p>截止到目前，只有一条时间线，在<code>Git</code>里，这个分支叫<strong>主分支</strong>，即<code>master</code>分支</p><p>我们可以通过<code>checkout</code>命令进行分支的创建及切换</p></blockquote><ul><li><code>git checkout -b</code>：创建并切换分支<ul><li><code>git branch branchname</code>：创建分支</li><li><code>git checkout branchname</code>：切换分支</li></ul></li><li>创建一个测试分支</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -<span class="selector-tag">b</span> testbranch</span><br></pre></td></tr></table></figure><ul><li>删除一个分支</li></ul><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">git</span> <span class="keyword">branch </span>-d testbranch</span><br></pre></td></tr></table></figure><ul><li>提交分支代码</li></ul><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push <span class="comment">--all</span></span><br></pre></td></tr></table></figure><ul><li>合并分支</li></ul><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">merge</span> testbranch</span><br></pre></td></tr></table></figure><h3 id="GIT冲突"><a href="#GIT冲突" class="headerlink" title="GIT冲突"></a>GIT冲突</h3><blockquote><p>常见git冲突造成，是由于在多个分支下，或多个仓库中，对同一个文件修改，或添加了新的文件之后</p><p>由于某一方对于文件的修改没有及时在另一方生效，当另一方或另一分支在进行提交时，即会出现冲突</p></blockquote><ul><li>在testbranch分支下，修改1.py文件，并提交到云仓库</li><li>在master分支下，也修改1.py文件，并尝试提交</li></ul><p><a href="https://lienze.tech/blog/images/1565915294853.png" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/1565915294853.png" alt="1565915294853"></a></p><ul><li>此时冲突出现，使用<code>git status</code>命令查看当前仓库状态</li></ul><p><a href="https://lienze.tech/blog/images/git冲突status.png" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/git%E5%86%B2%E7%AA%81status.png" alt="git冲突status"></a></p><ul><li>查看被修改的文件<code>1.py</code></li></ul><p><a href="https://lienze.tech/blog/images/git冲突文件.png" target="_blank" rel="noopener"><img src="https://lienze.tech/blog/images/git%E5%86%B2%E7%AA%81%E6%96%87%E4%BB%B6.png" alt="git冲突文件"></a></p><ul><li><code>Git</code>用<code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>，<code>=======</code>，<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code>标记出不同分支的内容，其中&lt;&lt;&lt;HEAD是指主分支修改的内容，<code>&gt;&gt;&gt;&gt;&gt; testbranch</code>是指<code>fenzhi1</code>上修改的内容，我们可以将差异部分的标注删掉重新提交，或是与对方协商，另行拷贝文件内容，重新clone仓库，将拷贝过的内容添加至内</li><li>之后再进行提交</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">add</span><span class="bash"> 1.pygit commit -m <span class="string">"conflict fixed"</span></span></span><br></pre></td></tr></table></figure><ul><li>这样就可以搞定了</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;GitHub操作起来真的是太简单啦！&quot;&gt;&lt;a href=&quot;#GitHub操作起来真的是太简单啦！&quot; class=&quot;headerlink&quot; title=&quot;GitHub操作起来真的是太简单啦！&quot;&gt;&lt;/a&gt;GitHub操作起来真的是太简单啦！&lt;/h1&gt;&lt;h2 id=&quot;Git&quot;&gt;&lt;a href=&quot;#Git&quot; class=&quot;headerlink&quot; title=&quot;Git&quot;&gt;&lt;/a&gt;Git&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Git是一个&lt;strong&gt;免费的开源&lt;/strong&gt;分布式版本控制系统，旨在快速高效地处理从小型到大型项目的所有事务。&lt;/p&gt;
&lt;p&gt;Git易于学习， 占地面积小，具有闪电般快速的性能。它超越了Subversion，CVS，Perforce和ClearCase等SCM工具，具有廉价本地分支，便捷的&lt;strong&gt;临时区域&lt;/strong&gt;和&lt;strong&gt;多个工作流程&lt;/strong&gt;等功能&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Git" scheme="https://cy-blogs.cn/categories/Git/"/>
    
    
      <category term="Git" scheme="https://cy-blogs.cn/tags/Git/"/>
    
  </entry>
  
</feed>
